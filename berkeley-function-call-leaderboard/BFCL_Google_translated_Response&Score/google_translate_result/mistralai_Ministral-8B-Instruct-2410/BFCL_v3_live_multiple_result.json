{"id": "live_multiple_0-0-0", "result": "[ChaDri.change_drink(drink_id=\"\u62ff\u9435\", new_preferences={\"size\": \"large\", \"temperature\": \"hot\"})]", "input_token_count": 1518, "output_token_count": 36, "latency": 29.762610912322998}
{"id": "live_multiple_1-0-1", "result": "[ChaDri.change_drink(drink_id='1234', new_preferences={'sweetness_level': 'none', 'temperature': 'hot'})]", "input_token_count": 1519, "output_token_count": 39, "latency": 31.51347589492798}
{"id": "live_multiple_2-1-0", "result": [{"uber.ride": {"loc": "123 Main St, San Francisco, CA", "type": "plus", "time": 10}}], "input_token_count": 1103, "output_token_count": 42, "latency": 32.68716526031494}
{"id": "live_multiple_3-2-0", "result": "[api.weather(loc=\"Ha Noi, Vietnam\")]", "input_token_count": 922, "output_token_count": 14, "latency": 16.047951221466064}
{"id": "live_multiple_4-2-1", "result": [{"uber.ride": {"loc": "H\u00e0 N\u1ed9i, Vi\u1ec7t Nam", "type": "plus", "time": 10}}], "input_token_count": 942, "output_token_count": 38, "latency": 29.839442253112793}
{"id": "live_multiple_5-3-0", "result": [{"get_current_weather": {"location": "Shanghai, China", "unit": "metric"}}], "input_token_count": 1710, "output_token_count": 30, "latency": 25.278047561645508}
{"id": "live_multiple_6-3-1", "result": "Error during inference: 'str' object does not support item assignment", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 267, in _parse_query_response_prompting\n    model_response[\"id\"] = tool_call_id\nTypeError: 'str' object does not support item assignment\n"}
{"id": "live_multiple_7-3-2", "result": "[create_workspace(name='developersHub', base_branch='master')]", "input_token_count": 1692, "output_token_count": 16, "latency": 17.201034545898438}
{"id": "live_multiple_8-4-0", "result": "[cookbook.search_recipe(keyword=\"\u725b\u6392\", cuisine=\"Indian\", max_results=1)]", "input_token_count": 3067, "output_token_count": 23, "latency": 21.30155086517334}
{"id": "live_multiple_9-4-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_10-4-2", "result": "[ControlAppliance.execute(command=\"\ub2e4\uc6a9\ub3c4\uc2e4, \ud1b5\ub3cc\uc774, \uc911\uc9c0\")]", "input_token_count": 3072, "output_token_count": 21, "latency": 19.042320489883423}
{"id": "live_multiple_11-4-3", "result": "[HNA_WQA.search(keyword=\"JI SUNG\u516c\u5712\")]", "input_token_count": 3065, "output_token_count": 20, "latency": 17.89187741279602}
{"id": "live_multiple_12-4-4", "result": "[HNA_WQA.search(keyword=\"Park Geun-hye\")]", "input_token_count": 3081, "output_token_count": 18, "latency": 16.171330213546753}
{"id": "live_multiple_13-4-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_14-4-6", "result": "[ControlAppliance.execute(command=\"\ub2e4\uc6a9\ub3c4\uc2e4, \ud1b5\ub3cc\uc774, \uc911\uc9c0\")]", "input_token_count": 3096, "output_token_count": 21, "latency": 17.938098907470703}
{"id": "live_multiple_15-4-7", "result": "[HNA_NEWS.search(keyword=\"\u5152\u5b50\u6700\u65b0\u76ee\u6a19\", category=\"Sports\")]", "input_token_count": 3081, "output_token_count": 24, "latency": 18.470003366470337}
{"id": "live_multiple_16-4-8", "result": "[HNA_NEWS.search(keyword=\"\ucd5c\uadfc\ub274\uc2a4\")]", "input_token_count": 3067, "output_token_count": 17, "latency": 14.44092345237732}
{"id": "live_multiple_17-4-9", "result": "[cookbook.search_recipe(keyword=\"\u932b\u514b\u6d77\")]", "input_token_count": 3064, "output_token_count": 17, "latency": 13.887346982955933}
{"id": "live_multiple_18-4-10", "result": "[HNA_NEWS.search(keyword=\"\u4eba\u5de5\u667a\u80fd\", date_range=\"2023-10-01 to 2023-10-07\")]", "input_token_count": 3087, "output_token_count": 43, "latency": 28.223727226257324}
{"id": "live_multiple_19-4-11", "result": "[ControlAppliance.execute(command=\"\uac70\uc2e4, \uc5d0\uc5b4\ucee8, \uc2e4\ud589\")]", "input_token_count": 3062, "output_token_count": 18, "latency": 13.30015230178833}
{"id": "live_multiple_20-4-12", "result": "[ControlAppliance.execute(command=\"\ub2e4\uc6a9\ub3c4\uc2e4, \ud1b5\ub3cc\uc774, \ud655\uc778\")]", "input_token_count": 3066, "output_token_count": 20, "latency": 14.445765495300293}
{"id": "live_multiple_21-4-13", "result": "[cookbook.search_recipe(keyword=\"\uc2a4\ud14c\uc774\ud06c\")]", "input_token_count": 3062, "output_token_count": 17, "latency": 12.707011222839355}
{"id": "live_multiple_22-4-14", "result": "[HNA_WQA.search(keyword='\uc784\uc9c4\uc65c\ub780', max_results=10)]", "input_token_count": 3100, "output_token_count": 22, "latency": 15.574525594711304}
{"id": "live_multiple_23-5-0", "result": "[search_products(category=\"shoes\", color=\"red\")]", "input_token_count": 1589, "output_token_count": 15, "latency": 11.58425521850586}
{"id": "live_multiple_24-5-1", "result": [{"search_products": {"category": "clothing", "size": "xl"}}], "input_token_count": 1575, "output_token_count": 26, "latency": 18.443816423416138}
{"id": "live_multiple_25-6-0", "result": "[recall_memory_search(query=\"Shishir's birthday\")]", "input_token_count": 4521, "output_token_count": 15, "latency": 12.760928392410278}
{"id": "live_multiple_26-6-1", "result": "[send_message(message=\"Shishir Patil's birthday is on October 15th. Happy Birthday!\", recipient=\"Shishir Patil\")]", "input_token_count": 5872, "output_token_count": 33, "latency": 23.588561058044434}
{"id": "live_multiple_27-7-0", "result": "[add(a=100, b=-40)]", "input_token_count": 746, "output_token_count": 14, "latency": 12.204936742782593}
{"id": "live_multiple_28-8-0", "result": [{"my_core_function": {"name": "Balkrushn"}}], "input_token_count": 948, "output_token_count": 24, "latency": 19.52074146270752}
{"id": "live_multiple_29-9-0", "result": "[add(a=10, b=3)]", "input_token_count": 1432, "output_token_count": 12, "latency": 10.996406555175781}
{"id": "live_multiple_30-10-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_31-10-1", "result": [{"duck_duck_go.search": {"query": "\u8da8\u52e2\u7269\u54c1"}}], "input_token_count": 1981, "output_token_count": 29, "latency": 21.825754642486572}
{"id": "live_multiple_32-10-2", "result": "[sub(a=100, b=40)]", "input_token_count": 1985, "output_token_count": 14, "latency": 13.295223951339722}
{"id": "live_multiple_33-10-3", "result": "[add(a=10, b=10), add(a=10, b=10)]", "input_token_count": 2060, "output_token_count": 24, "latency": 18.972761392593384}
{"id": "live_multiple_34-11-0", "result": "[get_news_report(location=\"Leighton Buzzard, UK\")]", "input_token_count": 974, "output_token_count": 16, "latency": 14.979514122009277}
{"id": "live_multiple_35-11-1", "result": "[get_tesco_locations(location=\"Letterkenny, IE\")]", "input_token_count": 948, "output_token_count": 17, "latency": 14.980944871902466}
{"id": "live_multiple_36-12-0", "result": [{"todo_add": {"content": "\u53bb\u4e0b\u53489\u9ede\u8cfc\u7269"}}], "input_token_count": 676, "output_token_count": 25, "latency": 20.07746148109436}
{"id": "live_multiple_37-13-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_38-14-0", "result": "[get_interviewer_list(skill=\"Python\")]", "input_token_count": 1252, "output_token_count": 13, "latency": 14.368519306182861}
{"id": "live_multiple_39-14-1", "result": "[review_of_interviewer(interviewer_name=\"Charlie Brown\")]", "input_token_count": 967, "output_token_count": 17, "latency": 16.15183997154236}
{"id": "live_multiple_40-15-0", "result": [{"oven_preheat": {"duration": 36, "temperature": 201}}], "input_token_count": 942, "output_token_count": 29, "latency": 23.016045331954956}
{"id": "live_multiple_41-16-0", "result": "[get_services(namespace='default')]", "input_token_count": 918, "output_token_count": 11, "latency": 13.304333448410034}
{"id": "live_multiple_42-16-1", "result": "[get_pods(namespace='default')]", "input_token_count": 931, "output_token_count": 11, "latency": 12.744198322296143}
{"id": "live_multiple_43-16-2", "result": "[get_services(namespace=\"cascade-sandbox\")]", "input_token_count": 924, "output_token_count": 14, "latency": 14.43087649345398}
{"id": "live_multiple_44-17-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_45-18-0", "result": "[product_search(category=\"clothing\", color=\"red\")]", "input_token_count": 1567, "output_token_count": 14, "latency": 14.407647609710693}
{"id": "live_multiple_46-18-1", "result": [{"inventory_management": {"product_id": "12345-67890"}}], "input_token_count": 1591, "output_token_count": 31, "latency": 24.82790470123291}
{"id": "live_multiple_47-18-2", "result": "[order_status_check(order_id=123456789, product=\"\u667a\u80fdLED\u96fb\u8996\")]", "input_token_count": 1593, "output_token_count": 26, "latency": 21.88008761405945}
{"id": "live_multiple_48-18-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_49-19-0", "result": "[interviewer_review.get(name=\"Charlie Ji\")]", "input_token_count": 1175, "output_token_count": 14, "latency": 14.357534408569336}
{"id": "live_multiple_50-20-0", "result": "[get_movies(city=\"Noida\", movie_date=\"11-11-2024\")]", "input_token_count": 2113, "output_token_count": 26, "latency": 21.85491967201233}
{"id": "live_multiple_51-21-0", "result": "[order_status_check(order_id=\"#123\", product=\"\u904b\u52d5\u978b\")]", "input_token_count": 1933, "output_token_count": 20, "latency": 18.36780595779419}
{"id": "live_multiple_52-21-1", "result": "[get_product_details(product_id=\"SK123\", color=\"Red\")]", "input_token_count": 1913, "output_token_count": 18, "latency": 17.209347009658813}
{"id": "live_multiple_53-22-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_54-22-1", "result": [{"inventory_management": {"product_id": "12345xyz", "sizes": ["M"], "color": "red"}}], "input_token_count": 1948, "output_token_count": 39, "latency": 29.49340796470642}
{"id": "live_multiple_55-22-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_56-22-3", "result": [{"inventory_management": {"product_id": "111", "sizes": ["L"]}}], "input_token_count": 1895, "output_token_count": 31, "latency": 24.79324460029602}
{"id": "live_multiple_57-22-4", "result": "[get_product_details(product_id=\"282828\", size=\"all sizes\")]", "input_token_count": 2016, "output_token_count": 21, "latency": 17.22043514251709}
{"id": "live_multiple_58-22-5", "result": [{"inventory_management": {"product_id": "XY123", "sizes": ["M"]}}], "input_token_count": 2015, "output_token_count": 32, "latency": 23.705543041229248}
{"id": "live_multiple_59-22-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_60-22-7", "result": [{"inventory_management": {"product_id": "abc123", "sizes": ["L"]}}], "input_token_count": 1906, "output_token_count": 32, "latency": 23.13089609146118}
{"id": "live_multiple_61-23-0", "result": [{"get_movies": {"city": "Noida"}}], "input_token_count": 2306, "output_token_count": 22, "latency": 17.257073640823364}
{"id": "live_multiple_62-24-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_63-25-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_64-26-0", "result": "[uber.eat.order(restaurant_id=\"McDonald's\", items=[{\"item_id\": \"Burger123\", \"quantity\": 5}, {\"item_id\": \"wing456\", \"quantity\": 6}])]", "input_token_count": 1521, "output_token_count": 51, "latency": 34.67898750305176}
{"id": "live_multiple_65-26-1", "result": [{"get_current_weather": {"location": "\u6ce2\u58eb\u9813, \u99ac\u85a9\u8af8\u585e\u5dde"}}], "input_token_count": 1531, "output_token_count": 33, "latency": 24.876614093780518}
{"id": "live_multiple_66-27-0", "result": "[add_postgres_server(host=\"plgah.ca\", database=\"finance_db\", username=\"pascal\", password=\"123123\")]", "input_token_count": 1146, "output_token_count": 34, "latency": 24.86542057991028}
{"id": "live_multiple_67-28-0", "result": "[add_postgres_server(host=\"plgah.ca\", database=\"maindb\", username=\"pascal\", password=\"SecurePassword123\")]", "input_token_count": 1102, "output_token_count": 32, "latency": 23.71085834503174}
{"id": "live_multiple_68-29-0", "result": "[add_postgres_server(nickname=\"projectDB\", host=\"http://foo.com\", port=5432, database=\"project_data\", username=\"user1\", password=\"12345\")]", "input_token_count": 1133, "output_token_count": 46, "latency": 31.760818004608154}
{"id": "live_multiple_69-30-0", "result": "[add_postgres_server(nickname=\"primaryDB\", host=\"db.example.com\", port=5432, database=\"inventory\", username=\"admin\", password=\"1234567890\")]", "input_token_count": 2007, "output_token_count": 48, "latency": 33.50286316871643}
{"id": "live_multiple_70-30-1", "result": [{"dartfx_help": {"topic": "troubleshooting"}}], "input_token_count": 1965, "output_token_count": 22, "latency": 18.42174768447876}
{"id": "live_multiple_71-31-0", "result": "[add_postgres_server(nickname=\"EntrprisedB\", host=\"db.company.com\", database=\"sales_data\", username=\"dbadmin\", password=\"Secure*pwd123\")]", "input_token_count": 1249, "output_token_count": 41, "latency": 30.031909227371216}
{"id": "live_multiple_72-32-0", "result": "[add_postgres_server(nickname=\"primaryDB\", host=\"192.168.0.10\", port=5432, database=\"\u4e3b\", username=\"admin_user\", password=\"Secure*pass123\")]", "input_token_count": 1565, "output_token_count": 54, "latency": 36.96505641937256}
{"id": "live_multiple_73-33-0", "result": "[add_postgres_server(nickname='primaryDB', host='192.168.0.12', port=5432, database='main_db', username='admin', password='SecurePass123')]", "input_token_count": 1645, "output_token_count": 53, "latency": 36.96782922744751}
{"id": "live_multiple_74-34-0", "result": [{"dartfx_help": {"topic": "trading", "include_examples": true}}], "input_token_count": 1678, "output_token_count": 29, "latency": 23.131336212158203}
{"id": "live_multiple_75-34-1", "result": "[add_postgres_server(nickname=\"PrimaryDB\", host=\"plgah.ca\", port=5432, database=\"aindb\", username=\"admin\", password=\"12341234\")]", "input_token_count": 1729, "output_token_count": 48, "latency": 34.089492321014404}
{"id": "live_multiple_76-35-0", "result": [{"dartfx_help": {"topic": "charts", "language": "Spanish"}}], "input_token_count": 2115, "output_token_count": 27, "latency": 22.540130376815796}
{"id": "live_multiple_77-35-1", "result": "[add_postgres_server(nickname='x', host='http://plga.ca', port=5432, database='Postgres', username='\u7ba1\u7406', password='Secure_password123')]", "input_token_count": 2150, "output_token_count": 45, "latency": 33.492263078689575}
{"id": "live_multiple_78-35-2", "result": [{"dartfx_help": {"topic": "charts", "language": "Spanish"}}], "input_token_count": 2084, "output_token_count": 26, "latency": 21.371206045150757}
{"id": "live_multiple_79-36-0", "result": [{"dartfx_help": {"topic": "installation"}}], "input_token_count": 1913, "output_token_count": 22, "latency": 19.61970353126526}
{"id": "live_multiple_80-36-1", "result": "[add_mtnards_server(host=\"http://plga.ca\", api_key=\"12344\")]", "input_token_count": 1932, "output_token_count": 25, "latency": 21.924450635910034}
{"id": "live_multiple_81-36-2", "result": "[add_mtnards_server(host=\"http://plga.ca\", api_key=\"1234324\")]", "input_token_count": 1898, "output_token_count": 27, "latency": 23.095332860946655}
{"id": "live_multiple_82-37-0", "result": "[add_postgres_server(host='192.168.0.5')]", "input_token_count": 1978, "output_token_count": 21, "latency": 20.175373315811157}
{"id": "live_multiple_83-38-0", "result": "[list_servers(type=\"postgres\")]", "input_token_count": 2327, "output_token_count": 11, "latency": 14.874543190002441}
{"id": "live_multiple_84-38-1", "result": "[add_postgres_server(nickname='main_db', host='pg.example.org', port=5432, database='main_db', username='admin', password='123412')]", "input_token_count": 2399, "output_token_count": 45, "latency": 34.59875845909119}
{"id": "live_multiple_85-38-2", "result": "[add_mtnards_server(nickname='primary_db_server', host='192.168.0.5', api_key='1234123')]", "input_token_count": 2405, "output_token_count": 41, "latency": 31.765676021575928}
{"id": "live_multiple_86-38-3", "result": "[add_mtnards_server(nickname=\"RSD1\", host=\"http://rds.com\", api_key=\"1234123\")]", "input_token_count": 2378, "output_token_count": 35, "latency": 28.2923686504364}
{"id": "live_multiple_87-38-4", "result": "[list_servers(type=\"openapi\")]", "input_token_count": 2320, "output_token_count": 11, "latency": 13.778087139129639}
{"id": "live_multiple_88-38-5", "result": "[list_servers(type=\"mtnards\")]", "input_token_count": 2373, "output_token_count": 12, "latency": 14.937322854995728}
{"id": "live_multiple_89-39-0", "result": "[render_ui_date_picker_widget(default_date='20-09-2023')]", "input_token_count": 1666, "output_token_count": 23, "latency": 21.94907546043396}
{"id": "live_multiple_90-40-0", "result": "[add_mtnards_server(host=\"data.example.com\", api_key=\"12345-abcde\", nickname=\"fastdataserver\")]", "input_token_count": 2348, "output_token_count": 33, "latency": 27.715625524520874}
{"id": "live_multiple_91-40-1", "result": "[add_postgres_server(nickname=\"primary_db\", host=\"example.org\", port=5432, database=\"main\", username=\"admin\", password=\"12345\")]", "input_token_count": 2357, "output_token_count": 42, "latency": 32.92211079597473}
{"id": "live_multiple_92-40-2", "result": "[list_servers(server_type=\"postgres\")]", "input_token_count": 2296, "output_token_count": 12, "latency": 15.540405750274658}
{"id": "live_multiple_93-41-0", "result": "[add_postgres_server(host='example.org', port=5432, database='\u5eab\u5b58', username='admin', password='Secret', nickname='inventory')]", "input_token_count": 2727, "output_token_count": 36, "latency": 30.024632453918457}
{"id": "live_multiple_94-41-1", "result": [{"list_servers": {}}], "input_token_count": 2688, "output_token_count": 17, "latency": 19.06947374343872}
{"id": "live_multiple_95-41-2", "result": "[close_project(project_id=\"DA-12345\", archive=True, notify_users=False)]", "input_token_count": 2706, "output_token_count": 22, "latency": 21.940703868865967}
{"id": "live_multiple_96-42-0", "result": "[list_files(file_type='data', recursive=True)]", "input_token_count": 4041, "output_token_count": 12, "latency": 17.3341121673584}
{"id": "live_multiple_97-42-1", "result": "[connect_to_server(nickname=\"XYZ\")]", "input_token_count": 4056, "output_token_count": 12, "latency": 17.895543336868286}
{"id": "live_multiple_98-42-2", "result": "[open_project(path='/foo/bar', create_if_missing=True, access_mode='readwrite')]", "input_token_count": 4037, "output_token_count": 23, "latency": 23.657287120819092}
{"id": "live_multiple_99-42-3", "result": "[connect_to_server(nickname=\"PG1\")]", "input_token_count": 4029, "output_token_count": 13, "latency": 17.92274284362793}
{"id": "live_multiple_100-42-4", "result": "[connect_to_server(nickname=\"Text01\")]", "input_token_count": 4040, "output_token_count": 14, "latency": 17.9523823261261}
{"id": "live_multiple_101-42-5", "result": "[connect_to_server(nickname=\"SQL01\", timeout=60)]", "input_token_count": 4033, "output_token_count": 18, "latency": 20.238797664642334}
{"id": "live_multiple_102-43-0", "result": "[list_files(type='json')]", "input_token_count": 4145, "output_token_count": 9, "latency": 16.200682640075684}
{"id": "live_multiple_103-43-1", "result": "[add_postgres_server(nickname='PG1', host='localhost', port=5432, database='main_db', username='admin', password='secure_pass123')]", "input_token_count": 4216, "output_token_count": 42, "latency": 35.86225128173828}
{"id": "live_multiple_104-43-2", "result": "[open_project(path='/foo/bar')]", "input_token_count": 4146, "output_token_count": 11, "latency": 17.953768491744995}
{"id": "live_multiple_105-43-3", "result": "[list_files(type='py', include_hidden=False)]", "input_token_count": 4131, "output_token_count": 12, "latency": 18.530517101287842}
{"id": "live_multiple_106-43-4", "result": "[add_mtnards_server(nickname=\"fastquery\", host=\"rds.example.org\", api_key=\"1231231\")]", "input_token_count": 4172, "output_token_count": 33, "latency": 30.088890075683594}
{"id": "live_multiple_107-43-5", "result": "[list_files(type='sav', include_hidden=True)]", "input_token_count": 4162, "output_token_count": 13, "latency": 19.681044340133667}
{"id": "live_multiple_108-43-6", "result": "[list_servers(type=\"postgres\")]", "input_token_count": 4144, "output_token_count": 11, "latency": 17.368407726287842}
{"id": "live_multiple_109-43-7", "result": "[list_servers(type=\"mtna\")]", "input_token_count": 4134, "output_token_count": 11, "latency": 17.974170446395874}
{"id": "live_multiple_110-43-8", "result": "[list_files(type='txt', include_hidden=True)]", "input_token_count": 4150, "output_token_count": 12, "latency": 18.54099130630493}
{"id": "live_multiple_111-43-9", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_112-43-10", "result": "[list_servers(type=\"postgres\")]", "input_token_count": 4147, "output_token_count": 11, "latency": 16.837694883346558}
{"id": "live_multiple_113-44-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_114-44-1", "result": "[add_postgres_server(nickname=\"aindb\", host=\"pg.example.org\", port=5432, database=\"sales_db\", username=\"\u7ba1\u7406\", password=\"\u5bc6\u78bc\")]", "input_token_count": 3881, "output_token_count": 42, "latency": 34.7109956741333}
{"id": "live_multiple_115-45-0", "result": "[analysis_api.AnalysisApi.retrieve_analysis(project='PROJECTGO', component='AB1010CD', vulnerability='EF903AC-893-F00')]", "input_token_count": 2111, "output_token_count": 43, "latency": 35.29223394393921}
{"id": "live_multiple_116-45-1", "result": "[acl_api.add_mapping(principal_id=\"user-123\", resource_id=\"Resource-456\", permissions=\"read\")]", "input_token_count": 2089, "output_token_count": 31, "latency": 27.82380723953247}
{"id": "live_multiple_117-45-2", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 2076, "output_token_count": 10, "latency": 15.685956001281738}
{"id": "live_multiple_118-45-3", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 2065, "output_token_count": 10, "latency": 15.690398216247559}
{"id": "live_multiple_119-45-4", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 2082, "output_token_count": 10, "latency": 15.721487760543823}
{"id": "live_multiple_120-45-5", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 2081, "output_token_count": 10, "latency": 15.675482273101807}
{"id": "live_multiple_121-46-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_122-46-1", "result": "[get_time_to_collision(ego_velocity=50, ego_acceleration=-2, leading_object_velocity=30, leading_object_acceleration=-1, initial_distance=100)]", "input_token_count": 2607, "output_token_count": 43, "latency": 35.241119146347046}
{"id": "live_multiple_123-46-2", "result": "[get_time_to_collision(ego_velocity=20, ego_acceleration=2, leading_object_velocity=15, leading_object_acceleration=15, initial_distance=50)]", "input_token_count": 2597, "output_token_count": 43, "latency": 35.23344302177429}
{"id": "live_multiple_124-47-0", "result": "[duck_duck_go(query=\"Langfuse\")]", "input_token_count": 2250, "output_token_count": 16, "latency": 19.17035698890686}
{"id": "live_multiple_125-47-1", "result": "[add(a=10, b=3), multiply(a=10, b=3)]", "input_token_count": 2916, "output_token_count": 22, "latency": 22.64221501350403}
{"id": "live_multiple_126-48-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_127-49-0", "result": [{"search_engine.query": {"prompt": "\u98a8\u7b8f\u7684\u6b77\u53f2\u53ca\u5176\u88fd\u4f5c\u65b9\u5f0f"}}], "input_token_count": 1876, "output_token_count": 29, "latency": 27.265188694000244}
{"id": "live_multiple_128-50-0", "result": "[generate_image(prompt=\"A man wearing a red dress\")]", "input_token_count": 2900, "output_token_count": 15, "latency": 19.749816179275513}
{"id": "live_multiple_129-50-1", "result": "[search_engine.query(prompt=\"\u5370\u5ea6\u73b0\u4efb\u603b\u7406\", include_after_year=True)]", "input_token_count": 2902, "output_token_count": 19, "latency": 20.92721676826477}
{"id": "live_multiple_130-50-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_131-50-3", "result": "[multilingual_llm(q=\"What is the capital of India?\", language=\"Hindi\")]", "input_token_count": 2893, "output_token_count": 23, "latency": 22.64231777191162}
{"id": "live_multiple_132-50-4", "result": "[search_engine.query(prompt=\"Who is the current Prime Minister of India\", include_after_year=True)]", "input_token_count": 3035, "output_token_count": 22, "latency": 22.066357374191284}
{"id": "live_multiple_133-50-5", "result": "[multilingual_llm(q=\"Chai Kaise Bnaye\", language=\"Hindi\")]", "input_token_count": 2893, "output_token_count": 24, "latency": 22.62922477722168}
{"id": "live_multiple_134-51-0", "result": "[stock_price.get(ticker='AAPL', exchange='NYSE')]", "input_token_count": 1183, "output_token_count": 18, "latency": 19.16371774673462}
{"id": "live_multiple_135-51-1", "result": "[weather.get(city=\"London\", country=\"GB\")]", "input_token_count": 1172, "output_token_count": 14, "latency": 16.836834192276}
{"id": "live_multiple_136-52-0", "result": [{"weather.get_weather": {"city": "London", "country": "United Kingdom"}}], "input_token_count": 975, "output_token_count": 28, "latency": 24.905368328094482}
{"id": "live_multiple_137-52-1", "result": "[stock_price.get(ticker='AAPL', exchange='NASDAQ')]", "input_token_count": 971, "output_token_count": 20, "latency": 19.73235011100769}
{"id": "live_multiple_138-53-0", "result": "[weather.get(city=\"London\", country=\"United Kingdom\", units=\"metric\")]", "input_token_count": 1241, "output_token_count": 19, "latency": 19.139568090438843}
{"id": "live_multiple_139-53-1", "result": [{"stock_price.get": {"ticker": "AAPL", "exchange": "NASDAQ"}}], "input_token_count": 1231, "output_token_count": 32, "latency": 26.62667751312256}
{"id": "live_multiple_140-54-0", "result": [{"weather.get": {"city": "London", "country": "GB", "units": "metric"}}], "input_token_count": 1170, "output_token_count": 31, "latency": 26.63429594039917}
{"id": "live_multiple_141-54-1", "result": [{"stock_price.get": {"ticker": "AAPL", "exchange": "NASDAQ"}}], "input_token_count": 1170, "output_token_count": 32, "latency": 27.174814224243164}
{"id": "live_multiple_142-55-0", "result": [{"weather.get_weather_data": {"city": "London", "country": "GB"}}], "input_token_count": 1300, "output_token_count": 28, "latency": 24.345418691635132}
{"id": "live_multiple_143-55-1", "result": [{"stock_price.get": {"ticker": "AAPL"}}], "input_token_count": 1297, "output_token_count": 23, "latency": 21.433614015579224}
{"id": "live_multiple_144-56-0", "result": "[get_sensor_readings_latest(perPage=100, metrics=[\"temperature\"], serials=[\"sensor1\", \"sensor2\", \"sensor3\"])]", "input_token_count": 2361, "output_token_count": 35, "latency": 28.863298416137695}
{"id": "live_multiple_145-57-0", "result": [{"get_shopping": {"item_name": "\u51ac\u5b63\u5916\u5957", "location": "\u52a0\u5229\u798f\u5c3c\u4e9e\u5dde\u4f2f\u514b\u5229"}}], "input_token_count": 1373, "output_token_count": 40, "latency": 31.65816354751587}
{"id": "live_multiple_146-58-0", "result": "[get_sensor_readings_latest(perPage=10, networkId=[\"N1\", \"N2\"])]", "input_token_count": 4957, "output_token_count": 26, "latency": 25.443806648254395}
{"id": "live_multiple_147-58-1", "result": "[get_sensor_readings_history(t0='2024-03-05T12:00:00Z', t1='2024-03-05T15:00:00Z', networkId=['L_579838452023959405'], metrics=['temperature'], perPage=10)]", "input_token_count": 5004, "output_token_count": 89, "latency": 61.00898504257202}
{"id": "live_multiple_148-58-2", "result": "[get_sensor_readings_latest(perPage=10)]", "input_token_count": 4959, "output_token_count": 15, "latency": 19.085767030715942}
{"id": "live_multiple_149-58-3", "result": "[get_sensor_alerts(perPage=10, networkId=[\"L_579838452023959405\"])]", "input_token_count": 4971, "output_token_count": 39, "latency": 32.79809904098511}
{"id": "live_multiple_150-58-4", "result": "[get_sensor_readings_latest(perPage=100)]", "input_token_count": 5002, "output_token_count": 16, "latency": 19.062599420547485}
{"id": "live_multiple_151-58-5", "result": "[get_sensor_readings_latest(perPage=10)]", "input_token_count": 4969, "output_token_count": 15, "latency": 18.476534843444824}
{"id": "live_multiple_152-58-6", "result": "[get_sensor_readings_latest(perPage=100, networkId=[\"Office-Network-001\"], metrics=[\"temperature\", \"humidity\"])]", "input_token_count": 4991, "output_token_count": 37, "latency": 29.856379747390747}
{"id": "live_multiple_153-58-7", "result": "[get_sensor_readings_history_by_interval(perPage=100, networkId=[\"12312\"], metrics=[\"temperature\"], timespan=3600, interval=15)]", "input_token_count": 4990, "output_token_count": 43, "latency": 33.498316049575806}
{"id": "live_multiple_154-58-8", "result": "[get_sensor_alerts(perPage=50, networkId=[\"L_5798452023959405\"])]", "input_token_count": 4969, "output_token_count": 37, "latency": 29.83971667289734}
{"id": "live_multiple_155-58-9", "result": "[get_sensor_readings_latest(perPage=50)]", "input_token_count": 4961, "output_token_count": 15, "latency": 17.285356283187866}
{"id": "live_multiple_156-59-0", "result": "[analysis_api.AnalysisApi.retrieve_analysis(project='project_uuid', component='component_uuid', vulnerability='vulnerability_uuid')]", "input_token_count": 1833, "output_token_count": 31, "latency": 26.39165711402893}
{"id": "live_multiple_157-60-0", "result": "[get_adriel_projects(start_date=\"2021-01-01\", end_date=\"2021-12-31\")]", "input_token_count": 1041, "output_token_count": 36, "latency": 29.84833788871765}
{"id": "live_multiple_158-61-0", "result": "[get_adriel_projects(user_id=7623, include_completed=True)]", "input_token_count": 1030, "output_token_count": 20, "latency": 20.770944833755493}
{"id": "live_multiple_159-62-0", "result": "[get_detail_adriel_projects(project_name=\"\u96fb\u5b50\u5546\u52d9\u5e73\u53f0\u5927\u4fee\")]", "input_token_count": 982, "output_token_count": 20, "latency": 20.78035306930542}
{"id": "live_multiple_160-62-1", "result": "[get_adriel_projects(user_id=\"Adriel\", status_filter=\"active\", include_completed=False)]", "input_token_count": 974, "output_token_count": 23, "latency": 22.480365991592407}
{"id": "live_multiple_161-63-0", "result": "[get_detail_adriel_project(project_name=\"Portfolio-Web\")]", "input_token_count": 2023, "output_token_count": 16, "latency": 18.44711661338806}
{"id": "live_multiple_162-63-1", "result": "[get_detail_adriel_project(project_name=\"\u96fb\u5b50\u5546\u52d9 - \u7db2\u7d61\")]", "input_token_count": 2025, "output_token_count": 19, "latency": 20.182363986968994}
{"id": "live_multiple_163-64-0", "result": "[get_detail_adriel_project(project_name=\"\u6295\u8cc7\u7d44\u5408 -  WEB\", include_tasks=True, include_financials=True)]", "input_token_count": 1496, "output_token_count": 30, "latency": 26.3718204498291}
{"id": "live_multiple_164-65-0", "result": "[get_detail_adriel_project(project_name=\"Portfolio-Web\")]", "input_token_count": 1993, "output_token_count": 16, "latency": 19.604936838150024}
{"id": "live_multiple_165-65-1", "result": "[get_adriel_list_projects(user_id=123, include_inactive=True)]", "input_token_count": 2002, "output_token_count": 20, "latency": 20.742446422576904}
{"id": "live_multiple_166-66-0", "result": "[get_adriel_profile(user_id=12445, include_contacts=True)]", "input_token_count": 2335, "output_token_count": 20, "latency": 21.865185499191284}
{"id": "live_multiple_167-67-0", "result": "[get_adriel_profile(user_id='12345', include_preferences=True)]", "input_token_count": 1863, "output_token_count": 20, "latency": 22.425259113311768}
{"id": "live_multiple_168-68-0", "result": "[get_adriel_profile(user_id=12345)]", "input_token_count": 2297, "output_token_count": 15, "latency": 20.14856719970703}
{"id": "live_multiple_169-69-0", "result": "[get_adriel_detail_experience_and_education(experience_or_education_name='Sebelas Maret University Internship', experience_or_education_type='experience')]", "input_token_count": 2466, "output_token_count": 35, "latency": 32.36281156539917}
{"id": "live_multiple_170-70-0", "result": "[get_adriel_detail_experience_and_education(experience_or_education_name=\"Sebelas Maret University Internship\", experience_or_education_type=\"work_experience\")]", "input_token_count": 2228, "output_token_count": 36, "latency": 32.36209487915039}
{"id": "live_multiple_171-71-0", "result": "[get_adriel_detail_experience_and_education(experience_or_education_type=\"Internship\", experience_or_education_name=\"Not specified\", details=\"\", start_date=\"2023-01-01\", end_date=\"2023-12-31\")]", "input_token_count": 3021, "output_token_count": 62, "latency": 48.712116718292236}
{"id": "live_multiple_172-71-1", "result": "[get_adriel_list_projects(user_id=123)]", "input_token_count": 3009, "output_token_count": 15, "latency": 21.85626721382141}
{"id": "live_multiple_173-71-2", "result": "[get_adriel_tech_stack(employee_id=\"123\", category=\"programming_languages\"), get_adriel_tech_stack(employee_id=\"123\", category=\"frameworks\"), get_adriel_tech_stack(employee_id=\"123\", category=\"tools\")]", "input_token_count": 3040, "output_token_count": 61, "latency": 48.12691402435303}
{"id": "live_multiple_174-72-0", "result": "[get_adriel_detail_experience_and_education(experience_or_education_type=\"Internship at Sebelas Maret University (UNS)\")]", "input_token_count": 2357, "output_token_count": 31, "latency": 31.178418397903442}
{"id": "live_multiple_175-72-1", "result": "[get_adriel_list_projects(user_id=12345, status=\"active\")]", "input_token_count": 2364, "output_token_count": 22, "latency": 25.782824754714966}
{"id": "live_multiple_176-73-0", "result": "[recall_memory_search(query=\"Shishir's birthday\")]", "input_token_count": 3963, "output_token_count": 15, "latency": 22.921133041381836}
{"id": "live_multiple_177-74-0", "result": "[get_trip(location=\"New York, NY\")]", "input_token_count": 836, "output_token_count": 13, "latency": 20.697096824645996}
{"id": "live_multiple_178-75-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_179-75-1", "result": [{"HNA_NEWS.search": {"keyword": "artificial intelligence", "category": "Technology", "language": "en", "limit": 10, "sort_by": "Date"}}], "input_token_count": 2646, "output_token_count": 53, "latency": 44.68182396888733}
{"id": "live_multiple_180-76-0", "result": "[order_processing.handle_order(order_id=\"ORD123\", items=[\"ITM456\", \"ITM789\"], customer_info={\"customer_id\": \"CUST001\", \"shipping_address\": \"123 Maple Street, Springfield, IL, 62704\", \"billing_address\": \"456 Oak Avenue, Springfield, IL, 62705\"}, apply_discount=True, discount_code=\"Disc20\", notify_customer=True, item_quantities=[2, 1], item_prices=[15.99, 42.50])]", "input_token_count": 6653, "output_token_count": 132, "latency": 86.6454553604126}
{"id": "live_multiple_181-76-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_182-77-0", "result": "[math_gcd(a=100, b=120)]", "input_token_count": 933, "output_token_count": 17, "latency": 25.825485229492188}
{"id": "live_multiple_183-78-0", "result": "[get_translation_baidu(question=\"\u5feb\u901f\u7684\u68d5\u8272\u72d0\u72f8\u8df3\u904e\u61f6\u72d7\u7684\u72d7\", target_language=\"da\")]", "input_token_count": 2002, "output_token_count": 37, "latency": 38.538493633270264}
{"id": "live_multiple_184-79-0", "result": "[search_advice(query=\"\u8077\u696d\u767c\u5c55\", language=\"EN\")]", "input_token_count": 1775, "output_token_count": 17, "latency": 26.406272649765015}
{"id": "live_multiple_185-80-0", "result": "[get_activity_by_participants(participant_count=5, activity_type=\"education\")]", "input_token_count": 4084, "output_token_count": 21, "latency": 30.63417387008667}
{"id": "live_multiple_186-81-0", "result": "[weather_forecast.get(location=\"\u5317\u4eac\", date=\"the day after tomorrow\")]", "input_token_count": 1036, "output_token_count": 18, "latency": 28.885022401809692}
{"id": "live_multiple_187-82-0", "result": "[quarterly_earnings(company_name=\"Berkshire Hathaway\", cik=\"0001067983\")]", "input_token_count": 1030, "output_token_count": 33, "latency": 36.27225875854492}
{"id": "live_multiple_188-82-1", "result": "[holdings.get_13F_HR(company_name=\"Berkshire Hathaway\", cik=\"0001067983\")]", "input_token_count": 1021, "output_token_count": 37, "latency": 39.648545026779175}
{"id": "live_multiple_189-83-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_190-84-0", "result": "[game_rewards.get(game=\"Fortnite\", platform=\"PlayStation\")]", "input_token_count": 1673, "output_token_count": 18, "latency": 30.036221504211426}
{"id": "live_multiple_191-85-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_192-86-0", "result": "[initialize_question_answering_pipeline(model_name='vikhyatk/moondream2', use_gpu=False), analyze_image_with_question.pipeline(image_path='image.png', question='\u5728\u6280\u8853\u4e0a\u8907\u96dc\u7684\u95dc\u6ce8\u5c0d\u60a8\u6240\u770b\u5230\u7684\u63cf\u8ff0\u7684\u8a73\u7d30\u8aaa\u660e')]", "input_token_count": 1757, "output_token_count": 64, "latency": 54.104909896850586}
{"id": "live_multiple_193-87-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_194-87-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_195-87-2", "result": "[getCurrentTime(timezone=\"America/Los_Angeles\")]", "input_token_count": 1105, "output_token_count": 16, "latency": 25.452136278152466}
{"id": "live_multiple_196-88-0", "result": "[get_tickets(customer=\"Adidas\")]", "input_token_count": 797, "output_token_count": 11, "latency": 22.535457372665405}
{"id": "live_multiple_197-89-0", "result": "[get_tickets(customer=\"Adidas\", priority=5)]", "input_token_count": 913, "output_token_count": 14, "latency": 23.7156400680542}
{"id": "live_multiple_198-90-0", "result": "[adriel_contact]", "input_token_count": 2518, "output_token_count": 6, "latency": 18.89528203010559}
{"id": "live_multiple_199-90-1", "result": "[adriel_tech_stack()]", "input_token_count": 2524, "output_token_count": 8, "latency": 20.093672275543213}
{"id": "live_multiple_200-90-2", "result": "[adriel_list_projects(user_id=3)]", "input_token_count": 2540, "output_token_count": 12, "latency": 21.974260330200195}
{"id": "live_multiple_201-90-3", "result": "[adriel_contact(format='xml')]", "input_token_count": 2525, "output_token_count": 10, "latency": 20.796534299850464}
{"id": "live_multiple_202-90-4", "result": "[adriel_list_projects(user_id=1234)]", "input_token_count": 2549, "output_token_count": 15, "latency": 23.698540687561035}
{"id": "live_multiple_203-90-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_204-90-6", "result": "[adriel_experiences_and_education()]", "input_token_count": 2522, "output_token_count": 11, "latency": 20.80765986442566}
{"id": "live_multiple_205-90-7", "result": "[adriel_experiences_and_education()]", "input_token_count": 2537, "output_token_count": 11, "latency": 21.373409032821655}
{"id": "live_multiple_206-91-0", "result": "[detail_project(project_name=\"e-commerce-website\")]", "input_token_count": 3013, "output_token_count": 13, "latency": 22.544699907302856}
{"id": "live_multiple_207-91-1", "result": "[get_tech_stack(employee_id='Adriel')]", "input_token_count": 3024, "output_token_count": 14, "latency": 22.53713822364807}
{"id": "live_multiple_208-91-2", "result": "[list_projects(user_id='1234', include_completed=True)]", "input_token_count": 3035, "output_token_count": 18, "latency": 24.78093981742859}
{"id": "live_multiple_209-91-3", "result": "[detail_project(project_name=\"turing-machine\", include_status=True)]", "input_token_count": 3016, "output_token_count": 16, "latency": 23.648879766464233}
{"id": "live_multiple_210-91-4", "result": "[detail_experience_and_education(experience_or_education_type=\"Freelance at Pingfest\")]", "input_token_count": 3015, "output_token_count": 23, "latency": 27.00854229927063}
{"id": "live_multiple_211-91-5", "result": "[get_tech_stack(employee_id=1234, include_tools=False)]", "input_token_count": 3053, "output_token_count": 20, "latency": 25.31599760055542}
{"id": "live_multiple_212-91-6", "result": "[detail_project(project_name=\"car-rental\", include_status=True, start_date=\"2023-01-01\")]", "input_token_count": 3042, "output_token_count": 30, "latency": 30.345499515533447}
{"id": "live_multiple_213-91-7", "result": "[detail_experience_and_education(experience_or_education_type=\"Internship at Universitas Sebelas Maret (UNS)\")]", "input_token_count": 3036, "output_token_count": 28, "latency": 29.231663942337036}
{"id": "live_multiple_214-91-8", "result": "[experiences_and_education(person_id=1234, include_experiences=True, include_education=True)]", "input_token_count": 3025, "output_token_count": 27, "latency": 28.675713777542114}
{"id": "live_multiple_215-91-9", "result": "[experiences_and_education(person_id=1234, include_experiences=True, include_education=True)]", "input_token_count": 3027, "output_token_count": 27, "latency": 28.664588451385498}
{"id": "live_multiple_216-92-0", "result": [{"find_flights": {"origin": "BER", "destination": "JFK", "date": "2021-10-10", "passengers": 2}}], "input_token_count": 1144, "output_token_count": 51, "latency": 42.471928358078}
{"id": "live_multiple_217-93-0", "result": "[Subdomain(domain='google.com')]", "input_token_count": 11224, "output_token_count": 11, "latency": 22.45656681060791}
{"id": "live_multiple_218-94-0", "result": "[get_sensor_readings_history_by_interval(perPage=10, timespan=3600, networkIds=[\"L_5798452023959405\"])]", "input_token_count": 3897, "output_token_count": 47, "latency": 43.679283618927}
{"id": "live_multiple_219-94-1", "result": "[get_sensor_readings_latest(perPage=100)]", "input_token_count": 3873, "output_token_count": 16, "latency": 28.08918261528015}
{"id": "live_multiple_220-94-2", "result": "[get_sensor_readings_latest(perPage=10)]", "input_token_count": 3837, "output_token_count": 15, "latency": 26.396514177322388}
{"id": "live_multiple_221-95-0", "result": [{"segment": {"img_path": "./yoha.jpg"}}], "input_token_count": 907, "output_token_count": 21, "latency": 30.312164068222046}
{"id": "live_multiple_222-96-0", "result": [{"uber.ride": {"loc": "456 ELM ST, Springfield, IL", "type": "comfort", "time": 10}}], "input_token_count": 1228, "output_token_count": 42, "latency": 43.11652183532715}
{"id": "live_multiple_223-97-0", "result": "[list_directory_contents(dir_path=\"/out/program\", include_hidden=True, sort_order=\"desc\")]", "input_token_count": 1332, "output_token_count": 22, "latency": 31.981985569000244}
{"id": "live_multiple_224-98-0", "result": [{"reschedule": {"identifier": "ID\u7259\u91ab", "dateortime": "2024-11-01T16:00:00", "timezone": "America/New_York"}}], "input_token_count": 1146, "output_token_count": 58, "latency": 47.60796070098877}
{"id": "live_multiple_225-99-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1589, "output_token_count": 10, "latency": 25.26676368713379}
{"id": "live_multiple_226-100-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_227-101-0", "result": "[project_api.ProjectApi.get_children_projects(uuid='123e4567-e89b-12d3-a456-4266614174000')]", "input_token_count": 2232, "output_token_count": 50, "latency": 45.60962104797363}
{"id": "live_multiple_228-102-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_229-103-0", "result": "[get_contact_information(id_no=\"A1234567B\")]", "input_token_count": 1265, "output_token_count": 20, "latency": 31.98039674758911}
{"id": "live_multiple_230-103-1", "result": "[get_contact_information(name=\"Liam Neeson\")]", "input_token_count": 1266, "output_token_count": 14, "latency": 28.013222694396973}
{"id": "live_multiple_231-104-0", "result": "[get_contact_information(id_no=123)]", "input_token_count": 1228, "output_token_count": 13, "latency": 27.427165746688843}
{"id": "live_multiple_232-104-1", "result": "[get_contact_information(name=\"Liam Neeson\")]", "input_token_count": 1245, "output_token_count": 14, "latency": 27.38541078567505}
{"id": "live_multiple_233-105-0", "result": "[get_contact_information(name=\"Rayson Goh\")]", "input_token_count": 1181, "output_token_count": 15, "latency": 27.94579768180847}
{"id": "live_multiple_234-106-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_235-106-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_236-106-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_237-106-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_238-106-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_239-107-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_240-107-1", "result": "[search_web_tool(query=\"weather in India\")]", "input_token_count": 2767, "output_token_count": 13, "latency": 25.662113189697266}
{"id": "live_multiple_241-107-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_242-107-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_243-107-4", "result": "[search_web_tool(query=\"\u96fb\u6688\u75c5\u6bd2\u6700\u65b0\u65b0\u805e\", source=\"news\")]", "input_token_count": 2775, "output_token_count": 23, "latency": 31.406656980514526}
{"id": "live_multiple_244-108-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1801, "output_token_count": 10, "latency": 23.9774169921875}
{"id": "live_multiple_245-109-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1230, "output_token_count": 10, "latency": 23.423530101776123}
{"id": "live_multiple_246-110-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 909, "output_token_count": 10, "latency": 23.41728162765503}
{"id": "live_multiple_247-111-0", "result": "[analysis_api.AnalysisApi.retrieve_analysis(project='project_uuid', component='AB1010CD', vulnerability='EF903AC-893-f')]", "input_token_count": 1347, "output_token_count": 40, "latency": 39.3047251701355}
{"id": "live_multiple_248-112-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 2290, "output_token_count": 10, "latency": 24.533933877944946}
{"id": "live_multiple_249-113-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1052, "output_token_count": 10, "latency": 24.546263456344604}
{"id": "live_multiple_250-114-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1324, "output_token_count": 10, "latency": 23.96959638595581}
{"id": "live_multiple_251-115-0", "result": "To determine the current version of the application, you can call the `version_api.VersionApi.get_version` function.", "input_token_count": 1038, "output_token_count": 25, "latency": 32.72441482543945}
{"id": "live_multiple_252-116-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1314, "output_token_count": 10, "latency": 24.555777072906494}
{"id": "live_multiple_253-117-0", "result": "[badge_api.BadgeApi.get_project_vulnerabilities_badge(name=\"Bandana\", version=\"5\")]", "input_token_count": 1045, "output_token_count": 25, "latency": 33.32536816596985}
{"id": "live_multiple_254-118-0", "result": "[badge_api.BadgeApi.get_project_policy_violations_badge(uuid='project_uuid')]", "input_token_count": 1131, "output_token_count": 22, "latency": 31.020813703536987}
{"id": "live_multiple_255-119-0", "result": "[badge_api.BadgeApi.get_project_policy_violations_badge(uuid='12345')]", "input_token_count": 1321, "output_token_count": 25, "latency": 32.84644818305969}
{"id": "live_multiple_256-120-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_257-121-0", "result": "[vex_api.VexApi.export_project_as_cyclone_dx1(uuid=\"1A1A-C6\")]", "input_token_count": 1782, "output_token_count": 28, "latency": 32.71882748603821}
{"id": "live_multiple_258-122-0", "result": "[project_api.ProjectApi.get_project_by_name_and_version(name=\"Orion\", version=\"2.1.3\")]", "input_token_count": 1194, "output_token_count": 26, "latency": 31.997127056121826}
{"id": "live_multiple_259-123-0", "result": "[project_api.ProjectApi.get_project_by_name_and_version(name=\"my_version_proj\", version=\"1.2.3\")]", "input_token_count": 1285, "output_token_count": 28, "latency": 31.86633849143982}
{"id": "live_multiple_260-124-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1111, "output_token_count": 10, "latency": 22.89102840423584}
{"id": "live_multiple_261-125-0", "result": "[rotateImageAction(degrees=30)]", "input_token_count": 2564, "output_token_count": 12, "latency": 24.03670310974121}
{"id": "live_multiple_262-125-1", "result": "[rotateImageAction(degrees=20), resizeImageAction(aspect_ratio_width=100, aspect_ratio_height=100)]", "input_token_count": 2577, "output_token_count": 32, "latency": 33.49660134315491}
{"id": "live_multiple_263-126-0", "result": [{"EventQuery": {"search_string": "\u9ad4\u80b2\u8ab2"}}], "input_token_count": 1073, "output_token_count": 22, "latency": 30.58745503425598}
{"id": "live_multiple_264-126-1", "result": [{"EventQuery": {"search_string": "\u65c5\u884c", "start_date": "2023-04-01", "end_date": "2023-04-30"}}], "input_token_count": 1098, "output_token_count": 53, "latency": 42.80071806907654}
{"id": "live_multiple_265-127-0", "result": [{"Weather_1_GetWeather": {"city": "\u6cb3\u5167"}}], "input_token_count": 3579, "output_token_count": 23, "latency": 30.525620460510254}
{"id": "live_multiple_266-127-1", "result": "[Weather_1_GetWeather(city='\u8056\u5730\u4e9e\u54e5')]", "input_token_count": 3588, "output_token_count": 16, "latency": 27.597908973693848}
{"id": "live_multiple_267-127-2", "result": [{"Weather_1_GetWeather": {"city": "Vancouver"}}], "input_token_count": 3597, "output_token_count": 23, "latency": 29.920692205429077}
{"id": "live_multiple_268-127-3", "result": [{"Weather_1_GetWeather": {"city": "London"}}], "input_token_count": 3598, "output_token_count": 22, "latency": 28.4914493560791}
{"id": "live_multiple_269-127-4", "result": [{"Weather_1_GetWeather": {"city": "\u8cbb\u57ce", "date": "2023-03-08"}}], "input_token_count": 3597, "output_token_count": 38, "latency": 33.20746350288391}
{"id": "live_multiple_270-127-5", "result": [{"Weather_1_GetWeather": {"city": "New York", "date": "2023-04-17"}}], "input_token_count": 3603, "output_token_count": 38, "latency": 33.19293260574341}
{"id": "live_multiple_271-127-6", "result": [{"Weather_1_GetWeather": {"city": "San Diego, CA", "date": "2023-03-07"}}], "input_token_count": 3605, "output_token_count": 40, "latency": 33.429858684539795}
{"id": "live_multiple_272-127-7", "result": "[Weather_1_GetWeather(city='Nairobi')]", "input_token_count": 3590, "output_token_count": 15, "latency": 23.941793203353882}
{"id": "live_multiple_273-127-8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_274-127-9", "result": [{"Weather_1_GetWeather": {"city": "Chicago"}}], "input_token_count": 3593, "output_token_count": 22, "latency": 26.734705209732056}
{"id": "live_multiple_275-127-10", "result": [{"Weather_1_GetWeather": {"city": "\u7f8e\u570b\u5cfd\u8c37", "date": "2024-03-12"}}], "input_token_count": 3601, "output_token_count": 40, "latency": 32.8748996257782}
{"id": "live_multiple_276-127-11", "result": "[Weather_1_GetWeather(city='Los Angeles')]", "input_token_count": 3587, "output_token_count": 14, "latency": 23.37206196784973}
{"id": "live_multiple_277-128-0", "result": "[Restaurants_2_FindRestaurants(category=\"moderate\", location=\"New York, NY\", has_seating_outdoors=True)]", "input_token_count": 2103, "output_token_count": 31, "latency": 28.997462034225464}
{"id": "live_multiple_278-128-1", "result": "[Restaurants_2_FindRestaurants(category=\"Italian\", location=\"Oakland, CA\", price_range=\"moderate\")]", "input_token_count": 2089, "output_token_count": 31, "latency": 28.986089944839478}
{"id": "live_multiple_279-128-2", "result": "[Restaurants_2_FindRestaurants(category=\"Asian Fusion\", location=\"Santa Clara, CA\")]", "input_token_count": 2118, "output_token_count": 26, "latency": 28.38146138191223}
{"id": "live_multiple_280-128-3", "result": "[Restaurants_2_FindRestaurants(category=\"Coffeehouse\", location=\"New York, NY\", price_range=\"moderate\")]", "input_token_count": 2109, "output_token_count": 33, "latency": 29.54029107093811}
{"id": "live_multiple_281-128-4", "result": [{"Restaurants_2_FindRestaurants": {"category": "Vegetarian", "location": "Berkeley, CA"}}], "input_token_count": 2102, "output_token_count": 39, "latency": 32.42829751968384}
{"id": "live_multiple_282-128-5", "result": "[Restaurants_2_FindRestaurants(category=\"American\", location=\"Mountain View, CA\", has_seating_outdoors=True)]", "input_token_count": 2095, "output_token_count": 31, "latency": 28.971640825271606}
{"id": "live_multiple_283-128-6", "result": "[Restaurants_2_FindRestaurants(category=\"Izakaya\", location=\"San Francisco, CA\", price_range=\"cheap\")]", "input_token_count": 2143, "output_token_count": 32, "latency": 29.07518458366394}
{"id": "live_multiple_284-128-7", "result": "[Restaurants_2_FindRestaurants(category=\"Italian\", location=\"San Francisco, CA\")]", "input_token_count": 2160, "output_token_count": 24, "latency": 27.377585887908936}
{"id": "live_multiple_285-129-0", "result": [{"Services_4_FindProvider": {"city": "Pittsburgh, PA", "type": "Psychiatrist", "insurance_accepted": true}}], "input_token_count": 1716, "output_token_count": 43, "latency": 35.13797330856323}
{"id": "live_multiple_286-129-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_287-129-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_288-129-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_289-129-4", "result": [{"Services_4_FindProvider": {"city": "Novi, CA", "type": "Psychologist"}}], "input_token_count": 1723, "output_token_count": 33, "latency": 28.07793116569519}
{"id": "live_multiple_290-129-5", "result": [{"Services_4_FindProvider": {"city": "\u6838\u6843\u6eaa, CA", "type": "Family Counselor"}}], "input_token_count": 1713, "output_token_count": 38, "latency": 29.110971450805664}
{"id": "live_multiple_291-130-0", "result": "[Hotels_2_SearchHouse(where_to='Austin, TX')]", "input_token_count": 1339, "output_token_count": 18, "latency": 21.98011589050293}
{"id": "live_multiple_292-130-1", "result": "[Hotels_2_SearchHouse(where_to='Long Beach, CA', rating=4.2)]", "input_token_count": 1348, "output_token_count": 24, "latency": 22.614743947982788}
{"id": "live_multiple_293-130-2", "result": "[Hotels_2_SearchHouse(where_to='New York, NY', rating=3.7, has_laundry_service='True')]", "input_token_count": 1364, "output_token_count": 34, "latency": 25.651887893676758}
{"id": "live_multiple_294-130-3", "result": "[Hotels_2_SearchHouse(where_to='Kuala Lumpur, Malaysia', number_of_adults=1, rating=3.8)]", "input_token_count": 1378, "output_token_count": 33, "latency": 24.939275979995728}
{"id": "live_multiple_295-130-4", "result": "[Hotels_2_SearchHouse(where_to='Austin, TX', number_of_adults=2)]", "input_token_count": 1345, "output_token_count": 25, "latency": 21.66000747680664}
{"id": "live_multiple_296-130-5", "result": "[Hotels_2_SearchHouse(where_to='Austin, TX', number_of_adults=4, rating=4.0)]", "input_token_count": 1355, "output_token_count": 31, "latency": 23.555010080337524}
{"id": "live_multiple_297-130-6", "result": "[Hotels_2_SearchHouse(where_to='Long Beach, CA', has_laundry_service='True')]", "input_token_count": 1345, "output_token_count": 28, "latency": 22.22061276435852}
{"id": "live_multiple_298-130-7", "result": "[Hotels_2_SearchHouse(where_to='Chicago, IL', rating=3.9)]", "input_token_count": 1342, "output_token_count": 23, "latency": 20.778453826904297}
{"id": "live_multiple_299-130-8", "result": "[Hotels_2_SearchHouse(where_to='Sydney, NSW', has_laundry_service='True', number_of_adults=3)]", "input_token_count": 1364, "output_token_count": 34, "latency": 23.39298367500305}
{"id": "live_multiple_300-130-9", "result": "[Hotels_2_SearchHouse(where_to='Rio de Janeiro, RJ', number_of_adults=2, rating=4.2)]", "input_token_count": 1359, "output_token_count": 33, "latency": 23.239899396896362}
{"id": "live_multiple_301-131-0", "result": "[Hotels_4_SearchHotel(location='London, UK')]", "input_token_count": 3977, "output_token_count": 16, "latency": 18.020294666290283}
{"id": "live_multiple_302-131-1", "result": "[Hotels_4_SearchHotel(location='New York, NY')]", "input_token_count": 3981, "output_token_count": 17, "latency": 18.062557458877563}
{"id": "live_multiple_303-131-2", "result": "[Hotels_4_SearchHotel(location='Vancouver, BC', star_rating='3')]", "input_token_count": 4004, "output_token_count": 22, "latency": 19.2252779006958}
{"id": "live_multiple_304-131-3", "result": "[Hotels_4_SearchHotel(location='Los Angeles, CA', star_rating='4')]", "input_token_count": 3987, "output_token_count": 22, "latency": 19.21119523048401}
{"id": "live_multiple_305-131-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_306-131-5", "result": "[Hotels_4_SearchHotel(location='Kuala Lumpur, Malaysia')]", "input_token_count": 3970, "output_token_count": 18, "latency": 17.975749969482422}
{"id": "live_multiple_307-131-6", "result": "[Hotels_4_SearchHotel(location='Philadelphia, PA', number_of_rooms='3')]", "input_token_count": 3998, "output_token_count": 23, "latency": 18.306965112686157}
{"id": "live_multiple_308-131-7", "result": "[Hotels_4_SearchHotel(location='Phoenix, AZ')]", "input_token_count": 3988, "output_token_count": 17, "latency": 16.719924688339233}
{"id": "live_multiple_309-131-8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_310-132-0", "result": [{"Movies_3_FindMovies": {"directed_by": "Herbert Ross", "genre": "Family", "cast": "Betsy Widhalm"}}], "input_token_count": 2345, "output_token_count": 44, "latency": 29.344550132751465}
{"id": "live_multiple_311-132-1", "result": [{"Movies_3_FindMovies": {"directed_by": "Wes Anderson", "genre": "Comedy", "cast": "Bill Murray"}}], "input_token_count": 2341, "output_token_count": 41, "latency": 27.711408615112305}
{"id": "live_multiple_312-132-2", "result": [{"Movies_3_FindMovies": {"directed_by": "Jordan Peele", "cast": "Lupita Nyong'o", "genre": "Horror"}}], "input_token_count": 2344, "output_token_count": 46, "latency": 30.53619384765625}
{"id": "live_multiple_313-132-3", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "cast": "Martin Kove"}}], "input_token_count": 2331, "output_token_count": 34, "latency": 23.84249210357666}
{"id": "live_multiple_314-132-4", "result": [{"Movies_3_FindMovies": {"directed_by": "Jim Henson", "cast": "Jennifer Connelly"}}], "input_token_count": 2345, "output_token_count": 36, "latency": 25.050337314605713}
{"id": "live_multiple_315-132-5", "result": [{"Movies_3_FindMovies": {"directed_by": "Herbert Ross", "cast": "James Shapkoff III"}}], "input_token_count": 2344, "output_token_count": 37, "latency": 25.072193384170532}
{"id": "live_multiple_316-132-6", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "genre": "Offbeat", "cast": "Camila Sosa"}}], "input_token_count": 2335, "output_token_count": 43, "latency": 27.81789517402649}
{"id": "live_multiple_317-132-7", "result": [{"Movies_3_FindMovies": {"directed_by": "Guillermo del Toro", "genre": "Fantasy", "cast": "Emma Watson"}}], "input_token_count": 2340, "output_token_count": 43, "latency": 27.802653551101685}
{"id": "live_multiple_318-132-8", "result": [{"Movies_3_FindMovies": {"directed_by": "Daniel", "cast": "dontcare"}}], "input_token_count": 2325, "output_token_count": 32, "latency": 22.486250638961792}
{"id": "live_multiple_319-132-9", "result": [{"Movies_3_FindMovies": {"directed_by": "Gavin Hood", "cast": "Hattie Morahan"}}], "input_token_count": 2340, "output_token_count": 36, "latency": 23.926024436950684}
{"id": "live_multiple_320-132-10", "result": [{"Movies_3_FindMovies": {"directed_by": "Thurop Van Orman", "cast": "Pete Davidson"}}], "input_token_count": 2350, "output_token_count": 37, "latency": 25.099006175994873}
{"id": "live_multiple_321-132-11", "result": [{"Movies_3_FindMovies": {"directed_by": "Quentin Tarantino", "cast": "Maya Hawke", "genre": "dontcare"}}], "input_token_count": 2366, "output_token_count": 44, "latency": 28.259745359420776}
{"id": "live_multiple_322-132-12", "result": [{"Movies_3_FindMovies": {"directed_by": "Peter Jackson", "genre": "Fantasy", "cast": "Dominic Monaghan"}}], "input_token_count": 2349, "output_token_count": 42, "latency": 26.670730590820312}
{"id": "live_multiple_323-132-13", "result": [{"Movies_3_FindMovies": {"directed_by": "Steven Spielberg", "cast": "Josef Sommer"}}], "input_token_count": 2349, "output_token_count": 34, "latency": 22.727981567382812}
{"id": "live_multiple_324-132-14", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "genre": "dontcare", "cast": "Zoey Margaret Colletti"}}], "input_token_count": 2322, "output_token_count": 45, "latency": 27.143185138702393}
{"id": "live_multiple_325-132-15", "result": [{"Movies_3_FindMovies": {"directed_by": "Riley Stearns"}}], "input_token_count": 2335, "output_token_count": 29, "latency": 18.432198762893677}
{"id": "live_multiple_326-132-16", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_327-132-17", "result": [{"Movies_3_FindMovies": {"directed_by": "Steven Spielberg", "genre": "Sci-fi", "cast": "James Keane"}}], "input_token_count": 2352, "output_token_count": 42, "latency": 24.937068223953247}
{"id": "live_multiple_328-132-18", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_329-132-19", "result": [{"Movies_3_FindMovies": {"directed_by": "Quentin Tarantino", "cast": "Eric Stoltz"}}], "input_token_count": 2345, "output_token_count": 37, "latency": 22.435811758041382}
{"id": "live_multiple_330-132-20", "result": [{"Movies_3_FindMovies": {"directed_by": "Joel Zwick", "cast": "Joey Fatone"}}], "input_token_count": 2345, "output_token_count": 37, "latency": 21.87213945388794}
{"id": "live_multiple_331-132-21", "result": [{"Movies_3_FindMovies": {"directed_by": "Sunita Mani", "cast": "Josephine Decker", "genre": "Thriller"}}], "input_token_count": 2347, "output_token_count": 44, "latency": 24.88604712486267}
{"id": "live_multiple_332-132-22", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "genre": "Mystery", "cast": "Kathy Griffin"}}], "input_token_count": 2333, "output_token_count": 42, "latency": 23.087527751922607}
{"id": "live_multiple_333-132-23", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "genre": "dontcare", "cast": "dontcare"}}], "input_token_count": 2322, "output_token_count": 40, "latency": 22.06818389892578}
{"id": "live_multiple_334-132-24", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "genre": "Mystery", "cast": "Lisa Tharps"}}], "input_token_count": 2326, "output_token_count": 43, "latency": 22.506470203399658}
{"id": "live_multiple_335-132-25", "result": [{"Movies_3_FindMovies": {"directed_by": "Taika Waititi", "genre": "Comedy"}}], "input_token_count": 2323, "output_token_count": 35, "latency": 17.555888414382935}
{"id": "live_multiple_336-133-0", "result": "[Music_3_PlayMedia(track=\"\u60a8\u7684\u5f62\u72c0\", artist=\"Ed Sheeran\", device=\"Kitchen\")]", "input_token_count": 2054, "output_token_count": 29, "latency": 14.103896141052246}
{"id": "live_multiple_337-133-1", "result": "[Music_3_LookupMusic(artist=\"Carrie Underwood\", genre=\"Pop\")]", "input_token_count": 2085, "output_token_count": 23, "latency": 10.810304641723633}
{"id": "live_multiple_338-133-2", "result": [{"Music_3_LookupMusic": {"genre": "Rock"}}], "input_token_count": 2040, "output_token_count": 25, "latency": 11.995940208435059}
{"id": "live_multiple_339-133-3", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='dontcare', year='dontcare')]", "input_token_count": 2073, "output_token_count": 31, "latency": 15.16829514503479}
{"id": "live_multiple_340-133-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_341-133-5", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='Pop', year='19')]", "input_token_count": 2048, "output_token_count": 30, "latency": 13.966873407363892}
{"id": "live_multiple_342-133-6", "result": [{"Music_3_LookupMusic": {"artist": "Eric Church", "album": "Chief", "genre": "dontcare", "year": "dontcare"}}], "input_token_count": 2068, "output_token_count": 47, "latency": 23.15373396873474}
{"id": "live_multiple_343-133-7", "result": "[Music_3_LookupMusic(artist=\"Martin Garrix\", genre=\"dontcare\", year=\"dontcare\")]", "input_token_count": 2067, "output_token_count": 27, "latency": 12.578282594680786}
{"id": "live_multiple_344-133-8", "result": "[Music_3_LookupMusic(artist=\"dontcare\", album=\"Prequelle\", genre=\"dontcare\", year=\"dontcare\")]", "input_token_count": 2053, "output_token_count": 32, "latency": 15.156646490097046}
{"id": "live_multiple_345-133-9", "result": [{"Music_3_LookupMusic": {"genre": "Pop", "artist": "Kesha", "album": "Rainbow"}}], "input_token_count": 2067, "output_token_count": 40, "latency": 17.731435775756836}
{"id": "live_multiple_346-133-10", "result": "[Music_3_LookupMusic(artist='Justin Bieber', year=2013)]", "input_token_count": 2062, "output_token_count": 22, "latency": 7.826585054397583}
{"id": "live_multiple_347-133-11", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_348-133-12", "result": "[Music_3_LookupMusic(artist='Meghan Trainor', year=2018, genre='Pop')]", "input_token_count": 2049, "output_token_count": 29, "latency": 11.589154958724976}
{"id": "live_multiple_349-133-13", "result": [{"Music_3_LookupMusic": {"artist": "Vybz Kartel", "genre": "Reggae", "year": 2019}}], "input_token_count": 2046, "output_token_count": 44, "latency": 19.933586835861206}
{"id": "live_multiple_350-133-14", "result": "[Music_3_LookupMusic(artist='Jinjer', genre='Metal')]", "input_token_count": 2042, "output_token_count": 21, "latency": 7.58041787147522}
{"id": "live_multiple_351-133-15", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='dontcare', year='dontcare')]", "input_token_count": 2048, "output_token_count": 31, "latency": 13.166323184967041}
{"id": "live_multiple_352-133-16", "result": "[Music_3_LookupMusic(artist=\"Pitbull\")]", "input_token_count": 2067, "output_token_count": 17, "latency": 6.100827693939209}
{"id": "live_multiple_353-133-17", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_354-133-18", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_355-134-0", "result": [{"Movies_3_FindMovies": {"directed_by": "Herbert Ross", "cast": "Ronald Young"}}], "input_token_count": 1987, "output_token_count": 36, "latency": 16.605603218078613}
{"id": "live_multiple_356-134-1", "result": [{"Movies_3_FindMovies": {"directed_by": "Lawrence Bender", "cast": "Quentin Tarantino"}}], "input_token_count": 2011, "output_token_count": 37, "latency": 17.199806213378906}
{"id": "live_multiple_357-134-2", "result": [{"Movies_3_FindMovies": {"cast": "Ving Rhames"}}], "input_token_count": 1960, "output_token_count": 26, "latency": 11.636567831039429}
{"id": "live_multiple_358-134-3", "result": [{"Movies_3_FindMovies": {"directed_by": "Steven Spielberg", "genre": "Sci-fi", "cast": "J. Patrick McNamara"}}], "input_token_count": 2012, "output_token_count": 46, "latency": 22.59670639038086}
{"id": "live_multiple_359-134-4", "result": [{"Movies_3_FindMovies": {"directed_by": "Josh Cooley", "cast": "Bill Hader"}}], "input_token_count": 1981, "output_token_count": 35, "latency": 16.463287830352783}
{"id": "live_multiple_360-134-5", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "genre": "dontcare", "cast": "dontcare"}}], "input_token_count": 1963, "output_token_count": 41, "latency": 19.494529962539673}
{"id": "live_multiple_361-134-6", "result": [{"Movies_3_FindMovies": {"directed_by": "David Leitch", "cast": "Ryan Reynolds", "genre": "Action"}}], "input_token_count": 1993, "output_token_count": 40, "latency": 18.87370467185974}
{"id": "live_multiple_362-134-7", "result": [{"Movies_3_FindMovies": {"directed_by": "Sujeeth Reddy", "cast": "Supreet Reddy"}}], "input_token_count": 1973, "output_token_count": 38, "latency": 17.680482149124146}
{"id": "live_multiple_363-134-8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_364-134-9", "result": [{"Movies_3_FindMovies": {"directed_by": "Wes Anderson", "genre": "Comedy"}}], "input_token_count": 1980, "output_token_count": 34, "latency": 15.709500312805176}
{"id": "live_multiple_365-134-10", "result": [{"Movies_3_FindMovies": {"directed_by": "Gene Stupnitsky", "cast": "Josh Barclay Caras", "genre": "Comedy"}}], "input_token_count": 1996, "output_token_count": 47, "latency": 23.949717044830322}
{"id": "live_multiple_366-134-11", "result": "[Movies_3_FindMovies(directed_by=\"Herbert Ross\")]", "input_token_count": 1964, "output_token_count": 17, "latency": 7.436089277267456}
{"id": "live_multiple_367-134-12", "result": [{"Movies_3_FindMovies": {"genre": "Action"}}], "input_token_count": 1983, "output_token_count": 23, "latency": 10.642587423324585}
{"id": "live_multiple_368-134-13", "result": [{"Movies_3_FindMovies": {"directed_by": "Peter Strickland", "cast": "Gwendoline Christie"}}], "input_token_count": 1999, "output_token_count": 37, "latency": 18.461392641067505}
{"id": "live_multiple_369-134-14", "result": [{"Movies_3_FindMovies": {"directed_by": "Peter Jackson", "genre": "Fantasy"}}], "input_token_count": 1970, "output_token_count": 33, "latency": 16.032615900039673}
{"id": "live_multiple_370-134-15", "result": [{"Movies_3_FindMovies": {"directed_by": "Jim Henson", "cast": "Danny John-Jules"}}], "input_token_count": 1996, "output_token_count": 36, "latency": 17.855031728744507}
{"id": "live_multiple_371-134-16", "result": [{"Movies_3_FindMovies": {"directed_by": "Gregory La Cava"}}], "input_token_count": 1977, "output_token_count": 29, "latency": 14.08699369430542}
{"id": "live_multiple_372-134-17", "result": "[Movies_3_FindMovies(directed_by=\"Joel Zwick\", genre=\"Comedy\")]", "input_token_count": 1985, "output_token_count": 23, "latency": 11.100509405136108}
{"id": "live_multiple_373-134-18", "result": [{"Movies_3_FindMovies": {"directed_by": "Jagan Shakti", "cast": "Sanjay Kapoor", "genre": "Action"}}], "input_token_count": 1968, "output_token_count": 44, "latency": 23.074000120162964}
{"id": "live_multiple_374-134-19", "result": [{"Movies_3_FindMovies": {"directed_by": "Riley Stearns", "cast": "C.J. Rush"}}], "input_token_count": 1989, "output_token_count": 38, "latency": 19.50529670715332}
{"id": "live_multiple_375-134-20", "result": "[Movies_3_FindMovies(directed_by=\"Sameh Zoabi\")]", "input_token_count": 1958, "output_token_count": 18, "latency": 8.965215921401978}
{"id": "live_multiple_376-135-0", "result": [{"Services_4_FindProvider": {"city": "Santa Rosa, CA", "type": "Psychologist"}}], "input_token_count": 1007, "output_token_count": 33, "latency": 16.942719221115112}
{"id": "live_multiple_377-135-1", "result": [{"Services_4_FindProvider": {"city": "Berkeley, CA", "type": "Family Counselor"}}], "input_token_count": 1008, "output_token_count": 34, "latency": 17.552218198776245}
{"id": "live_multiple_378-135-2", "result": [{"Services_4_FindProvider": {"city": "Berkeley, CA", "type": "Family Counselor"}}], "input_token_count": 1005, "output_token_count": 34, "latency": 18.21290612220764}
{"id": "live_multiple_379-136-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_380-136-1", "result": [{"Alarm_1_GetAlarms": {"user_id": "12345"}}], "input_token_count": 3888, "output_token_count": 30, "latency": 17.01611614227295}
{"id": "live_multiple_381-136-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_382-137-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_383-137-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_384-137-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_385-137-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_386-137-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_387-137-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_388-137-6", "result": [{"Services_1_FindProvider": {"city": "Alameda, CA"}}], "input_token_count": 2114, "output_token_count": 28, "latency": 15.098937273025513}
{"id": "live_multiple_389-137-7", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_390-137-8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_391-137-9", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_392-138-0", "result": "[Services_1_FindProvider(city='Austin, TX', is_unisex=True)]", "input_token_count": 1046, "output_token_count": 21, "latency": 11.235677003860474}
{"id": "live_multiple_393-138-1", "result": [{"Services_1_FindProvider": {"city": "Pinole, CA", "is_unisex": true}}], "input_token_count": 1054, "output_token_count": 34, "latency": 19.038025379180908}
{"id": "live_multiple_394-138-2", "result": [{"Services_1_FindProvider": {"city": "Berkeley, CA"}}], "input_token_count": 1049, "output_token_count": 26, "latency": 14.86199402809143}
{"id": "live_multiple_395-138-3", "result": [{"Services_1_FindProvider": {"city": "Ronald Reagan Park, TX"}}], "input_token_count": 1045, "output_token_count": 28, "latency": 16.038382530212402}
{"id": "live_multiple_396-139-0", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Chicago, IL", "date": "2023-03-10"}}], "input_token_count": 1770, "output_token_count": 48, "latency": 28.356629371643066}
{"id": "live_multiple_397-139-1", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Palo Alto, CA", "date": "2023-03-13"}}], "input_token_count": 1754, "output_token_count": 50, "latency": 29.526700973510742}
{"id": "live_multiple_398-139-2", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "San Diego, CA", "date": "2023-05-02"}}], "input_token_count": 1745, "output_token_count": 48, "latency": 28.352226734161377}
{"id": "live_multiple_399-139-3", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Chicago, IL", "date": "2023-05-02"}}], "input_token_count": 1745, "output_token_count": 48, "latency": 27.770073413848877}
{"id": "live_multiple_400-139-4", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Chicago, IL", "date": "2023-10-02"}}], "input_token_count": 1784, "output_token_count": 48, "latency": 28.3573739528656}
{"id": "live_multiple_401-139-5", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Toronto, ON", "date": "2023-10-02"}}], "input_token_count": 1770, "output_token_count": 47, "latency": 27.767319202423096}
{"id": "live_multiple_402-139-6", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "London, UK", "date": "2023-10-02"}}], "input_token_count": 1751, "output_token_count": 48, "latency": 28.93168044090271}
{"id": "live_multiple_403-139-7", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "London, UK", "date": "2024-05-05"}}], "input_token_count": 1727, "output_token_count": 48, "latency": 28.336326837539673}
{"id": "live_multiple_404-140-0", "result": "[RideSharing_2_GetRide(destination='123 Beijing Street, San Francisco', number_of_seats=1, ride_type='Regular')]", "input_token_count": 1906, "output_token_count": 36, "latency": 21.25318956375122}
{"id": "live_multiple_405-140-1", "result": "[RideSharing_2_GetRide(destination=\"123 Main St, Anytown\", number_of_seats=2, ride_type=\"Luxury\")]", "input_token_count": 1899, "output_token_count": 39, "latency": 23.014853954315186}
{"id": "live_multiple_406-140-2", "result": [{"RideSharing_2_GetRide": {"destination": "2508 Palo Alto University Avenue, California"}}], "input_token_count": 1904, "output_token_count": 37, "latency": 21.24394464492798}
{"id": "live_multiple_407-140-3", "result": [{"RideSharing_2_GetRide": {"destination": "540 El Camino Real, Berkeley", "ride_type": "Regular"}}], "input_token_count": 1892, "output_token_count": 40, "latency": 22.99129557609558}
{"id": "live_multiple_408-140-4", "result": [{"RideSharing_2_GetRide": {"destination": "123 Park Branham Apartments, San Jose", "number_of_seats": 2}}], "input_token_count": 1889, "output_token_count": 45, "latency": 25.94901728630066}
{"id": "live_multiple_409-140-5", "result": "[RideSharing_2_GetRide(destination=\"123 White Street, San Jose\", number_of_seats=1, ride_type=\"Pool\")]", "input_token_count": 1918, "output_token_count": 36, "latency": 20.624866724014282}
{"id": "live_multiple_410-140-6", "result": [{"RideSharing_2_GetRide": {"destination": "3236 Oakland Street, Chicago", "ride_type": "Luxury"}}], "input_token_count": 1940, "output_token_count": 43, "latency": 24.75294041633606}
{"id": "live_multiple_411-141-0", "result": "[Movies_1_FindMovies(location=\"Union City, CA\", genre=\"Animation\", show_type=\"imax\")]", "input_token_count": 2100, "output_token_count": 26, "latency": 15.590990781784058}
{"id": "live_multiple_412-141-1", "result": "[Movies_1_BuyMovieTickets(movie_name=\"\u5927\u5192\u96aa\", number_of_tickets=2, location=\"Santa Rosa, CA\", show_date=\"2023-11-15\", show_time=\"17:30\")]", "input_token_count": 2139, "output_token_count": 56, "latency": 33.995654344558716}
{"id": "live_multiple_413-141-2", "result": "[Movies_1_BuyMovieTickets(movie_name=\"\u5a5a\u79ae\u7d50\u675f\u5f8c\", number_of_tickets=2, location=\"Berkeley, CA\", show_date=\"2023-04-22\", show_time=\"19:00\")]", "input_token_count": 2128, "output_token_count": 57, "latency": 34.759315729141235}
{"id": "live_multiple_414-141-3", "result": "[Movies_1_FindMovies(location=\"Newark, NJ\")]", "input_token_count": 2125, "output_token_count": 16, "latency": 10.400066614151001}
{"id": "live_multiple_415-141-4", "result": "[Movies_1_BuyMovieTickets(movie_name=\"\u592a\u7a7a\u5192\u96aa\", number_of_tickets=2, location=\"\u8056\u4f55\u585e, \u52a0\u5229\u798f\u5c3c\u4e9e\u5dde\", show_date=\"2023-10-02\", show_time=\"23:00\", show_type=\"regular\")]", "input_token_count": 2133, "output_token_count": 68, "latency": 39.71421718597412}
{"id": "live_multiple_416-141-5", "result": "[Movies_1_FindMovies(location=\"Hillsborough, CA\", show_type=\"3d\")]", "input_token_count": 2116, "output_token_count": 23, "latency": 13.932355403900146}
{"id": "live_multiple_417-141-6", "result": "[Movies_1_FindMovies(location=\"San Jose, CA\")]", "input_token_count": 2090, "output_token_count": 16, "latency": 9.781394958496094}
{"id": "live_multiple_418-141-7", "result": "[Movies_1_BuyMovieTickets(movie_name=\"\u592a\u7a7a\u5192\u96aa\", number_of_tickets=2, location=\"New York, NY\", show_date=\"2023-04-15\", show_time=\"19:30\", show_type=\"regular\")]", "input_token_count": 2122, "output_token_count": 62, "latency": 36.09393858909607}
{"id": "live_multiple_419-141-8", "result": "[Movies_1_FindMovies(location=\"San Ramon, CA\", theater_name=\"Regal Crow Canyon\", genre=\"dontcare\", show_type=\"regular\")]", "input_token_count": 2122, "output_token_count": 34, "latency": 19.823994398117065}
{"id": "live_multiple_420-141-9", "result": "[Movies_1_BuyMovieTickets(movie_name=\"\u5fa9\u4ec7\u8005\u806f\u76df\", number_of_tickets=3, location=\"Los Angeles, CA\", show_date=\"2023-10-06\", show_time=\"19:00\", show_type=\"regular\")]", "input_token_count": 2132, "output_token_count": 62, "latency": 35.9568989276886}
{"id": "live_multiple_421-141-10", "result": [{"Movies_1_FindMovies": {"location": "Mountain View, CA"}}], "input_token_count": 2101, "output_token_count": 28, "latency": 16.26500654220581}
{"id": "live_multiple_422-141-11", "result": "[Movies_1_FindMovies(location=\"Santa Rosa\", genre=\"Animation\", show_type=\"imax\")]", "input_token_count": 2122, "output_token_count": 24, "latency": 14.502792835235596}
{"id": "live_multiple_423-141-12", "result": "[Movies_1_FindMovies(location=\"San Francisco, CA\", genre=\"Action\", show_type=\"regular\")]", "input_token_count": 2119, "output_token_count": 25, "latency": 15.088438272476196}
{"id": "live_multiple_424-141-13", "result": "[Movies_1_FindMovies(location=\"San Francisco, CA\", theater_name=\"Century Tanforan\", genre=\"Sci-fi\", show_type=\"3d\")]", "input_token_count": 2110, "output_token_count": 37, "latency": 21.60721445083618}
{"id": "live_multiple_425-141-14", "result": "[Movies_1_GetTimesForMovie(movie_name=\"AD Astra\", location=\"Berkeley, CA\", show_date=\"2023-10-15\", show_type=\"regular\")]", "input_token_count": 2112, "output_token_count": 42, "latency": 24.566123485565186}
{"id": "live_multiple_426-141-15", "result": "[Movies_1_FindMovies(location=\"Hayward, CA\", genre=\"Sci-fi\")]", "input_token_count": 2125, "output_token_count": 22, "latency": 13.335570096969604}
{"id": "live_multiple_427-141-16", "result": "[Movies_1_FindMovies(location=\"Oakland, CA\", genre=\"Drama\", show_type=\"regular\")]", "input_token_count": 2147, "output_token_count": 27, "latency": 15.69574761390686}
{"id": "live_multiple_428-141-17", "result": "[Movies_1_FindMovies(location=\"Berkeley, CA\", genre=\"Sci-fi\", show_type=\"imax\")]", "input_token_count": 2127, "output_token_count": 28, "latency": 16.882859468460083}
{"id": "live_multiple_429-141-18", "result": "[Movies_1_BuyMovieTickets(movie_name=\"\u73a9\u5177\u6545\u4e8b4\", number_of_tickets=4, location=\"Los Angeles, CA\", show_date=\"2023-06-15\", show_time=\"14:00\")]", "input_token_count": 2124, "output_token_count": 56, "latency": 33.41804218292236}
{"id": "live_multiple_430-141-19", "result": "[Movies_1_BuyMovieTickets(movie_name=\"\u6c38\u6046\u6230\u58eb\", number_of_tickets=3, location=\"Los Angeles, CA\", show_date=\"2023-04-15\", show_time=\"19:00\")]", "input_token_count": 2133, "output_token_count": 56, "latency": 33.411401987075806}
{"id": "live_multiple_431-141-20", "result": [{"Movies_1_FindMovies": {"location": "Danville, CA"}}], "input_token_count": 2121, "output_token_count": 27, "latency": 16.10952091217041}
{"id": "live_multiple_432-141-21", "result": "[Movies_1_GetTimesForMovie(movie_name=\"\u66fe\u7d93\u5728\u597d\u840a\u5862\u7684\u4e00\u6b21\", location=\"Los Angeles, CA\", show_date=\"2023-04-15\", show_time=\"19:00\")]", "input_token_count": 2128, "output_token_count": 53, "latency": 31.598815441131592}
{"id": "live_multiple_433-141-22", "result": "[Movies_1_FindMovies(location=\"Napa, CA\", theater_name=\"Century Napa Valley\", show_type=\"3d\"), Movies_1_FindMovies(location=\"Napa, CA\", theater_name=\"XD\", show_type=\"3d\")]", "input_token_count": 2117, "output_token_count": 56, "latency": 33.40854334831238}
{"id": "live_multiple_434-142-0", "result": "[RentalCars_3_GetCarsAvailable(city=\"Los Angeles, CA\", start_date=\"2023-03-09\", pickup_time=\"09:00\", end_date=\"2023-03-10\", car_type=\"Sedan\")]", "input_token_count": 4775, "output_token_count": 62, "latency": 37.119300365448}
{"id": "live_multiple_435-142-1", "result": "[RentalCars_3_GetCarsAvailable(city=\"Los Angeles, CA\", start_date=\"2023-04-21\", pickup_time=\"10:00\", end_date=\"2023-04-25\", car_type=\"Sedan\")]", "input_token_count": 4774, "output_token_count": 62, "latency": 37.10932445526123}
{"id": "live_multiple_436-142-2", "result": "[RentalCars_3_GetCarsAvailable(city=\"Portland, OR\", start_date=\"2023-04-22\", pickup_time=\"10:00\", end_date=\"2023-04-27\")]", "input_token_count": 4762, "output_token_count": 56, "latency": 33.84664273262024}
{"id": "live_multiple_437-142-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_438-142-4", "result": "[RentalCars_3_GetCarsAvailable(city=\"Los Angeles, CA\", start_date=\"2023-04-24\", pickup_time=\"10:00\", end_date=\"2023-04-28\")]", "input_token_count": 4792, "output_token_count": 56, "latency": 35.21897292137146}
{"id": "live_multiple_439-143-0", "result": "[Trains_1_FindTrains(_from='Sacramento, CA', to='Fresno, CA', date_of_journey='2023-03-10')]", "input_token_count": 2958, "output_token_count": 44, "latency": 27.197551012039185}
{"id": "live_multiple_440-144-0", "result": "[Services_4_FindProvider(city='Berkeley, CA', type='Psychologist')]", "input_token_count": 3329, "output_token_count": 22, "latency": 15.912164688110352}
{"id": "live_multiple_441-144-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_442-144-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_443-144-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_444-144-4", "result": [{"Services_4_FindProvider": {"city": "Los Gatos, CA", "type": "Family Counselor"}}], "input_token_count": 3340, "output_token_count": 36, "latency": 23.206077814102173}
{"id": "live_multiple_445-144-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_446-144-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_447-144-7", "result": "[Services_4_FindProvider(city='Novato, CA', type='Psychologist')]", "input_token_count": 3331, "output_token_count": 22, "latency": 14.89656114578247}
{"id": "live_multiple_448-144-8", "result": [{"Services_4_FindProvider": {"city": "St. Helena, CA", "type": "Family Counselor"}}], "input_token_count": 3339, "output_token_count": 36, "latency": 26.77206802368164}
{"id": "live_multiple_449-145-0", "result": "[Flights_4_SearchRoundtripFlights(origin_airport='JFK', destination_airport='LAX', departure_date='2023-04-15', return_date='2023-04-22', seating_class='Business', number_of_tickets=1, airlines='dontcare')]", "input_token_count": 3795, "output_token_count": 76, "latency": 40.82884931564331}
{"id": "live_multiple_450-145-1", "result": "[Travel_1_FindAttractions(location=\"Paris, France\", good_for_kids=\"True\")]", "input_token_count": 3772, "output_token_count": 24, "latency": 19.59494972229004}
{"id": "live_multiple_451-145-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_452-145-3", "result": "[Travel_1_FindAttractions(location=\"New York, NY\", free_entry=\"True\", good_for_kids=\"True\")]", "input_token_count": 3795, "output_token_count": 30, "latency": 22.00307321548462}
{"id": "live_multiple_453-145-4", "result": "[Travel_1_FindAttractions(location='San Francisco, CA', free_entry='True', good_for_kids='True')]", "input_token_count": 3799, "output_token_count": 30, "latency": 23.176381826400757}
{"id": "live_multiple_454-145-5", "result": "[Travel_1_FindAttractions(location=\"London, UK\", free_entry=\"True\", good_for_kids=\"True\")]", "input_token_count": 3827, "output_token_count": 29, "latency": 22.59026336669922}
{"id": "live_multiple_455-145-6", "result": "[Travel_1_FindAttractions(location=\"London, UK\", free_entry=\"True\", category=\"dontcare\", good_for_kids=\"dontcare\")]", "input_token_count": 3810, "output_token_count": 35, "latency": 27.381595849990845}
{"id": "live_multiple_456-145-7", "result": "[Travel_1_FindAttractions(location='London, UK', free_entry='True', category='dontcare', good_for_kids='dontcare')]", "input_token_count": 3789, "output_token_count": 35, "latency": 27.99547004699707}
{"id": "live_multiple_457-145-8", "result": "[Travel_1_FindAttractions(location=\"Paris, France\", good_for_kids=\"True\")]", "input_token_count": 3805, "output_token_count": 24, "latency": 21.393192529678345}
{"id": "live_multiple_458-145-9", "result": "[Travel_1_FindAttractions(location=\"Paris, France\", free_entry=\"True\", good_for_kids=\"True\")]", "input_token_count": 3852, "output_token_count": 29, "latency": 24.970932006835938}
{"id": "live_multiple_459-145-10", "result": "[Travel_1_FindAttractions(location=\"Berlin, Germany\", free_entry=\"True\", good_for_kids=\"True\")]", "input_token_count": 3833, "output_token_count": 29, "latency": 25.559957265853882}
{"id": "live_multiple_460-145-11", "result": "[Travel_1_FindAttractions(location='New York, NY', free_entry='True', good_for_kids='True')]", "input_token_count": 3794, "output_token_count": 30, "latency": 26.182781219482422}
{"id": "live_multiple_461-145-12", "result": "[Travel_1_FindAttractions(location=\"Paris, France\", free_entry=\"True\", category=\"Shopping Area\", good_for_kids=\"True\")]", "input_token_count": 3794, "output_token_count": 34, "latency": 31.13711714744568}
{"id": "live_multiple_462-145-13", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_463-145-14", "result": "[Travel_1_FindAttractions(location=\"Philadelphia, PA\", free_entry=\"True\")]", "input_token_count": 3807, "output_token_count": 22, "latency": 23.111926078796387}
{"id": "live_multiple_464-145-15", "result": "[Travel_1_FindAttractions(location=\"Orlando, FL\", free_entry=\"True\", good_for_kids=\"True\", category=\"Theme Park\")]", "input_token_count": 3809, "output_token_count": 35, "latency": 31.153409004211426}
{"id": "live_multiple_465-145-16", "result": "[Flights_4_SearchOnewayFlight(origin_airport='JFK', destination_airport='LAX', departure_date='2023-10-06', seating_class='Economy', number_of_tickets=1, airlines='dontcare')]", "input_token_count": 3789, "output_token_count": 62, "latency": 40.33580803871155}
{"id": "live_multiple_466-145-17", "result": "[Travel_1_FindAttractions(location='New York, NY', free_entry='True', good_for_kids='True', category='Shopping Area')]", "input_token_count": 3791, "output_token_count": 35, "latency": 32.349825382232666}
{"id": "live_multiple_467-145-18", "result": "[Travel_1_FindAttractions(location='Portland, OR', free_entry='False', category='Historical Landmark', good_for_kids='True')]", "input_token_count": 3819, "output_token_count": 37, "latency": 34.18840956687927}
{"id": "live_multiple_468-145-19", "result": "[Travel_1_FindAttractions(location=\"Seattle, WA\", good_for_kids=\"True\")]", "input_token_count": 3812, "output_token_count": 25, "latency": 28.09495973587036}
{"id": "live_multiple_469-145-20", "result": "[Travel_1_FindAttractions(location='Toronto, Ontario', good_for_kids='True', free_entry='dontcare')]", "input_token_count": 3796, "output_token_count": 30, "latency": 31.12445092201233}
{"id": "live_multiple_470-145-21", "result": "[Travel_1_FindAttractions(location=\"Paris, France\", free_entry=\"True\", good_for_kids=\"True\")]", "input_token_count": 3787, "output_token_count": 29, "latency": 30.520816326141357}
{"id": "live_multiple_471-145-22", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_472-145-23", "result": "[Travel_1_FindAttractions(location=\"Chicago, IL\", good_for_kids=\"True\")]", "input_token_count": 3796, "output_token_count": 24, "latency": 27.363232851028442}
{"id": "live_multiple_473-145-24", "result": "[Travel_1_FindAttractions(location='New York, NY', free_entry='True', category='Museum')]", "input_token_count": 3795, "output_token_count": 28, "latency": 29.356504440307617}
{"id": "live_multiple_474-145-25", "result": "[Travel_1_FindAttractions(location='Paris, France', free_entry='True', category='Museum', good_for_kids='True')]", "input_token_count": 3792, "output_token_count": 34, "latency": 33.144822120666504}
{"id": "live_multiple_475-146-0", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='Electropop', year='2019')]", "input_token_count": 1459, "output_token_count": 34, "latency": 33.167853593826294}
{"id": "live_multiple_476-146-1", "result": "[Music_3_LookupMusic(genre='Electropop', year='2014')]", "input_token_count": 1465, "output_token_count": 24, "latency": 27.506604194641113}
{"id": "live_multiple_477-146-2", "result": "[Music_3_LookupMusic(artist='dontcare', album='\u6211\u5011\u4e0d\u662f\u4f60\u7684\u90a3\u6a23', genre='Rock', year='2019')]", "input_token_count": 1488, "output_token_count": 38, "latency": 34.534372329711914}
{"id": "live_multiple_478-146-3", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='dontcare', year='2021')]", "input_token_count": 1494, "output_token_count": 33, "latency": 33.13512182235718}
{"id": "live_multiple_479-146-4", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='Electropop', year='2014')]", "input_token_count": 1474, "output_token_count": 34, "latency": 33.27655744552612}
{"id": "live_multiple_480-146-5", "result": "[Music_3_PlayMedia(track=\"\u6211\u6700\u559c\u6b61\u7684\u590f\u5b63\u6c1b\u570d\", artist=\"DJ Sunny\", device=\"Kitchen\")]", "input_token_count": 1476, "output_token_count": 35, "latency": 32.933212757110596}
{"id": "live_multiple_481-146-6", "result": "[Music_3_LookupMusic(artist='dontcare', album='\u9ad8\u671f\u671b', year='2019', genre='dontcare')]", "input_token_count": 1469, "output_token_count": 34, "latency": 32.73279094696045}
{"id": "live_multiple_482-146-7", "result": "[Music_3_LookupMusic(genre=\"Reggae\", year=\"dontcare\")]", "input_token_count": 1458, "output_token_count": 21, "latency": 25.595622777938843}
{"id": "live_multiple_483-146-8", "result": "[Music_3_LookupMusic(artist=\"Sia\", genre=\"Pop\", year=\"dontcare\")]", "input_token_count": 1504, "output_token_count": 25, "latency": 27.557400226593018}
{"id": "live_multiple_484-146-9", "result": "[Music_3_LookupMusic(artist='dontcare', album='\u65b0\u7d93\u5178', year='2017')]", "input_token_count": 1481, "output_token_count": 29, "latency": 29.958431243896484}
{"id": "live_multiple_485-147-0", "result": "[Trains_1_FindTrains(_from='New York, NY', to='Los Angeles, CA', date_of_journey='04/25/2023')]", "input_token_count": 4635, "output_token_count": 43, "latency": 34.26641845703125}
{"id": "live_multiple_486-147-1", "result": "[Trains_1_GetTrainTickets(_from='New York, NY', to='Los Angeles, CA', date_of_journey='04/23/2023', journey_start_time='10:00', number_of_adults=2, trip_protection=False, _class='Business')]", "input_token_count": 4665, "output_token_count": 70, "latency": 40.43457078933716}
{"id": "live_multiple_487-147-2", "result": "[Trains_1_GetTrainTickets(_from='New York, NY', to='Sacramento, CA', date_of_journey='03/13/2023', journey_start_time='13:45', number_of_adults=2, trip_protection=True, _class='Business')]", "input_token_count": 4650, "output_token_count": 70, "latency": 39.864495515823364}
{"id": "live_multiple_488-147-3", "result": "[Trains_1_FindTrains(_from=\"Portland, OR\", to=\"Seattle, WA\", date_of_journey=\"04/22/2023\", _class=\"Value\", number_of_adults=1)]", "input_token_count": 4644, "output_token_count": 55, "latency": 36.583343267440796}
{"id": "live_multiple_489-147-4", "result": "[Trains_1_GetTrainTickets(_from='New York, NY', to='Phoenix, AZ', date_of_journey='04/23/2023', journey_start_time='13:45', number_of_adults=1, trip_protection=False)]", "input_token_count": 4664, "output_token_count": 64, "latency": 38.47093224525452}
{"id": "live_multiple_490-148-0", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Chicago, IL", "date": "2023-04-29"}}], "input_token_count": 2046, "output_token_count": 48, "latency": 34.52263283729553}
{"id": "live_multiple_491-148-1", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Berkeley, CA", "date": "2023-05-12"}}], "input_token_count": 2039, "output_token_count": 48, "latency": 33.93271350860596}
{"id": "live_multiple_492-148-2", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Berkeley, CA", "date": "2023-03-10"}}], "input_token_count": 2052, "output_token_count": 48, "latency": 33.87917375564575}
{"id": "live_multiple_493-148-3", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "2023-04-15"}}], "input_token_count": 2048, "output_token_count": 49, "latency": 34.07852864265442}
{"id": "live_multiple_494-148-4", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-04-15"}}], "input_token_count": 2051, "output_token_count": 48, "latency": 33.29506802558899}
{"id": "live_multiple_495-148-5", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-10-05"}}], "input_token_count": 2045, "output_token_count": 48, "latency": 33.28767442703247}
{"id": "live_multiple_496-148-6", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-03-25"}}], "input_token_count": 2044, "output_token_count": 48, "latency": 32.71199655532837}
{"id": "live_multiple_497-148-7", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Oakland, CA", "date": "2023-04-11"}}], "input_token_count": 2050, "output_token_count": 50, "latency": 33.507439613342285}
{"id": "live_multiple_498-148-8", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-03-01"}}], "input_token_count": 2035, "output_token_count": 48, "latency": 32.7001678943634}
{"id": "live_multiple_499-148-9", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-03-09"}}], "input_token_count": 2058, "output_token_count": 48, "latency": 32.126973390579224}
{"id": "live_multiple_500-148-10", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "San Francisco, CA"}}], "input_token_count": 2036, "output_token_count": 33, "latency": 27.90927028656006}
{"id": "live_multiple_501-148-11", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "San Francisco, CA", "date": "2023-10-01"}}], "input_token_count": 2082, "output_token_count": 49, "latency": 31.144538164138794}
{"id": "live_multiple_502-148-12", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "2024-03-12"}}], "input_token_count": 2040, "output_token_count": 49, "latency": 30.5468692779541}
{"id": "live_multiple_503-149-0", "result": [{"Flights_4_SearchOnewayFlight": {"origin_airport": "JFK", "destination_airport": "LAX", "departure_date": "2023-04-15", "seating_class": "Premium Economy"}}], "input_token_count": 3440, "output_token_count": 68, "latency": 36.41155743598938}
{"id": "live_multiple_504-149-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_505-149-2", "result": [{"Flights_4_SearchOnewayFlight": {"origin_airport": "SFO", "destination_airport": "ORD", "departure_date": "2023-05-20", "seating_class": "Business", "airlines": "American Airlines"}}], "input_token_count": 3497, "output_token_count": 73, "latency": 37.58741807937622}
{"id": "live_multiple_506-149-3", "result": [{"Flights_4_SearchOnewayFlight": {"origin_airport": "JFK", "destination_airport": "LAX", "departure_date": "2023-04-15"}}], "input_token_count": 3468, "output_token_count": 58, "latency": 32.835148096084595}
{"id": "live_multiple_507-149-4", "result": [{"Flights_4_SearchOnewayFlight": {"origin_airport": "LAX", "destination_airport": "JFK", "departure_date": "2023-03-14", "seating_class": "Economy"}}], "input_token_count": 3474, "output_token_count": 68, "latency": 35.593655586242676}
{"id": "live_multiple_508-149-5", "result": [{"Flights_4_SearchOnewayFlight": {"origin_airport": "JFK", "destination_airport": "LAX", "departure_date": "2023-04-15"}}], "input_token_count": 3482, "output_token_count": 58, "latency": 32.23199534416199}
{"id": "live_multiple_509-149-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_510-149-7", "result": [{"Flights_4_SearchOnewayFlight": {"origin_airport": "JFK", "destination_airport": "PDX", "departure_date": "2023-04-20"}}], "input_token_count": 3486, "output_token_count": 58, "latency": 31.67264461517334}
{"id": "live_multiple_511-149-8", "result": [{"Flights_4_SearchOnewayFlight": {"origin_airport": "Chicago", "destination_airport": "Shanghai", "departure_date": "2023-04-15", "airlines": "Delta Airlines"}}], "input_token_count": 3487, "output_token_count": 64, "latency": 33.50798535346985}
{"id": "live_multiple_512-150-0", "result": "[Movies_1_FindMovies(location=\"Los Angeles, CA\", show_type=\"3d\")]", "input_token_count": 3468, "output_token_count": 22, "latency": 22.710417985916138}
{"id": "live_multiple_513-150-1", "result": "[Movies_1_FindMovies(location=\"New York, NY\", genre=\"Action\")]", "input_token_count": 3452, "output_token_count": 20, "latency": 20.488720417022705}
{"id": "live_multiple_514-150-2", "result": "[Movies_1_FindMovies(location=\"San Jose, CA\", genre=\"dontcare\", show_type=\"dontcare\")]", "input_token_count": 3461, "output_token_count": 27, "latency": 21.997347593307495}
{"id": "live_multiple_515-150-3", "result": "[Movies_1_FindMovies(location=\"San Jose, CA\", theater_name=\"West Wind Capitol Drive-In Theatre\", genre=\"Horror\")]", "input_token_count": 3469, "output_token_count": 31, "latency": 22.551077127456665}
{"id": "live_multiple_516-150-4", "result": "[Movies_1_FindMovies(location=\"San Ramon, CA\", show_type=\"imax\")]", "input_token_count": 3461, "output_token_count": 22, "latency": 20.91364622116089}
{"id": "live_multiple_517-150-5", "result": [{"Movies_1_FindMovies": {"location": "Los Angeles, CA", "genre": "Supernatural"}}], "input_token_count": 3462, "output_token_count": 34, "latency": 22.964126586914062}
{"id": "live_multiple_518-150-6", "result": [{"Movies_1_FindMovies": {"location": "Sonoma, CA", "genre": "Action"}}], "input_token_count": 3467, "output_token_count": 33, "latency": 22.244821071624756}
{"id": "live_multiple_519-150-7", "result": "[Movies_1_FindMovies(location=\"Los Angeles, CA\", genre=\"Documentary\")]", "input_token_count": 3462, "output_token_count": 21, "latency": 19.90138339996338}
{"id": "live_multiple_520-150-8", "result": "[Movies_1_FindMovies(location=\"Saratoga, CA\", genre=\"dontcare\", show_type=\"dontcare\")]", "input_token_count": 3476, "output_token_count": 28, "latency": 20.96711826324463}
{"id": "live_multiple_521-150-9", "result": "[Movies_1_FindMovies(location=\"Sonoma, CA\", genre=\"Family\", show_type=\"3d\")]", "input_token_count": 3468, "output_token_count": 26, "latency": 20.677470922470093}
{"id": "live_multiple_522-150-10", "result": "[Movies_1_FindMovies(location=\"Larkspur\", genre=\"Action\")]", "input_token_count": 3484, "output_token_count": 19, "latency": 18.133376836776733}
{"id": "live_multiple_523-150-11", "result": "[Movies_1_FindMovies(location=\"San Jose, CA\", genre=\"War\")]", "input_token_count": 3462, "output_token_count": 20, "latency": 18.732673168182373}
{"id": "live_multiple_524-151-0", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Chicago, IL"}}], "input_token_count": 1181, "output_token_count": 33, "latency": 21.383343935012817}
{"id": "live_multiple_525-151-1", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Toronto, ON", "date": "2023-05-01"}}], "input_token_count": 1206, "output_token_count": 47, "latency": 24.719911575317383}
{"id": "live_multiple_526-151-2", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "San Diego, CA", "date": "05/05/2023"}}], "input_token_count": 1194, "output_token_count": 48, "latency": 24.855475902557373}
{"id": "live_multiple_527-151-3", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "\u897f\u96c5\u5716, WA", "date": "05/15/2023"}}], "input_token_count": 1189, "output_token_count": 51, "latency": 24.850162506103516}
{"id": "live_multiple_528-151-4", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "dontcare"}}], "input_token_count": 1191, "output_token_count": 41, "latency": 22.37574601173401}
{"id": "live_multiple_529-151-5", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Los Angeles, CA", "date": "04/07/2010"}}], "input_token_count": 1186, "output_token_count": 48, "latency": 23.056726694107056}
{"id": "live_multiple_530-151-6", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "09/09/2023"}}], "input_token_count": 1192, "output_token_count": 48, "latency": 23.0560085773468}
{"id": "live_multiple_531-151-7", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Philadelphia, PA"}}], "input_token_count": 1185, "output_token_count": 32, "latency": 18.973395586013794}
{"id": "live_multiple_532-151-8", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Portland, OR"}}], "input_token_count": 1182, "output_token_count": 33, "latency": 19.459973573684692}
{"id": "live_multiple_533-151-9", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "London, UK"}}], "input_token_count": 1174, "output_token_count": 33, "latency": 18.885963201522827}
{"id": "live_multiple_534-151-10", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Livermore, CA", "date": "03/06/2023"}}], "input_token_count": 1202, "output_token_count": 50, "latency": 22.60897970199585}
{"id": "live_multiple_535-151-11", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Belvedere, CA"}}], "input_token_count": 1197, "output_token_count": 34, "latency": 18.46016573905945}
{"id": "live_multiple_536-151-12", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Portland, OR", "date": "03/09/2023"}}], "input_token_count": 1213, "output_token_count": 48, "latency": 19.522058486938477}
{"id": "live_multiple_537-151-13", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Chicago, IL"}}], "input_token_count": 1186, "output_token_count": 32, "latency": 15.41581392288208}
{"id": "live_multiple_538-152-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_539-152-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_540-152-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_541-152-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_542-152-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_543-152-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_544-152-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_545-152-7", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_546-152-8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_547-152-9", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_548-152-10", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_549-152-11", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_550-152-12", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_551-153-0", "result": [{"Services_1_FindProvider": {"city": "Berkeley, CA"}}], "input_token_count": 1852, "output_token_count": 26, "latency": 9.681828260421753}
{"id": "live_multiple_552-153-1", "result": [{"Services_1_FindProvider": {"city": "Walnut Creek, CA", "is_unisex": "True"}}], "input_token_count": 1875, "output_token_count": 36, "latency": 12.64994215965271}
{"id": "live_multiple_553-153-2", "result": [{"Services_1_FindProvider": {"city": "San Francisco, CA"}}], "input_token_count": 1861, "output_token_count": 26, "latency": 9.807496309280396}
{"id": "live_multiple_554-154-0", "result": "[RentalCars_3_GetCarsAvailable(city=\"London\", start_date=\"2024-03-10\", pickup_time=\"12:00\", end_date=\"2024-03-17\", car_type=\"dontcare\")]", "input_token_count": 2457, "output_token_count": 59, "latency": 19.581287622451782}
{"id": "live_multiple_555-154-1", "result": "[RentalCars_3_GetCarsAvailable(city=\"Los Angeles, CA\", start_date=\"2023-04-14\", pickup_time=\"10:00\", end_date=\"2023-04-18\")]", "input_token_count": 2481, "output_token_count": 56, "latency": 18.76180148124695}
{"id": "live_multiple_556-154-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_557-154-3", "result": "[RentalCars_3_GetCarsAvailable(city=\"Los Angeles, CA\", start_date=\"2023-04-18\", pickup_time=\"10:00\", end_date=\"2023-04-24\")]", "input_token_count": 2459, "output_token_count": 56, "latency": 17.538448095321655}
{"id": "live_multiple_558-154-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_559-154-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_560-155-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_561-155-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_562-155-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_563-155-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_564-155-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_565-155-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_566-155-6", "result": "[Hotels_2_SearchHouse(where_to='Sacramento, CA')]", "input_token_count": 3648, "output_token_count": 19, "latency": 6.219306230545044}
{"id": "live_multiple_567-155-7", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_568-155-8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_569-155-9", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_570-155-10", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_571-155-11", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_572-155-12", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_573-155-13", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_574-156-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_575-156-1", "result": [{"Services_1_FindProvider": {"city": "Santa Rosa, CA"}}], "input_token_count": 2926, "output_token_count": 26, "latency": 6.753604173660278}
{"id": "live_multiple_576-156-2", "result": [{"Services_1_FindProvider": {"city": "Berkeley, CA", "is_unisex": true}}], "input_token_count": 2925, "output_token_count": 34, "latency": 8.639413118362427}
{"id": "live_multiple_577-156-3", "result": [{"Services_1_FindProvider": {"city": "New York, NY"}}], "input_token_count": 2915, "output_token_count": 27, "latency": 6.877359390258789}
{"id": "live_multiple_578-156-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_579-157-0", "result": "[Media_3_FindMovies(genre=\"Comedy\", starring=\"Jim Carrey\")]", "input_token_count": 1367, "output_token_count": 21, "latency": 5.300241947174072}
{"id": "live_multiple_580-157-1", "result": [{"Media_3_FindMovies": {"genre": "Comedy", "starring": "Vanessa Przada"}}], "input_token_count": 1365, "output_token_count": 34, "latency": 7.9000084400177}
{"id": "live_multiple_581-157-2", "result": "[Media_3_FindMovies(genre=\"Sci-fi\")]", "input_token_count": 1353, "output_token_count": 16, "latency": 3.6861746311187744}
{"id": "live_multiple_582-157-3", "result": "[Media_3_FindMovies(genre=\"Comedy\", starring=\"Jim Carrey\")]", "input_token_count": 1361, "output_token_count": 21, "latency": 5.006452560424805}
{"id": "live_multiple_583-157-4", "result": "[Media_3_FindMovies(genre=\"Fantasy\", starring=\"Brett McKenzie\")]", "input_token_count": 1369, "output_token_count": 22, "latency": 5.125490665435791}
{"id": "live_multiple_584-157-5", "result": "[Media_3_FindMovies(genre=\"Sci-fi\", starring=\"Chris Hemsworth or Zoe Saldana\")]", "input_token_count": 1381, "output_token_count": 28, "latency": 5.9377264976501465}
{"id": "live_multiple_585-157-6", "result": "[Media_3_FindMovies(genre=\"Action\", starring=\"Bruce Willis\")]", "input_token_count": 1366, "output_token_count": 19, "latency": 4.6192755699157715}
{"id": "live_multiple_586-157-7", "result": "[Media_3_FindMovies(genre=\"Fantasy\", starring=\"Timothy Bateson\")]", "input_token_count": 1367, "output_token_count": 22, "latency": 5.063685655593872}
{"id": "live_multiple_587-157-8", "result": "[Media_3_FindMovies(genre=\"Horror\", starring=\"Christopher Lee\")]", "input_token_count": 1357, "output_token_count": 20, "latency": 4.775487661361694}
{"id": "live_multiple_588-157-9", "result": "[Media_3_FindMovies(genre=\"Horror\", starring=\"Arthur Lowe\")]", "input_token_count": 1358, "output_token_count": 20, "latency": 4.774629592895508}
{"id": "live_multiple_589-157-10", "result": [{"Media_3_FindMovies": {"genre": "Sci-fi", "starring": "Bobby Nish"}}], "input_token_count": 1359, "output_token_count": 34, "latency": 9.493756771087646}
{"id": "live_multiple_590-157-11", "result": "[Media_3_FindMovies(genre=\"Animation\", starring=\"Christina-Ann Zalamea\")]", "input_token_count": 1386, "output_token_count": 25, "latency": 6.340856552124023}
{"id": "live_multiple_591-157-12", "result": "[Media_3_FindMovies(genre=\"Drama\", starring=\"Dan Bittner\")]", "input_token_count": 1373, "output_token_count": 22, "latency": 5.834389686584473}
{"id": "live_multiple_592-157-13", "result": "[Media_3_FindMovies(genre=\"Offbeat\", starring=\"Inbal Amirav\")]", "input_token_count": 1369, "output_token_count": 22, "latency": 5.843562841415405}
{"id": "live_multiple_593-157-14", "result": "[Media_3_FindMovies(genre=\"Comedy\", starring=\"Ellise Chappell\")]", "input_token_count": 1357, "output_token_count": 23, "latency": 6.046766757965088}
{"id": "live_multiple_594-158-0", "result": "[Hotels_4_SearchHotel(location=\"London, UK\", smoking_allowed=False)]", "input_token_count": 1463, "output_token_count": 20, "latency": 5.562962532043457}
{"id": "live_multiple_595-158-1", "result": "[Hotels_4_SearchHotel(location='New York, NY', star_rating='3', smoking_allowed=True, number_of_rooms='2')]", "input_token_count": 1444, "output_token_count": 34, "latency": 10.473215103149414}
{"id": "live_multiple_596-158-2", "result": "[Hotels_4_SearchHotel(location='San Francisco, CA', number_of_rooms='1')]", "input_token_count": 1441, "output_token_count": 24, "latency": 6.190534591674805}
{"id": "live_multiple_597-158-3", "result": "[Hotels_4_SearchHotel(location=\"Toronto, ON\", star_rating=\"4\", number_of_rooms=\"1\")]", "input_token_count": 1431, "output_token_count": 28, "latency": 8.542524814605713}
{"id": "live_multiple_598-158-4", "result": "[Hotels_4_SearchHotel(location=\"Washington, DC\", star_rating=\"dontcare\", smoking_allowed=False, number_of_rooms=\"dontcare\")]", "input_token_count": 1460, "output_token_count": 35, "latency": 10.965964794158936}
{"id": "live_multiple_599-158-5", "result": [{"Hotels_4_SearchHotel": {"location": "Delhi, India"}}], "input_token_count": 1424, "output_token_count": 28, "latency": 8.52535080909729}
{"id": "live_multiple_600-158-6", "result": "[Hotels_4_SearchHotel(location='London, UK', smoking_allowed=True, number_of_rooms='2')]", "input_token_count": 1518, "output_token_count": 28, "latency": 8.199987411499023}
{"id": "live_multiple_601-158-7", "result": "[Hotels_4_SearchHotel(location='Kuala Lumpur, MY')]", "input_token_count": 1527, "output_token_count": 18, "latency": 5.044177055358887}
{"id": "live_multiple_602-158-8", "result": "[Hotels_4_SearchHotel(location=\"Nairobi, KE\", star_rating=\"4\")]", "input_token_count": 1513, "output_token_count": 23, "latency": 6.127695798873901}
{"id": "live_multiple_603-158-9", "result": "[Hotels_4_SearchHotel(location='New York, NY', star_rating='3')]", "input_token_count": 1506, "output_token_count": 22, "latency": 5.508312463760376}
{"id": "live_multiple_604-158-10", "result": "[Hotels_4_SearchHotel(location='Sacramento, CA')]", "input_token_count": 1518, "output_token_count": 17, "latency": 4.3768956661224365}
{"id": "live_multiple_605-158-11", "result": "[Hotels_4_SearchHotel(location='Paris, FR', star_rating='3', number_of_rooms='1')]", "input_token_count": 1516, "output_token_count": 28, "latency": 8.443957090377808}
{"id": "live_multiple_606-158-12", "result": "[Hotels_4_SearchHotel(location=\"Sydney, AU\", star_rating=\"4\", smoking_allowed=True, number_of_rooms=\"2\")]", "input_token_count": 1522, "output_token_count": 33, "latency": 10.024445295333862}
{"id": "live_multiple_607-159-0", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2024-03-14"}}], "input_token_count": 2250, "output_token_count": 48, "latency": 14.991320610046387}
{"id": "live_multiple_608-159-1", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Chicago, IL", "date": "2023-03-13"}}], "input_token_count": 2261, "output_token_count": 48, "latency": 14.997996091842651}
{"id": "live_multiple_609-159-2", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Philadelphia, PA", "date": "2023-03-10"}}], "input_token_count": 2276, "output_token_count": 47, "latency": 14.35952639579773}
{"id": "live_multiple_610-159-3", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Portland, OR", "date": "2024-03-14"}}], "input_token_count": 2256, "output_token_count": 48, "latency": 14.970999956130981}
{"id": "live_multiple_611-159-4", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Philadelphia, PA", "date": "2023-09-30"}}], "input_token_count": 2270, "output_token_count": 47, "latency": 14.202765464782715}
{"id": "live_multiple_612-159-5", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Los Angeles, CA"}}], "input_token_count": 2260, "output_token_count": 33, "latency": 9.835026979446411}
{"id": "live_multiple_613-159-6", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "London, UK", "date": "2024-03-10"}}], "input_token_count": 2270, "output_token_count": 48, "latency": 14.813132286071777}
{"id": "live_multiple_614-159-7", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Portland, OR", "date": "dontcare"}}], "input_token_count": 2272, "output_token_count": 40, "latency": 10.80515193939209}
{"id": "live_multiple_615-159-8", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "San Diego, CA", "date": "2023-04-08"}}], "input_token_count": 2263, "output_token_count": 48, "latency": 14.81025743484497}
{"id": "live_multiple_616-159-9", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Los Angeles, CA", "date": "2024-03-11"}}], "input_token_count": 2263, "output_token_count": 49, "latency": 15.697731256484985}
{"id": "live_multiple_617-159-10", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Los Angeles, CA", "date": "2024-03-10"}}], "input_token_count": 2262, "output_token_count": 48, "latency": 15.55532455444336}
{"id": "live_multiple_618-159-11", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "London, UK", "date": "2023-06-12"}}], "input_token_count": 2260, "output_token_count": 47, "latency": 15.38494324684143}
{"id": "live_multiple_619-159-12", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Long Beach, CA", "date": "2023-03-12"}}], "input_token_count": 2265, "output_token_count": 49, "latency": 16.157422065734863}
{"id": "live_multiple_620-160-0", "result": "[Payment_1_RequestPayment(receiver=\"\u746a\u9e97\", amount=200, private_visibility=True)]", "input_token_count": 1119, "output_token_count": 26, "latency": 8.172908544540405}
{"id": "live_multiple_621-160-1", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=154, receiver=\"landlord@example.com\", private_visibility=True)]", "input_token_count": 1119, "output_token_count": 33, "latency": 9.311584234237671}
{"id": "live_multiple_622-160-2", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=29, receiver=\"Thomas\")]", "input_token_count": 1108, "output_token_count": 25, "latency": 8.043989896774292}
{"id": "live_multiple_623-160-3", "result": "[Payment_1_RequestPayment(receiver=\"\u5a01\u723e\u905c\", amount=42, private_visibility=True)]", "input_token_count": 1120, "output_token_count": 26, "latency": 7.961784601211548}
{"id": "live_multiple_624-160-4", "result": "[Payment_1_RequestPayment(receiver=\"johndoe@example.com\", amount=15025, private_visibility=True)]", "input_token_count": 1124, "output_token_count": 31, "latency": 8.778215646743774}
{"id": "live_multiple_625-160-5", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=200, receiver=\"amelia@example.com\", private_visibility=True)]", "input_token_count": 1127, "output_token_count": 33, "latency": 9.911011457443237}
{"id": "live_multiple_626-160-6", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=83, receiver=\"johndoe@example.com\", private_visibility=True)]", "input_token_count": 1121, "output_token_count": 34, "latency": 10.17422080039978}
{"id": "live_multiple_627-160-7", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=200, receiver=\"Diego\", private_visibility=True)]", "input_token_count": 1123, "output_token_count": 31, "latency": 9.590980768203735}
{"id": "live_multiple_628-160-8", "result": "[Payment_1_RequestPayment(receiver=\"Diego\", amount=10800)]", "input_token_count": 1111, "output_token_count": 22, "latency": 7.378669261932373}
{"id": "live_multiple_629-160-9", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=250, receiver=\"Rachel\", private_visibility=True)]", "input_token_count": 1117, "output_token_count": 30, "latency": 9.464640378952026}
{"id": "live_multiple_630-160-10", "result": "[Payment_1_RequestPayment(receiver=\"Amelia\", amount=15500, private_visibility=False)]", "input_token_count": 1125, "output_token_count": 27, "latency": 8.221059083938599}
{"id": "live_multiple_631-160-11", "result": "[Payment_1_RequestPayment(receiver=\"customer@example.com\", amount=4500)]", "input_token_count": 1132, "output_token_count": 22, "latency": 7.570119142532349}
{"id": "live_multiple_632-161-0", "result": "[Music_3_LookupMusic(album='Winew to The Fishbowl', year='2015')]", "input_token_count": 3006, "output_token_count": 29, "latency": 9.438280582427979}
{"id": "live_multiple_633-161-1", "result": "[Music_3_LookupMusic(genre='Rock', year='2015')]", "input_token_count": 2999, "output_token_count": 22, "latency": 7.543418884277344}
{"id": "live_multiple_634-161-2", "result": "[Music_3_LookupMusic(genre='Country', artist='dontcare', album='dontcare', year='dontcare')]", "input_token_count": 3014, "output_token_count": 30, "latency": 9.610061645507812}
{"id": "live_multiple_635-161-3", "result": "[Music_3_LookupMusic(genre='Electropop', year='2019')]", "input_token_count": 2998, "output_token_count": 24, "latency": 7.758023738861084}
{"id": "live_multiple_636-161-4", "result": "[Music_3_LookupMusic(artist='Tove Lo', genre='dontcare', year='dontcare')]", "input_token_count": 2996, "output_token_count": 27, "latency": 8.49706482887268}
{"id": "live_multiple_637-161-5", "result": "[Music_3_PlayMedia(track='\u5343\u5206\u4e4b\u4e00', artist='any', device='Kitchen', album='any')]", "input_token_count": 2999, "output_token_count": 29, "latency": 8.921004295349121}
{"id": "live_multiple_638-161-6", "result": "[Music_3_LookupMusic(artist=\"Sia\", album=\"Davery Is Christmas\", genre=\"dontcare\", year=\"dontcare\")]", "input_token_count": 2997, "output_token_count": 34, "latency": 11.634457349777222}
{"id": "live_multiple_639-161-7", "result": "[Music_3_LookupMusic(artist='dontcare', album='High Experionations', year='2019')]", "input_token_count": 3001, "output_token_count": 30, "latency": 9.173894882202148}
{"id": "live_multiple_640-161-8", "result": "[Music_3_LookupMusic(artist=\"Cody Johnson\", album=\"Gotta Be Me\", year=\"2019\")]", "input_token_count": 3001, "output_token_count": 31, "latency": 10.267086744308472}
{"id": "live_multiple_641-161-9", "result": "[Music_3_LookupMusic(artist='Jess Glynne', year='2018')]", "input_token_count": 2995, "output_token_count": 25, "latency": 7.47556209564209}
{"id": "live_multiple_642-161-10", "result": "[Music_3_LookupMusic(artist='Taylor Swift', genre='dontcare', year='dontcare')]", "input_token_count": 3006, "output_token_count": 26, "latency": 8.14035964012146}
{"id": "live_multiple_643-161-11", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='Rock', year='2016')]", "input_token_count": 3000, "output_token_count": 32, "latency": 11.354012966156006}
{"id": "live_multiple_644-161-12", "result": "[Music_3_LookupMusic(artist='dontcare', genre='dontcare', year='dontcare'), Music_3_PlayMedia(track='any', artist='any', device='Living room', album='any')]", "input_token_count": 3017, "output_token_count": 50, "latency": 17.155146598815918}
{"id": "live_multiple_645-161-13", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='dontcare', year='2019')]", "input_token_count": 3009, "output_token_count": 33, "latency": 11.932876110076904}
{"id": "live_multiple_646-161-14", "result": "[Music_3_LookupMusic(artist='dontcare', album='Starboy', year='2020')]", "input_token_count": 3001, "output_token_count": 28, "latency": 8.888935089111328}
{"id": "live_multiple_647-161-15", "result": "[Music_3_LookupMusic(artist='Ariana Grande', year='2018')]", "input_token_count": 2997, "output_token_count": 25, "latency": 7.960557222366333}
{"id": "live_multiple_648-161-16", "result": "[Music_3_LookupMusic(artist=\"Little Mix\", album=\"Get Wired\")]", "input_token_count": 2998, "output_token_count": 22, "latency": 6.705601215362549}
{"id": "live_multiple_649-161-17", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='dontcare', year='2022')]", "input_token_count": 2997, "output_token_count": 33, "latency": 11.901411533355713}
{"id": "live_multiple_650-161-18", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_651-161-19", "result": "[Music_3_PlayMedia(track=\"The Getaway\", artist=\"Red Hot Chili Peppers\", device=\"Living room\", album=\"The Getaway\")]", "input_token_count": 3024, "output_token_count": 37, "latency": 13.893147945404053}
{"id": "live_multiple_652-161-20", "result": "[Music_3_PlayMedia(track=\"Artist's Song\", artist=\"Artist's Name\", device=\"Living room\")]", "input_token_count": 2999, "output_token_count": 27, "latency": 9.165974855422974}
{"id": "live_multiple_653-161-21", "result": "[Music_3_LookupMusic(album='Halcyon', year='2012')]", "input_token_count": 2997, "output_token_count": 24, "latency": 7.841681480407715}
{"id": "live_multiple_654-161-22", "result": "[Music_3_LookupMusic(genre='Pop', year='2023')]", "input_token_count": 3010, "output_token_count": 22, "latency": 7.470184564590454}
{"id": "live_multiple_655-161-23", "result": "[Music_3_LookupMusic(album='Warrior', year='2012', genre='Pop')]", "input_token_count": 3015, "output_token_count": 27, "latency": 9.614179611206055}
{"id": "live_multiple_656-161-24", "result": "[Music_3_LookupMusic(artist='Harris J', album='Salam')]", "input_token_count": 3004, "output_token_count": 22, "latency": 7.434361696243286}
{"id": "live_multiple_657-161-25", "result": "[Music_3_PlayMedia(track=\"\u4f60\u7684\u5f62\u72c0\", artist=\"Ed Sheeran\", device=\"Living room\")]", "input_token_count": 3012, "output_token_count": 29, "latency": 10.840245246887207}
{"id": "live_multiple_658-162-0", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "2023-03-12"}}], "input_token_count": 5351, "output_token_count": 49, "latency": 18.127869844436646}
{"id": "live_multiple_659-162-1", "result": "[Events_3_FindEvents(event_type=\"Theater\", city=\"New York, NY\")]", "input_token_count": 5342, "output_token_count": 22, "latency": 7.861701965332031}
{"id": "live_multiple_660-162-2", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-03-10"}}, {"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "2023-03-10"}}], "input_token_count": 5363, "output_token_count": 95, "latency": 33.92189383506775}
{"id": "live_multiple_661-162-3", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-05-21"}}], "input_token_count": 5357, "output_token_count": 48, "latency": 17.864080667495728}
{"id": "live_multiple_662-162-4", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-10-07"}}], "input_token_count": 5364, "output_token_count": 48, "latency": 17.848569869995117}
{"id": "live_multiple_663-162-5", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Philadelphia, PA", "date": "2023-03-08"}}], "input_token_count": 5382, "output_token_count": 47, "latency": 17.662763357162476}
{"id": "live_multiple_664-162-6", "result": "[Events_3_FindEvents(event_type=\"Music\", city=\"New York, NY\")]", "input_token_count": 5342, "output_token_count": 21, "latency": 6.919893503189087}
{"id": "live_multiple_665-162-7", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Los Angeles, CA", "date": "2023-03-09"}}], "input_token_count": 5350, "output_token_count": 49, "latency": 17.416088819503784}
{"id": "live_multiple_666-162-8", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-10-01"}}, {"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "2023-10-01"}}], "input_token_count": 5379, "output_token_count": 95, "latency": 33.32110118865967}
{"id": "live_multiple_667-162-9", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "2023-03-05"}}], "input_token_count": 5361, "output_token_count": 49, "latency": 16.973687648773193}
{"id": "live_multiple_668-162-10", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "New York, NY", "date": "2023-10-17"}}], "input_token_count": 5376, "output_token_count": 49, "latency": 16.451674461364746}
{"id": "live_multiple_669-162-11", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-03-07"}}], "input_token_count": 5355, "output_token_count": 48, "latency": 16.011359453201294}
{"id": "live_multiple_670-162-12", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Portland, OR", "date": "2023-10-09"}}], "input_token_count": 5358, "output_token_count": 48, "latency": 16.241663694381714}
{"id": "live_multiple_671-162-13", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-10-08"}}], "input_token_count": 5370, "output_token_count": 48, "latency": 16.25122356414795}
{"id": "live_multiple_672-162-14", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Los Angeles, CA", "date": "2023-10-01"}}], "input_token_count": 5366, "output_token_count": 48, "latency": 16.229249477386475}
{"id": "live_multiple_673-162-15", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-09-30"}}], "input_token_count": 5371, "output_token_count": 48, "latency": 16.24247121810913}
{"id": "live_multiple_674-162-16", "result": [{"Events_3_FindEvents": {"event_type": "Theater", "city": "Los Angeles, CA"}}], "input_token_count": 5344, "output_token_count": 34, "latency": 12.587251424789429}
{"id": "live_multiple_675-163-0", "result": [{"Weather_1_GetWeather": {"city": "Mexico City"}}], "input_token_count": 1824, "output_token_count": 23, "latency": 8.240416526794434}
{"id": "live_multiple_676-163-1", "result": [{"Weather_1_GetWeather": {"city": "New York, NY", "date": "2023-10-02"}}], "input_token_count": 1820, "output_token_count": 40, "latency": 13.518113851547241}
{"id": "live_multiple_677-163-2", "result": [{"Weather_1_GetWeather": {"city": "Philadelphia, PA", "date": "2024-04-13"}}], "input_token_count": 1838, "output_token_count": 39, "latency": 13.366694688796997}
{"id": "live_multiple_678-163-3", "result": [{"Weather_1_GetWeather": {"city": "Washington, DC", "date": "2023-04-02"}}], "input_token_count": 1833, "output_token_count": 39, "latency": 13.327678442001343}
{"id": "live_multiple_679-163-4", "result": [{"Weather_1_GetWeather": {"city": "Sydney, AU", "date": "2023-03-02"}}], "input_token_count": 1840, "output_token_count": 39, "latency": 13.322778224945068}
{"id": "live_multiple_680-163-5", "result": [{"Weather_1_GetWeather": {"city": "Chicago, IL", "date": "2023-03-08"}}], "input_token_count": 1832, "output_token_count": 39, "latency": 13.310132265090942}
{"id": "live_multiple_681-163-6", "result": [{"Weather_1_GetWeather": {"city": "Vancouver, BC"}}], "input_token_count": 1828, "output_token_count": 25, "latency": 9.312400817871094}
{"id": "live_multiple_682-163-7", "result": [{"Weather_1_GetWeather": {"city": "\u897f\u96c5\u5716, WA", "date": "2023-03-04"}}], "input_token_count": 1840, "output_token_count": 42, "latency": 14.547937154769897}
{"id": "live_multiple_683-163-8", "result": [{"Weather_1_GetWeather": {"city": "Miami, FL", "date": "2024-03-03"}}], "input_token_count": 1839, "output_token_count": 40, "latency": 13.802689790725708}
{"id": "live_multiple_684-164-0", "result": "[Movies_3_FindMovies(directed_by=\"Riley Stearns\", cast=\"Steve Terada\")]", "input_token_count": 1827, "output_token_count": 25, "latency": 9.275569915771484}
{"id": "live_multiple_685-164-1", "result": "[Movies_3_FindMovies(directed_by=\"Wes Anderson\")]", "input_token_count": 1809, "output_token_count": 17, "latency": 5.327577590942383}
{"id": "live_multiple_686-164-2", "result": "[Movies_3_FindMovies(directed_by=\"Leland Orser\")]", "input_token_count": 1806, "output_token_count": 18, "latency": 5.949559450149536}
{"id": "live_multiple_687-164-3", "result": "[Movies_3_FindMovies(directed_by=\"Guillermo del Toro\", genre=\"Fantasy\")]", "input_token_count": 1798, "output_token_count": 24, "latency": 9.044503450393677}
{"id": "live_multiple_688-164-4", "result": "[Movies_3_FindMovies(cast=\"Carol Sutton\")]", "input_token_count": 1816, "output_token_count": 16, "latency": 4.704228401184082}
{"id": "live_multiple_689-164-5", "result": "[Movies_3_FindMovies(directed_by=\"Gavin Hood\", cast=\"Rhys Ifans\")]", "input_token_count": 1825, "output_token_count": 24, "latency": 9.02292776107788}
{"id": "live_multiple_690-164-6", "result": "[Movies_3_FindMovies(directed_by=\"Jack Carson\")]", "input_token_count": 1811, "output_token_count": 16, "latency": 4.682635068893433}
{"id": "live_multiple_691-164-7", "result": "[Movies_3_FindMovies(directed_by=\"Herbert Ross\", cast=\"Nancy Parsons\")]", "input_token_count": 1826, "output_token_count": 23, "latency": 8.467742443084717}
{"id": "live_multiple_692-164-8", "result": "[Movies_3_FindMovies(directed_by=\"Peter Strickland\")]", "input_token_count": 1808, "output_token_count": 18, "latency": 5.967664957046509}
{"id": "live_multiple_693-164-9", "result": "[Movies_3_FindMovies(directed_by=\"Utkarsh Ambudkar\")]", "input_token_count": 1812, "output_token_count": 20, "latency": 7.226130247116089}
{"id": "live_multiple_694-164-10", "result": "[Movies_3_FindMovies(cast=\"Javier Bardem\")]", "input_token_count": 1824, "output_token_count": 17, "latency": 5.458261251449585}
{"id": "live_multiple_695-164-11", "result": "[Movies_3_FindMovies(directed_by=\"Satoshi Kon\", cast=\"Akiko Kawase\")]", "input_token_count": 1821, "output_token_count": 25, "latency": 9.833830833435059}
{"id": "live_multiple_696-164-12", "result": "[Movies_3_FindMovies(cast=\"Noah Gaynor\")]", "input_token_count": 1807, "output_token_count": 17, "latency": 5.933917284011841}
{"id": "live_multiple_697-164-13", "result": "[Movies_3_FindMovies(directed_by=\"Quentin Tarantino\", genre=\"Offbeat\")]", "input_token_count": 1814, "output_token_count": 23, "latency": 8.592287302017212}
{"id": "live_multiple_698-164-14", "result": "[Movies_3_FindMovies(genre='Offbeat')]", "input_token_count": 1802, "output_token_count": 15, "latency": 5.5902488231658936}
{"id": "live_multiple_699-164-15", "result": "[Movies_3_FindMovies(cast=\"Tzi Ma\")]", "input_token_count": 1802, "output_token_count": 16, "latency": 6.192767381668091}
{"id": "live_multiple_700-164-16", "result": "[Movies_3_FindMovies(directed_by=\"Hari Sama\")]", "input_token_count": 1811, "output_token_count": 18, "latency": 6.903748989105225}
{"id": "live_multiple_701-164-17", "result": "[Movies_3_FindMovies(genre='Comedy', cast='Vanessa Przada')]", "input_token_count": 1809, "output_token_count": 22, "latency": 8.864459991455078}
{"id": "live_multiple_702-164-18", "result": "[Movies_3_FindMovies(cast=\"Katsunosuke Hori\")]", "input_token_count": 1816, "output_token_count": 19, "latency": 7.426476001739502}
{"id": "live_multiple_703-164-19", "result": "[Movies_3_FindMovies(directed_by=\"Aryn Wright-Thompson\", cast=\"Alex Kendrick\")]", "input_token_count": 1803, "output_token_count": 26, "latency": 9.958556890487671}
{"id": "live_multiple_704-164-20", "result": "[Movies_3_FindMovies(cast=\"Claudia Doumit\")]", "input_token_count": 1813, "output_token_count": 17, "latency": 7.106961250305176}
{"id": "live_multiple_705-164-21", "result": "[Movies_3_FindMovies(cast=\"Nikita Mehta\")]", "input_token_count": 1816, "output_token_count": 17, "latency": 7.107496738433838}
{"id": "live_multiple_706-164-22", "result": "[Movies_3_FindMovies(genre='Fantasy')]", "input_token_count": 1806, "output_token_count": 15, "latency": 6.79785943031311}
{"id": "live_multiple_707-164-23", "result": "[Movies_3_FindMovies(cast=\"Pete Davidson\")]", "input_token_count": 1808, "output_token_count": 16, "latency": 6.975237131118774}
{"id": "live_multiple_708-164-24", "result": "[Movies_3_FindMovies(directed_by=\"Steven Spielberg\", genre=\"Sci-fi\")]", "input_token_count": 1810, "output_token_count": 22, "latency": 9.318607091903687}
{"id": "live_multiple_709-164-25", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_710-164-26", "result": "[Movies_3_FindMovies(genre='Comedy')]", "input_token_count": 1808, "output_token_count": 15, "latency": 7.278646945953369}
{"id": "live_multiple_711-164-27", "result": "[Movies_3_FindMovies(directed_by=\"Jim Henson, Steve Whitmire\", genre=\"Fantasy\")]", "input_token_count": 1831, "output_token_count": 27, "latency": 10.410264015197754}
{"id": "live_multiple_712-164-28", "result": "[Movies_3_FindMovies(directed_by=\"David Leitch\")]", "input_token_count": 1813, "output_token_count": 17, "latency": 8.504478693008423}
{"id": "live_multiple_713-165-0", "result": [{"Hotels_2_SearchHouse": {"where_to": "London, UK", "has_laundry_service": "True"}}], "input_token_count": 2139, "output_token_count": 39, "latency": 14.723281621932983}
{"id": "live_multiple_714-165-1", "result": "[Hotels_2_SearchHouse(where_to='Phoenix, AZ', rating=4.1)]", "input_token_count": 2138, "output_token_count": 24, "latency": 9.325157165527344}
{"id": "live_multiple_715-165-2", "result": "[Hotels_2_SearchHouse(where_to='Austin, TX', number_of_adults=2, rating=4.4, has_laundry_service='True')]", "input_token_count": 2144, "output_token_count": 41, "latency": 14.833184003829956}
{"id": "live_multiple_716-165-3", "result": "[Hotels_2_SearchHouse(where_to='Austin, TX', number_of_adults=1)]", "input_token_count": 2130, "output_token_count": 25, "latency": 9.793497085571289}
{"id": "live_multiple_717-165-4", "result": "[Hotels_2_SearchHouse(where_to='Kuala Lumpur, MY', has_laundry_service='True', number_of_adults=1)]", "input_token_count": 2126, "output_token_count": 36, "latency": 13.147271633148193}
{"id": "live_multiple_718-165-5", "result": "[Hotels_2_SearchHouse(where_to='Austin, TX', number_of_adults=4)]", "input_token_count": 2164, "output_token_count": 25, "latency": 9.792961359024048}
{"id": "live_multiple_719-165-6", "result": "[Hotels_2_SearchHouse(where_to='Anaheim, CA', number_of_adults=1)]", "input_token_count": 2124, "output_token_count": 26, "latency": 10.348657846450806}
{"id": "live_multiple_720-165-7", "result": "[Hotels_2_SearchHouse(where_to='New York, NY', number_of_adults=4, check_in_date='05/10/2023', check_out_date='05/15/2023')]", "input_token_count": 2165, "output_token_count": 57, "latency": 19.156063318252563}
{"id": "live_multiple_721-165-8", "result": "[Hotels_2_SearchHouse(where_to='Philadelphia, PA', has_laundry_service='True', number_of_adults=1, rating=4.1)]", "input_token_count": 2140, "output_token_count": 40, "latency": 14.18590760231018}
{"id": "live_multiple_722-165-9", "result": "[Hotels_2_SearchHouse(where_to='Los Angeles, CA', number_of_adults=4, rating=4.1)]", "input_token_count": 2153, "output_token_count": 32, "latency": 11.989793300628662}
{"id": "live_multiple_723-165-10", "result": "[Hotels_2_SearchHouse(where_to='Paris, FR', has_laundry_service='True')]", "input_token_count": 2134, "output_token_count": 27, "latency": 10.497029066085815}
{"id": "live_multiple_724-165-11", "result": "[Hotels_2_SearchHouse(where_to='Los Angeles, CA', has_laundry_service='True', rating=3.7)]", "input_token_count": 2145, "output_token_count": 33, "latency": 12.250646591186523}
{"id": "live_multiple_725-166-0", "result": "[Services_1_FindProvider(city=\"Lafayette, LA\")]", "input_token_count": 1338, "output_token_count": 18, "latency": 7.882172584533691}
{"id": "live_multiple_726-166-1", "result": "[Services_1_FindProvider(city='New York, NY', is_unisex=True)]", "input_token_count": 1339, "output_token_count": 22, "latency": 8.495978832244873}
{"id": "live_multiple_727-166-2", "result": [{"Services_1_BookAppointment": {"stylist_name": "\u7d04\u7ff0\u7684\u7406\u9aee\u5e97", "appointment_time": "14:00", "appointment_date": "2024-03-15"}}], "input_token_count": 1337, "output_token_count": 59, "latency": 20.369985342025757}
{"id": "live_multiple_728-166-3", "result": [{"Services_1_FindProvider": {"city": "Walnut Creek, CA"}}], "input_token_count": 1354, "output_token_count": 27, "latency": 10.462128400802612}
{"id": "live_multiple_729-167-0", "result": [{"Homes_2_FindHomeByArea": {"area": "Denver, CO", "intent": "rent", "number_of_beds": 2, "number_of_baths": 1}}], "input_token_count": 2250, "output_token_count": 55, "latency": 19.366363286972046}
{"id": "live_multiple_730-167-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_731-167-2", "result": [{"Homes_2_FindHomeByArea": {"area": "San Francisco, CA", "intent": "rent", "number_of_beds": 3, "number_of_baths": 2, "has_garage": true, "in_unit_laundry": "True"}}], "input_token_count": 2273, "output_token_count": 75, "latency": 28.880856037139893}
{"id": "live_multiple_732-167-3", "result": [{"Homes_2_FindHomeByArea": {"area": "\u897f\u96c5\u5716, WA", "intent": "buy", "number_of_beds": 3, "number_of_baths": 2}}], "input_token_count": 2251, "output_token_count": 58, "latency": 20.887879610061646}
{"id": "live_multiple_733-167-4", "result": [{"Homes_2_FindHomeByArea": {"area": "San Francisco, CA", "intent": "rent", "number_of_beds": 2, "number_of_baths": 1, "has_garage": false, "in_unit_laundry": "True"}}], "input_token_count": 2262, "output_token_count": 75, "latency": 28.400877714157104}
{"id": "live_multiple_734-167-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_735-167-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_736-167-7", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_737-167-8", "result": [{"Homes_2_FindHomeByArea": {"area": "San Francisco, CA", "intent": "buy", "number_of_beds": 2, "number_of_baths": 3, "has_garage": true}}], "input_token_count": 2257, "output_token_count": 64, "latency": 21.846662044525146}
{"id": "live_multiple_738-168-0", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=75.50, receiver=\"Peter\")]", "input_token_count": 2883, "output_token_count": 28, "latency": 10.752995014190674}
{"id": "live_multiple_739-168-1", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=50.0, receiver=\"Alex\", private_visibility=True)]", "input_token_count": 2889, "output_token_count": 31, "latency": 11.015402555465698}
{"id": "live_multiple_740-168-2", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=250.0, receiver=\"Margaret\", private_visibility=True)]", "input_token_count": 2898, "output_token_count": 33, "latency": 11.751667976379395}
{"id": "live_multiple_741-168-3", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=125, receiver=\"\u4e9e\u6b77\u514b\u65af\", private_visibility=True)]", "input_token_count": 2891, "output_token_count": 32, "latency": 11.14652419090271}
{"id": "live_multiple_742-168-4", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=84.0, receiver=\"Yumi\", private_visibility=True)]", "input_token_count": 2892, "output_token_count": 32, "latency": 11.140020608901978}
{"id": "live_multiple_743-168-5", "result": "[Payment_1_RequestPayment(receiver=\"Rachel\", amount=50, private_visibility=True)]", "input_token_count": 2898, "output_token_count": 23, "latency": 8.529268980026245}
{"id": "live_multiple_744-168-6", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=250, receiver=\"Svetlana\", private_visibility=True)]", "input_token_count": 2895, "output_token_count": 32, "latency": 11.295313835144043}
{"id": "live_multiple_745-169-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_746-169-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_747-169-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_748-169-3", "result": [{"Media_3_FindMovies": {"genre": "Action"}}], "input_token_count": 3086, "output_token_count": 23, "latency": 8.489225625991821}
{"id": "live_multiple_749-169-4", "result": "[Media_3_FindMovies(genre=\"Offbeat\")]", "input_token_count": 3092, "output_token_count": 15, "latency": 5.162919998168945}
{"id": "live_multiple_750-169-5", "result": [{"Media_3_FindMovies": {"genre": "Comedy-drama", "starring": "Madge Brindley"}}], "input_token_count": 3106, "output_token_count": 37, "latency": 11.898335456848145}
{"id": "live_multiple_751-169-6", "result": [{"Media_3_FindMovies": {"genre": "Comedy", "starring": "Jim Carrey"}}], "input_token_count": 3104, "output_token_count": 33, "latency": 10.813619613647461}
{"id": "live_multiple_752-169-7", "result": [{"Media_3_FindMovies": {"genre": "Mystery", "starring": "Monica Dolan"}}], "input_token_count": 3096, "output_token_count": 35, "latency": 11.168988704681396}
{"id": "live_multiple_753-169-8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_754-169-9", "result": [{"Media_3_FindMovies": {"genre": "Comedy-drama", "starring": "Ana de Armas"}}], "input_token_count": 3094, "output_token_count": 36, "latency": 11.316343784332275}
{"id": "live_multiple_755-169-10", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_756-169-11", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_757-169-12", "result": [{"Media_3_FindMovies": {"genre": "Family", "starring": "Debbie McCann"}}], "input_token_count": 3093, "output_token_count": 33, "latency": 10.405438661575317}
{"id": "live_multiple_758-169-13", "result": [{"Media_3_FindMovies": {"genre": "Thriller", "starring": "Robert De Niro"}}], "input_token_count": 3085, "output_token_count": 34, "latency": 10.572747945785522}
{"id": "live_multiple_759-169-14", "result": "[Media_3_FindMovies(genre=\"Animation\")]", "input_token_count": 3085, "output_token_count": 14, "latency": 4.550882339477539}
{"id": "live_multiple_760-169-15", "result": [{"Media_3_FindMovies": {"genre": "Thriller", "starring": "Michelle Caspar"}}], "input_token_count": 3095, "output_token_count": 34, "latency": 10.193357229232788}
{"id": "live_multiple_761-169-16", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_762-170-0", "result": [{"Buses_3_FindBus": {"from_city": "Portland, OR", "to_city": "Vancouver, BC", "departure_date": "2023-03-07", "num_passengers": 2}}], "input_token_count": 1535, "output_token_count": 64, "latency": 21.451058864593506}
{"id": "live_multiple_763-170-1", "result": [{"Buses_3_FindBus": {"from_city": "Los Angeles, CA", "to_city": "San Diego, CA", "departure_date": "2023-10-01", "num_passengers": 2}}], "input_token_count": 1514, "output_token_count": 64, "latency": 21.887985706329346}
{"id": "live_multiple_764-170-2", "result": "[Buses_3_FindBus(from_city='\u65e7\u91d1\u5c71, CA', to_city='\u6d1b\u6749\u78ef, CA', departure_date='2023-04-22')]", "input_token_count": 1518, "output_token_count": 43, "latency": 13.43452262878418}
{"id": "live_multiple_765-170-3", "result": "[Buses_3_FindBus(from_city='Philadelphia, PA', to_city='New York, NY', departure_date='2023-04-23', num_passengers=4)]", "input_token_count": 1528, "output_token_count": 44, "latency": 14.028380155563354}
{"id": "live_multiple_766-170-4", "result": [{"Buses_3_FindBus": {"from_city": "Austin, TX", "to_city": "Dallas, TX", "departure_date": "2023-03-13", "num_passengers": 3}}], "input_token_count": 1537, "output_token_count": 63, "latency": 21.27040982246399}
{"id": "live_multiple_767-171-0", "result": [{"Services_1_FindProvider": {"city": "New York, NY", "is_unisex": true}}], "input_token_count": 2796, "output_token_count": 34, "latency": 10.368096351623535}
{"id": "live_multiple_768-171-1", "result": [{"Services_1_FindProvider": {"city": "Emeryville, CA", "is_unisex": true}}], "input_token_count": 2789, "output_token_count": 35, "latency": 10.467537641525269}
{"id": "live_multiple_769-171-2", "result": [{"Services_1_FindProvider": {"city": "Mill Valley, CA"}}], "input_token_count": 2777, "output_token_count": 27, "latency": 8.812806606292725}
{"id": "live_multiple_770-171-3", "result": [{"Services_1_FindProvider": {"city": "Berkeley, CA", "is_unisex": true}}], "input_token_count": 2802, "output_token_count": 34, "latency": 10.349646806716919}
{"id": "live_multiple_771-171-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_772-171-5", "result": [{"Services_1_FindProvider": {"city": "Fremont, CA"}}], "input_token_count": 2793, "output_token_count": 27, "latency": 8.788861274719238}
{"id": "live_multiple_773-171-6", "result": [{"Services_1_FindProvider": {"city": "San Francisco, CA"}}], "input_token_count": 2773, "output_token_count": 27, "latency": 8.795032262802124}
{"id": "live_multiple_774-171-7", "result": [{"Services_1_FindProvider": {"city": "Morgan Hill, CA", "is_unisex": true}}], "input_token_count": 2776, "output_token_count": 34, "latency": 10.174998044967651}
{"id": "live_multiple_775-172-0", "result": "[RentalCars_3_GetCarsAvailable(city=\"Las Vegas, NV\", start_date=\"2023-10-01\", end_date=\"2023-10-12\", pickup_time=\"10:00\", car_type=\"SUV\")]", "input_token_count": 1538, "output_token_count": 62, "latency": 21.766218900680542}
{"id": "live_multiple_776-172-1", "result": "[RentalCars_3_GetCarsAvailable(city=\"Los Angeles, CA\", start_date=\"2024-03-07\", end_date=\"2024-03-07\", pickup_time=\"10:00\", car_type=\"SUV\")]", "input_token_count": 1517, "output_token_count": 62, "latency": 21.148361444473267}
{"id": "live_multiple_777-172-2", "result": "[RentalCars_3_GetCarsAvailable(city=\"Los Angeles, CA\", start_date=\"2023-04-15\", end_date=\"2023-04-20\", pickup_time=\"10:00\")]", "input_token_count": 1526, "output_token_count": 56, "latency": 17.48824906349182}
{"id": "live_multiple_778-173-0", "result": [{"Services_4_FindProvider": {"city": "Berkeley, CA", "type": "Family Counselor"}}], "input_token_count": 1387, "output_token_count": 34, "latency": 10.267772674560547}
{"id": "live_multiple_779-173-1", "result": [{"Services_4_FindProvider": {"city": "San Jose, CA", "type": "Psychologist"}}], "input_token_count": 1385, "output_token_count": 33, "latency": 9.058245420455933}
{"id": "live_multiple_780-173-2", "result": [{"Services_4_FindProvider": {"city": "New York, NY", "type": "Family Counselor"}}], "input_token_count": 1385, "output_token_count": 34, "latency": 9.447764158248901}
{"id": "live_multiple_781-173-3", "result": [{"Services_4_FindProvider": {"city": "San Francisco, CA", "type": "Psychologist"}}], "input_token_count": 1393, "output_token_count": 33, "latency": 9.034323930740356}
{"id": "live_multiple_782-173-4", "result": [{"Services_4_FindProvider": {"city": "Sausalito, CA", "type": "Psychologist"}}], "input_token_count": 1396, "output_token_count": 34, "latency": 9.77566909790039}
{"id": "live_multiple_783-173-5", "result": [{"Services_4_FindProvider": {"city": "Berkeley, CA", "type": "Family Counselor"}}], "input_token_count": 1420, "output_token_count": 34, "latency": 9.748053550720215}
{"id": "live_multiple_784-173-6", "result": [{"Services_4_FindProvider": {"city": "Berkeley, CA", "type": "Psychologist"}}], "input_token_count": 1424, "output_token_count": 33, "latency": 10.0410315990448}
{"id": "live_multiple_785-173-7", "result": [{"Services_4_FindProvider": {"city": "Sunnyvale, CA", "type": "Psychologist"}}], "input_token_count": 1425, "output_token_count": 34, "latency": 10.645622968673706}
{"id": "live_multiple_786-174-0", "result": "[Homes_2_ScheduleVisit(property_name=\"Riverdale\u516c\u5bd3\", visit_date=\"2023-04-15\")]", "input_token_count": 1321, "output_token_count": 33, "latency": 10.510592460632324}
{"id": "live_multiple_787-174-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_788-174-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_789-174-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_790-174-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_791-174-5", "result": [{"Homes_2_FindHomeByArea": {"area": "\u6838\u6843\u6eaa, CA", "intent": "buy", "number_of_beds": 3, "number_of_baths": 2, "has_garage": true}}], "input_token_count": 1364, "output_token_count": 67, "latency": 26.19969916343689}
{"id": "live_multiple_792-174-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_793-174-7", "result": "[Homes_2_ScheduleVisit(property_name=\"\u5317\u65b9\u9152\u5e97\", visit_date=\"2024-03-14\")]", "input_token_count": 1319, "output_token_count": 32, "latency": 10.335463762283325}
{"id": "live_multiple_794-175-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_795-175-1", "result": [{"Weather_1_GetWeather": {"city": "Tomales, CA"}}], "input_token_count": 3291, "output_token_count": 26, "latency": 8.65628433227539}
{"id": "live_multiple_796-175-2", "result": "[Weather_1_GetWeather(city='Sunol, CA')]", "input_token_count": 3275, "output_token_count": 16, "latency": 5.204021215438843}
{"id": "live_multiple_797-175-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_798-175-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_799-175-5", "result": [{"Weather_1_GetWeather": {"city": "Laguna Beach, CA"}}], "input_token_count": 3299, "output_token_count": 28, "latency": 8.930728197097778}
{"id": "live_multiple_800-175-6", "result": [{"Weather_1_GetWeather": {"city": "San Francisco, CA"}}], "input_token_count": 3300, "output_token_count": 26, "latency": 7.71656608581543}
{"id": "live_multiple_801-175-7", "result": "[Weather_1_GetWeather(city=\"New Delhi, IN\")]", "input_token_count": 3269, "output_token_count": 16, "latency": 4.351891994476318}
{"id": "live_multiple_802-175-8", "result": [{"Weather_1_GetWeather": {"city": "San Francisco, CA", "date": "2023-04-09"}}], "input_token_count": 3287, "output_token_count": 41, "latency": 13.014447450637817}
{"id": "live_multiple_803-175-9", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_804-175-10", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_805-175-11", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_806-175-12", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_807-175-13", "result": [{"Weather_1_GetWeather": {"city": "Larkspur, CA", "date": "2023-03-10"}}], "input_token_count": 3301, "output_token_count": 42, "latency": 14.049840688705444}
{"id": "live_multiple_808-175-14", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_809-176-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_810-176-1", "result": [{"Alarm_1_GetAlarms": {"user_id": 789}}], "input_token_count": 962, "output_token_count": 27, "latency": 8.355173826217651}
{"id": "live_multiple_811-176-2", "result": [{"Alarm_1_GetAlarms": {"user_id": 12345}}], "input_token_count": 944, "output_token_count": 29, "latency": 9.557893753051758}
{"id": "live_multiple_812-176-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_813-176-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_814-176-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_815-176-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_816-176-7", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_817-177-0", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "\u897f\u96c5\u5716, WA", "date": "2023-03-10"}}, {"Events_3_BuyEventTickets": {"event_name": "\u5b89\u6771\u5c3c\u00b7\u683c\u6797", "number_of_tickets": 2, "date": "2023-03-10", "city": "\u897f\u96c5\u5716, WA"}}], "input_token_count": 2467, "output_token_count": 113, "latency": 54.866841554641724}
{"id": "live_multiple_818-177-1", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY"}}], "input_token_count": 2439, "output_token_count": 33, "latency": 11.567785024642944}
{"id": "live_multiple_819-177-2", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Los Angeles, CA", "date": "2023-07-20"}}], "input_token_count": 2483, "output_token_count": 48, "latency": 18.228516340255737}
{"id": "live_multiple_820-177-3", "result": "[Events_3_FindEvents(event_type=\"Music\", city=\"New York, NY\", date=\"2023-03-04\"), Events_3_BuyEventTickets(event_name=\"\", number_of_tickets=1, date=\"2023-03-04\", city=\"New York, NY\")]", "input_token_count": 2468, "output_token_count": 72, "latency": 31.292352199554443}
{"id": "live_multiple_821-177-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_822-177-5", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "\u897f\u96c5\u5716, WA", "date": "2023-03-12"}}], "input_token_count": 2464, "output_token_count": 51, "latency": 20.12445044517517}
{"id": "live_multiple_823-177-6", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "Berkeley, CA", "date": "2023-03-13"}}], "input_token_count": 2459, "output_token_count": 48, "latency": 18.77814483642578}
{"id": "live_multiple_824-177-7", "result": "[Events_3_BuyEventTickets(event_name=\"\u66b4\u98a8\u96e8\", number_of_tickets=3, date=\"2023-03-02\", city=\"\u666e\u6797\u65af\u9813, NJ\")]", "input_token_count": 2475, "output_token_count": 46, "latency": 18.080668210983276}
{"id": "live_multiple_825-178-0", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='dontcare', year='dontcare')]", "input_token_count": 1898, "output_token_count": 31, "latency": 10.208211660385132}
{"id": "live_multiple_826-178-1", "result": "[Music_3_LookupMusic(artist='dontcare', year='2015')]", "input_token_count": 1886, "output_token_count": 23, "latency": 7.413714408874512}
{"id": "live_multiple_827-178-2", "result": "[Music_3_LookupMusic(artist='dontcare', year='2021')]", "input_token_count": 1885, "output_token_count": 23, "latency": 7.4136741161346436}
{"id": "live_multiple_828-178-3", "result": "[Music_3_LookupMusic(artist='dontcare', genre='Rock', year='dontcare')]", "input_token_count": 1888, "output_token_count": 25, "latency": 8.64140009880066}
{"id": "live_multiple_829-178-4", "result": "[Music_3_PlayMedia(track=\"\u6ce2\u5e0c\u7c73\u4e9e\u72c2\u60f3\u66f2\", device=\"Kitchen\")]", "input_token_count": 1889, "output_token_count": 26, "latency": 8.951080322265625}
{"id": "live_multiple_830-178-5", "result": "[Music_3_LookupMusic(artist=\"Sabaton\", year=\"2019\")]", "input_token_count": 1903, "output_token_count": 23, "latency": 7.870296955108643}
{"id": "live_multiple_831-178-6", "result": "[Music_3_LookupMusic(artist=\"Taylor Swift\", genre=\"Pop\")]", "input_token_count": 1908, "output_token_count": 20, "latency": 6.487338066101074}
{"id": "live_multiple_832-178-7", "result": "[Music_3_LookupMusic(artist='dontcare', genre='dontcare', year='2021')]", "input_token_count": 1896, "output_token_count": 28, "latency": 9.303362131118774}
{"id": "live_multiple_833-178-8", "result": "[Music_3_PlayMedia(track=\"Spice\", album=\"2018\")]", "input_token_count": 1891, "output_token_count": 22, "latency": 7.252001762390137}
{"id": "live_multiple_834-178-9", "result": "[Music_3_PlayMedia(track=\"Borbena\", artist=\"Teodora\", device=\"Kitchen\", album=\"Borbena\")]", "input_token_count": 1915, "output_token_count": 33, "latency": 11.88297986984253}
{"id": "live_multiple_835-178-10", "result": "[Music_3_LookupMusic(artist='dontcare', album='dontcare', genre='Reggaeton', year='19')]", "input_token_count": 1898, "output_token_count": 32, "latency": 11.266341924667358}
{"id": "live_multiple_836-178-11", "result": "[Music_3_PlayMedia(track=\"Love\", artist=\"Sucker Punch\", device=\"Kitchen\", album=\"Sucker Punch\")]", "input_token_count": 1906, "output_token_count": 33, "latency": 12.380973815917969}
{"id": "live_multiple_837-178-12", "result": "[Music_3_PlayMedia(track=\"Phan Dinh Tung\", artist=\"Phan Dinh Tung\", device=\"Kitchen\", album=\"\u5e3d\u5b50Nhan\")]", "input_token_count": 1896, "output_token_count": 39, "latency": 15.337405920028687}
{"id": "live_multiple_838-178-13", "result": "[Music_3_PlayMedia(track=\"\u8b20\u8a00\u8aaa\", artist=\"Alec Benjamin\", device=\"Living room\")]", "input_token_count": 1903, "output_token_count": 28, "latency": 9.31721830368042}
{"id": "live_multiple_839-178-14", "result": "[Music_3_LookupMusic(artist='dontcare', genre='Country', year='dontcare')]", "input_token_count": 1876, "output_token_count": 25, "latency": 8.816030979156494}
{"id": "live_multiple_840-178-15", "result": "[Music_3_LookupMusic(artist='dontcare', album='Gotta Be Me', year='2019')]", "input_token_count": 1900, "output_token_count": 30, "latency": 10.96958327293396}
{"id": "live_multiple_841-178-16", "result": "[Music_3_LookupMusic(artist='dontcare', album='Run', genre='Electropop')]", "input_token_count": 1892, "output_token_count": 26, "latency": 8.975409984588623}
{"id": "live_multiple_842-178-17", "result": "[Music_3_PlayMedia(track=\"Konshens\", artist=\"Konshens\", device=\"Patio\"), Music_3_LookupMusic(artist=\"Konshens\", genre=\"Reggae\")]", "input_token_count": 1921, "output_token_count": 46, "latency": 19.01810050010681}
{"id": "live_multiple_843-178-18", "result": "[Music_3_PlayMedia(track=\"The Last Stand\", artist=\"Sabaton\", album=\"The Great War\")]", "input_token_count": 1904, "output_token_count": 27, "latency": 9.575248718261719}
{"id": "live_multiple_844-178-19", "result": "[Music_3_PlayMedia(track=\"Cry Pretty\", album=\"Cry Pretty\", year=\"2018\")]", "input_token_count": 1907, "output_token_count": 29, "latency": 10.793590784072876}
{"id": "live_multiple_845-178-20", "result": "[Music_3_LookupMusic(artist=\"Sara Evans\", album=\"More Stronger\", genre=\"dontcare\", year=\"dontcare\")]", "input_token_count": 1907, "output_token_count": 33, "latency": 13.2174973487854}
{"id": "live_multiple_846-179-0", "result": [{"Restaurants_2_FindRestaurants": {"category": "Italian", "location": "San Francisco, CA", "price_range": "cheap"}}], "input_token_count": 1725, "output_token_count": 45, "latency": 18.852027416229248}
{"id": "live_multiple_847-179-1", "result": "[Restaurants_2_ReserveRestaurant(restaurant_name=\"Balthazar\", location=\"New York, NY\", time=\"20:00\", date=\"2024-05-17\", number_of_seats=4)]", "input_token_count": 1722, "output_token_count": 54, "latency": 24.32080888748169}
{"id": "live_multiple_848-179-2", "result": "[Restaurants_2_FindRestaurants(category=\"Italian\", location=\"New York, NY\", has_vegetarian_options=True)]", "input_token_count": 1732, "output_token_count": 31, "latency": 12.444853067398071}
{"id": "live_multiple_849-179-3", "result": "[Restaurants_2_FindRestaurants(category=\"Indian\", location=\"Sunnyvale, CA\", price_range=\"cheap\")]", "input_token_count": 1748, "output_token_count": 31, "latency": 12.45946741104126}
{"id": "live_multiple_850-179-4", "result": "[Restaurants_2_ReserveRestaurant(restaurant_name=\"\u6cd5\u570b\u6d17\u8863\u5e97\", location=\"\u63da\u7279\u7dad\u723e, \u52a0\u5229\u798f\u5c3c\u4e9e\u5dde\", time=\"13:30\", date=\"2023-03-14\")]", "input_token_count": 1743, "output_token_count": 59, "latency": 27.30184578895569}
{"id": "live_multiple_851-179-5", "result": "[Restaurants_2_FindRestaurants(category=\"Japanese\", location=\"San Francisco, CA\")]", "input_token_count": 1710, "output_token_count": 24, "latency": 8.228328704833984}
{"id": "live_multiple_852-180-0", "result": "[Buses_3_FindBus(from_city='San Francisco, CA', to_city='Los Angeles, CA', departure_date='04/25/2023')]", "input_token_count": 2850, "output_token_count": 40, "latency": 17.827270984649658}
{"id": "live_multiple_853-180-1", "result": "[Buses_3_BuyBusTicket(from_city='San Francisco, CA', to_city='Los Angeles, CA', departure_date='2023-03-07', departure_time='14:00', num_passengers=2)]", "input_token_count": 2862, "output_token_count": 55, "latency": 26.4164617061615}
{"id": "live_multiple_854-180-2", "result": "[Buses_3_FindBus(from_city='Philadelphia, PA', to_city='New York, NY', departure_date='03/14/2023')]", "input_token_count": 2859, "output_token_count": 39, "latency": 17.443563222885132}
{"id": "live_multiple_855-180-3", "result": "[Buses_3_FindBus(from_city='Fresno, CA', to_city='Los Angeles, CA', departure_date='03/10/2023', num_passengers=1, category='direct')]", "input_token_count": 2868, "output_token_count": 51, "latency": 24.00300097465515}
{"id": "live_multiple_856-180-4", "result": "[Buses_3_BuyBusTicket(from_city='Berkeley, CA', to_city='Portland, OR', departure_date='2023-05-15', departure_time='09:00', num_passengers=2, additional_luggage=True)]", "input_token_count": 2889, "output_token_count": 61, "latency": 30.04068922996521}
{"id": "live_multiple_857-180-5", "result": "[Buses_3_FindBus(from_city='San Francisco, CA', to_city='Los Angeles, CA', departure_date='03/07/2023', category='one-stop')]", "input_token_count": 2860, "output_token_count": 45, "latency": 20.340493202209473}
{"id": "live_multiple_858-180-6", "result": "[Buses_3_FindBus(from_city='San Francisco, CA', to_city='Los Angeles, CA', departure_date='05/15/2023', num_passengers=4, category='direct'), Buses_3_BuyBusTicket(from_city='San Francisco, CA', to_city='Los Angeles, CA', departure_date='2023-05-15', departure_time='14:00', num_passengers=4, additional_luggage=True)]", "input_token_count": 2876, "output_token_count": 108, "latency": 56.52130365371704}
{"id": "live_multiple_859-181-0", "result": "[Trains_1_GetTrainTickets(_from='New York, NY', to='Washington, DC', date_of_journey='10/11/2023', journey_start_time='09:00', _class='Business', trip_protection=True)]", "input_token_count": 1628, "output_token_count": 60, "latency": 29.43841791152954}
{"id": "live_multiple_860-181-1", "result": "[Trains_1_FindTrains(_from='San Francisco, CA', to='Los Angeles, CA', date_of_journey='2023-04-15')]", "input_token_count": 1601, "output_token_count": 43, "latency": 19.338272094726562}
{"id": "live_multiple_861-181-2", "result": "[Trains_1_GetTrainTickets(_from=\"Sacramento, CA\", to=\"Portland, OR\", date_of_journey=\"04/22/2023\", journey_start_time=\"10:00\")]", "input_token_count": 1608, "output_token_count": 52, "latency": 25.255495071411133}
{"id": "live_multiple_862-181-3", "result": "[Trains_1_FindTrains(_from=\"New York, NY\", to=\"Los Angeles, CA\", date_of_journey=\"2023-05-15\"), Trains_1_GetTrainTickets(_from=\"New York, NY\", to=\"Los Angeles, CA\", date_of_journey=\"2023-05-15\", journey_start_time=\"09:00\")]", "input_token_count": 1637, "output_token_count": 92, "latency": 48.17113494873047}
{"id": "live_multiple_863-182-0", "result": "[Movies_1_FindMovies(location=\"Orinda, CA\", genre=\"dontcare\", show_type=\"regular\")]", "input_token_count": 3655, "output_token_count": 26, "latency": 11.895324468612671}
{"id": "live_multiple_864-182-1", "result": "[Movies_1_FindMovies(location=\"Los Angeles, CA\", show_type=\"regular\")]", "input_token_count": 3652, "output_token_count": 21, "latency": 9.048565149307251}
{"id": "live_multiple_865-182-2", "result": "[Movies_1_FindMovies(location='Berkeley, CA', genre='Mystery', show_type='imax')]", "input_token_count": 3653, "output_token_count": 28, "latency": 12.535663604736328}
{"id": "live_multiple_866-182-3", "result": "[Movies_1_FindMovies(location=\"Fresno, CA\", genre=\"Drama\")]", "input_token_count": 3652, "output_token_count": 22, "latency": 9.650984048843384}
{"id": "live_multiple_867-182-4", "result": "[Movies_1_FindMovies(location='Berkeley, CA', genre='Supernatural')]", "input_token_count": 3642, "output_token_count": 21, "latency": 9.033506155014038}
{"id": "live_multiple_868-182-5", "result": "[Movies_1_FindMovies(location='Vallejo, CA')]", "input_token_count": 3625, "output_token_count": 17, "latency": 6.599987983703613}
{"id": "live_multiple_869-182-6", "result": "[Movies_1_FindMovies(location=\"San Rafael, CA\", show_type=\"imax\")]", "input_token_count": 3651, "output_token_count": 22, "latency": 9.632375240325928}
{"id": "live_multiple_870-182-7", "result": "[Movies_1_FindMovies(location=\"Pacific Place, CA\", genre=\"Sci-fi\", show_type=\"dontcare\")]", "input_token_count": 3664, "output_token_count": 29, "latency": 12.654630422592163}
{"id": "live_multiple_871-182-8", "result": "[Movies_1_GetTimesForMovie(movie_name=\"\u6e38\u620f\", location=\"Berkeley, CA\", show_date=\"2023-10-15\", show_type=\"regular\")]", "input_token_count": 3645, "output_token_count": 42, "latency": 19.686702013015747}
{"id": "live_multiple_872-182-9", "result": "[Movies_1_FindMovies(location=\"Hillsborough, CA\", show_type=\"regular\")]", "input_token_count": 3654, "output_token_count": 22, "latency": 9.352363586425781}
{"id": "live_multiple_873-182-10", "result": "[Movies_1_FindMovies(location='San Francisco, CA')]", "input_token_count": 3629, "output_token_count": 16, "latency": 6.002936363220215}
{"id": "live_multiple_874-182-11", "result": "[Movies_1_FindMovies(location='Sebastopol, CA', genre='Supernatural')]", "input_token_count": 3641, "output_token_count": 22, "latency": 9.807230234146118}
{"id": "live_multiple_875-183-0", "result": "[Travel_1_FindAttractions(location=\"San Francisco, CA\")]", "input_token_count": 3716, "output_token_count": 18, "latency": 8.728503942489624}
{"id": "live_multiple_876-183-1", "result": "[Travel_1_FindAttractions(location=\"Paris, FR\", free_entry=\"True\", category=\"Historical Landmark\", good_for_kids=\"True\")]", "input_token_count": 3722, "output_token_count": 36, "latency": 17.598299264907837}
{"id": "live_multiple_877-183-2", "result": "[Travel_1_FindAttractions(location=\"Paris, FR\", free_entry=\"True\", good_for_kids=\"True\")]", "input_token_count": 3738, "output_token_count": 29, "latency": 13.999042510986328}
{"id": "live_multiple_878-183-3", "result": "[Travel_1_FindAttractions(location=\"San Francisco, CA\", free_entry=\"True\", good_for_kids=\"True\", category=\"Nature Preserve\")]", "input_token_count": 3756, "output_token_count": 36, "latency": 17.47718620300293}
{"id": "live_multiple_879-183-4", "result": "[Travel_1_FindAttractions(location=\"San Francisco, CA\", free_entry=\"True\", good_for_kids=\"True\", category=\"Museum\")]", "input_token_count": 3728, "output_token_count": 35, "latency": 16.869173526763916}
{"id": "live_multiple_880-183-5", "result": "[Travel_1_FindAttractions(location=\"Paris, FR\", good_for_kids=\"True\")]", "input_token_count": 3718, "output_token_count": 24, "latency": 11.437114000320435}
{"id": "live_multiple_881-183-6", "result": "[Travel_1_FindAttractions(location=\"San Francisco, CA\", free_entry=\"True\", good_for_kids=\"True\")]", "input_token_count": 3729, "output_token_count": 30, "latency": 14.01735258102417}
{"id": "live_multiple_882-183-7", "result": "[Travel_1_FindAttractions(location=\"San Francisco, CA\", free_entry=\"True\", category=\"Museum\", good_for_kids=\"dontcare\")]", "input_token_count": 3737, "output_token_count": 36, "latency": 17.412396907806396}
{"id": "live_multiple_883-184-0", "result": "[Buses_3_FindBus(from_city='New York, NY', to_city='Boston, MA', departure_date='2023-04-20')]", "input_token_count": 3573, "output_token_count": 39, "latency": 20.22343921661377}
{"id": "live_multiple_884-184-1", "result": "[Buses_3_FindBus(from_city='Anaheim, CA', to_city='Las Vegas, NV', departure_date='2023-06-15', category='direct')]", "input_token_count": 3589, "output_token_count": 44, "latency": 23.38226842880249}
{"id": "live_multiple_885-184-2", "result": "[Buses_3_FindBus(from_city='New York, NY', to_city='Boston, MA', departure_date='2023-05-15')]", "input_token_count": 3570, "output_token_count": 39, "latency": 20.225465059280396}
{"id": "live_multiple_886-184-3", "result": "[Buses_3_FindBus(from_city='Los Angeles, CA', to_city='Fresno, CA', departure_date='2023-03-04', num_passengers=2)]", "input_token_count": 3569, "output_token_count": 46, "latency": 24.57443904876709}
{"id": "live_multiple_887-184-4", "result": "[Buses_3_FindBus(from_city='San Diego, CA', to_city='Los Angeles, CA', departure_date='2023-06-15', num_passengers=4, category='direct')]", "input_token_count": 3576, "output_token_count": 50, "latency": 26.756404161453247}
{"id": "live_multiple_888-184-5", "result": [{"Buses_3_FindBus": {"from_city": "Los Angeles, CA", "to_city": "San Diego, CA", "departure_date": "2023-10-01"}}], "input_token_count": 3595, "output_token_count": 56, "latency": 30.21723508834839}
{"id": "live_multiple_889-184-6", "result": "[Buses_3_FindBus(from_city='Miami, FL', to_city='Atlanta, GA', departure_date='2023-04-22', num_passengers=2, category='direct')]", "input_token_count": 3570, "output_token_count": 49, "latency": 26.169775009155273}
{"id": "live_multiple_890-185-0", "result": "[Payment_1_RequestPayment(receiver=\"Mahmoud\", amount=43, private_visibility=False)]", "input_token_count": 2591, "output_token_count": 25, "latency": 12.517858505249023}
{"id": "live_multiple_891-185-1", "result": "[Payment_1_RequestPayment(receiver=\"John Doe\", amount=250, private_visibility=True)]", "input_token_count": 2588, "output_token_count": 25, "latency": 12.516615390777588}
{"id": "live_multiple_892-185-2", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=100, receiver=\"\u746a\u9e97\", private_visibility=True)]", "input_token_count": 2594, "output_token_count": 32, "latency": 15.904640197753906}
{"id": "live_multiple_893-185-3", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=90, receiver=\"John Doe\")]", "input_token_count": 2586, "output_token_count": 26, "latency": 12.339497089385986}
{"id": "live_multiple_894-185-4", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=150.0, receiver=\"Alice\", private_visibility=True)]", "input_token_count": 2600, "output_token_count": 32, "latency": 16.168664932250977}
{"id": "live_multiple_895-185-5", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=50.0, receiver=\"\u6770\u91cc\", private_visibility=True)]", "input_token_count": 2593, "output_token_count": 32, "latency": 16.158372163772583}
{"id": "live_multiple_896-185-6", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=50.0, receiver=\"Margaret\")]", "input_token_count": 2587, "output_token_count": 28, "latency": 13.779164552688599}
{"id": "live_multiple_897-185-7", "result": "[Payment_1_RequestPayment(receiver=\"John\", amount=122)]", "input_token_count": 2594, "output_token_count": 19, "latency": 9.105136632919312}
{"id": "live_multiple_898-185-8", "result": "[Payment_1_RequestPayment(receiver=\"Jamie\", amount=50, private_visibility=True)]", "input_token_count": 2592, "output_token_count": 24, "latency": 11.845855474472046}
{"id": "live_multiple_899-185-9", "result": "[Payment_1_RequestPayment(receiver='Emma', amount=50, private_visibility=True)]", "input_token_count": 2601, "output_token_count": 23, "latency": 11.673571825027466}
{"id": "live_multiple_900-185-10", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=200.0, receiver=\"Alice\", private_visibility=True)]", "input_token_count": 2603, "output_token_count": 32, "latency": 17.43147325515747}
{"id": "live_multiple_901-185-11", "result": "[Payment_1_MakePayment(payment_method=\"app balance\", amount=31.0, receiver=\"Svetlana\")]", "input_token_count": 2606, "output_token_count": 29, "latency": 15.69203519821167}
{"id": "live_multiple_902-185-12", "result": "[Payment_1_MakePayment(payment_method=\"credit card\", amount=25.0, receiver=\"Alex\", private_visibility=False)]", "input_token_count": 2603, "output_token_count": 31, "latency": 17.4269278049469}
{"id": "live_multiple_903-186-0", "result": "[Trains_1_FindTrains(_from='Phoenix, AZ', to='Los Angeles, CA', date_of_journey='2023-04-25', _class='Value', number_of_adults=1)]", "input_token_count": 2820, "output_token_count": 55, "latency": 31.60770344734192}
{"id": "live_multiple_904-186-1", "result": "[Trains_1_FindTrains(_from='New York, NY', to='Los Angeles, CA', date_of_journey='03/04/2024', number_of_adults=2)]", "input_token_count": 2836, "output_token_count": 50, "latency": 28.695435047149658}
{"id": "live_multiple_905-186-2", "result": "[Trains_1_GetTrainTickets(_from='New York, NY', to='Seattle, WA', date_of_journey='2023-05-15', journey_start_time='10:00', number_of_adults=4, trip_protection=True, _class='Business')]", "input_token_count": 2842, "output_token_count": 70, "latency": 39.8987762928009}
{"id": "live_multiple_906-186-3", "result": "[Trains_1_GetTrainTickets(_from='New York, NY', to='Los Angeles, CA', date_of_journey='2023-05-05', journey_start_time='15:00', number_of_adults=2, trip_protection=True)]", "input_token_count": 2842, "output_token_count": 64, "latency": 37.57301068305969}
{"id": "live_multiple_907-186-4", "result": "[Trains_1_FindTrains(_from='Pennsylvania, PA', to='City, State', date_of_journey='2023-03-08', _class='Value', number_of_adults=1)]", "input_token_count": 2835, "output_token_count": 56, "latency": 33.10874533653259}
{"id": "live_multiple_908-187-0", "result": "[Travel_1_FindAttractions(location='New York, NY', free_entry='True', good_for_kids='True')]", "input_token_count": 3055, "output_token_count": 30, "latency": 17.865013360977173}
{"id": "live_multiple_909-188-0", "result": "[youtube.check_videos(title=\"Taj Mahal\u7684\u79d8\u5bc6\", publisher=\"Travel History\", tags=[\"Taj Mahal\", \"\u5370\u5ea6\", \"\u5efa\u7bc9\"])]", "input_token_count": 919, "output_token_count": 37, "latency": 21.632821083068848}
{"id": "live_multiple_910-189-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1820, "output_token_count": 10, "latency": 7.110614538192749}
{"id": "live_multiple_911-190-0", "result": "[view_service_provider_profile(service_id=1)]", "input_token_count": 2063, "output_token_count": 11, "latency": 7.8447511196136475}
{"id": "live_multiple_912-191-0", "result": "[get_service_providers(avg_rating=4, province_id=1, district_name='Bang Khen', service_id=2)]", "input_token_count": 2553, "output_token_count": 29, "latency": 17.896862745285034}
{"id": "live_multiple_913-191-1", "result": "[get_service_providers(avg_rating=4.9, province_id=1, district_name='Bangna', start_available_date='2024-03-19 12:00:00')]", "input_token_count": 2534, "output_token_count": 50, "latency": 30.217374324798584}
{"id": "live_multiple_914-191-2", "result": "[view_service_provider_profile(professional_id=9974)]", "input_token_count": 2532, "output_token_count": 16, "latency": 10.125799179077148}
{"id": "live_multiple_915-191-3", "result": "[get_service_providers(avg_rating=5.0, province_id=1, district_name=\"Lat Phrao\", is_package=True)]", "input_token_count": 2522, "output_token_count": 31, "latency": 19.201472520828247}
{"id": "live_multiple_916-191-4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_917-191-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_918-191-6", "result": "[get_service_providers(avg_rating=4.5, province_id=1, district_name='Bang Kruai', service_id=2)]", "input_token_count": 2510, "output_token_count": 31, "latency": 19.217223167419434}
{"id": "live_multiple_919-191-7", "result": "[get_service_providers(avg_rating=4, start_available_date='2024-03-19 12:00:00', is_cleaning_home=True, has_quality_problem=False)]", "input_token_count": 2558, "output_token_count": 49, "latency": 29.00187087059021}
{"id": "live_multiple_920-191-8", "result": "[get_service_providers(avg_rating=4, start_available_date='2024-02-23 10:30:00', end_available_date='2024-02-23 19:00:00', is_cleaning_home=True, has_quality_problem=False, has_late_check_in=False)]", "input_token_count": 2563, "output_token_count": 80, "latency": 46.30835175514221}
{"id": "live_multiple_921-191-9", "result": "[get_service_providers(province_id=2, district_name='Mueang', service_id=1)]", "input_token_count": 2522, "output_token_count": 24, "latency": 14.225839853286743}
{"id": "live_multiple_922-191-10", "result": "[get_service_providers(professional_group_id=2, min_age=25, max_age=35, has_late_check_in=False)]", "input_token_count": 2529, "output_token_count": 33, "latency": 19.769607543945312}
{"id": "live_multiple_923-191-11", "result": "[get_service_providers(avg_rating=4.5, province_id=1, district_name='Chatuchak', sub_district_name='null', start_available_date='2024-03-19 13:00:00', end_available_date='null', service_id=2)]", "input_token_count": 2526, "output_token_count": 68, "latency": 38.99085593223572}
{"id": "live_multiple_924-191-12", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_925-191-13", "result": "[view_service_provider_profile(professional_id=28)]", "input_token_count": 2499, "output_token_count": 14, "latency": 7.844788312911987}
{"id": "live_multiple_926-191-14", "result": "[get_service_providers(avg_rating=4.5, province_id=2, district_name='Hang Dong', sub_district_name='Chiang Mai', start_available_date='2024-03-25 14:30:00', end_available_date='2024-03-25 14:30:00', is_cleaning_home=True, available_for_pet=False)]", "input_token_count": 2546, "output_token_count": 94, "latency": 53.52307438850403}
{"id": "live_multiple_927-191-15", "result": "[get_service_providers(avg_rating=4.5, province_id=1, is_excellent=True)]", "input_token_count": 2538, "output_token_count": 25, "latency": 14.206906795501709}
{"id": "live_multiple_928-191-16", "result": "[get_service_providers(is_subscription=True, professional_group_id=2, has_late_check_in=False)]", "input_token_count": 2515, "output_token_count": 24, "latency": 13.024642705917358}
{"id": "live_multiple_929-191-17", "result": "[get_service_providers(avg_rating=4.7, province_id=2, district_name='Muang', sub_district_name='null', start_available_date='2024-03-19 09:30:00', end_available_date='null', is_cleaning_home=True)]", "input_token_count": 2539, "output_token_count": 68, "latency": 38.390928745269775}
{"id": "live_multiple_930-191-18", "result": "[get_service_providers(service_id=35)]", "input_token_count": 2500, "output_token_count": 12, "latency": 6.212080717086792}
{"id": "live_multiple_931-191-19", "result": "[get_service_providers(avg_rating=5, district_name='Phra Khanong', is_excellent=True)]", "input_token_count": 2514, "output_token_count": 26, "latency": 14.211369514465332}
{"id": "live_multiple_932-191-20", "result": "[view_service_provider_profile(professional_id=4724)]", "input_token_count": 2505, "output_token_count": 16, "latency": 8.271608591079712}
{"id": "live_multiple_933-191-21", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_934-191-22", "result": "[get_service_providers(avg_rating=4, province_id=1, district_name='Chatuchak', start_available_date='2024-03-22 00:00:00', service_id=1)]", "input_token_count": 2552, "output_token_count": 53, "latency": 30.507222414016724}
{"id": "live_multiple_935-192-0", "result": "[set_countdown(duration=\"00:01\")]", "input_token_count": 894, "output_token_count": 15, "latency": 7.694669961929321}
{"id": "live_multiple_936-192-1", "result": "[set_alarm(alarm_time='2023-04-02 07:30:00', purpose='Wake up for meeting')]", "input_token_count": 921, "output_token_count": 38, "latency": 22.002519130706787}
{"id": "live_multiple_937-193-0", "result": "[acl_api.AclApi.retrieve_projects(uuid='123E4567-E89B-12D3-A456-426614174000')]", "input_token_count": 1248, "output_token_count": 51, "latency": 29.39200258255005}
{"id": "live_multiple_938-194-0", "result": "[play_spotify_song(query='track:Shape of You artist:Ed Sheeran', volume=70)]", "input_token_count": 2048, "output_token_count": 26, "latency": 15.196479558944702}
{"id": "live_multiple_939-194-1", "result": "[set_alarm(alarm_time='23:00')]", "input_token_count": 2027, "output_token_count": 17, "latency": 9.136494398117065}
{"id": "live_multiple_940-194-2", "result": "[play_spotify_song(query='track:Baby Shark artist:Pinkfong Kids Songs')]", "input_token_count": 2022, "output_token_count": 24, "latency": 13.318944931030273}
{"id": "live_multiple_941-195-0", "result": "[play_song(query='track:\u73a9\u5b30\u5152\u9bca')]", "input_token_count": 780, "output_token_count": 20, "latency": 10.904693126678467}
{"id": "live_multiple_942-196-0", "result": "[play_song(query=\"\u73a9\u5b30\u5152\u9bca\", volume=70)]", "input_token_count": 924, "output_token_count": 22, "latency": 12.10111927986145}
{"id": "live_multiple_943-196-1", "result": "[play_song(query=\"\u548c\u4f60\", volume=70)]", "input_token_count": 922, "output_token_count": 15, "latency": 7.926942348480225}
{"id": "live_multiple_944-196-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_945-196-3", "result": "[play_song(query=\"Wo Noor\")]", "input_token_count": 924, "output_token_count": 11, "latency": 5.927732944488525}
{"id": "live_multiple_946-196-4", "result": "[play_song(query=\"\u9a5a\u609a\u7247\", volume=70)]", "input_token_count": 949, "output_token_count": 17, "latency": 9.468912601470947}
{"id": "live_multiple_947-197-0", "result": "[set_countdown(duration=\"5 minutes\", purpose=\"Remind me to send a message to Rajh\")]", "input_token_count": 2065, "output_token_count": 25, "latency": 15.019298315048218}
{"id": "live_multiple_948-198-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_949-199-0", "result": "[play_song(query=\"David Guetta\")]", "input_token_count": 1250, "output_token_count": 12, "latency": 7.176690101623535}
{"id": "live_multiple_950-199-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_951-200-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1792, "output_token_count": 10, "latency": 5.983411073684692}
{"id": "live_multiple_952-201-0", "result": [{"uber.eat.order": {"restaurant": "Mc Donalds", "items": ["\u85af\u689d"], "quantities": [5]}}], "input_token_count": 1140, "output_token_count": 40, "latency": 24.267009496688843}
{"id": "live_multiple_953-201-1", "result": "[flight.status.check(flight_identifier=\"IND5463\", passenger_name=\"Karan\", ticket_number=\"IND5463\")]", "input_token_count": 1164, "output_token_count": 32, "latency": 19.545504093170166}
{"id": "live_multiple_954-202-0", "result": [{"flight.status.check": {"airlines": "Delta", "person_name": "Karan Sharma", "ticket_number": "Ind4567"}}], "input_token_count": 1099, "output_token_count": 41, "latency": 24.08573079109192}
{"id": "live_multiple_955-202-1", "result": [{"uber.eat.order": {"restaurant": "Mc Donalds", "items": ["\u85af\u689d"], "quantities": [5]}}], "input_token_count": 1069, "output_token_count": 40, "latency": 23.52865481376648}
{"id": "live_multiple_956-203-0", "result": "[partner.mandates(status=\"all\")]", "input_token_count": 941, "output_token_count": 11, "latency": 6.480118036270142}
{"id": "live_multiple_957-203-1", "result": "[partner.mandates(status=\"active\")]", "input_token_count": 946, "output_token_count": 11, "latency": 6.559577465057373}
{"id": "live_multiple_958-204-0", "result": "[partner.sips(status=\"active\")]", "input_token_count": 1194, "output_token_count": 10, "latency": 5.955791234970093}
{"id": "live_multiple_959-204-1", "result": "[partner.sips(status=\"active\")]", "input_token_count": 1190, "output_token_count": 10, "latency": 6.210034370422363}
{"id": "live_multiple_960-205-0", "result": "[get_current_weather(location=\"New York, NY\")]", "input_token_count": 1007, "output_token_count": 14, "latency": 8.613612174987793}
{"id": "live_multiple_961-205-1", "result": [{"web_search": {"query": "\u5317\u4eac\u5728\u54ea\u88e1"}}], "input_token_count": 1013, "output_token_count": 23, "latency": 14.059184551239014}
{"id": "live_multiple_962-205-2", "result": [{"web_search": {"query": "\u54e5\u502b\u6bd4\u4e9e\u5927\u5b78\u4f4d\u7f6e"}}], "input_token_count": 1016, "output_token_count": 26, "latency": 16.355555057525635}
{"id": "live_multiple_963-206-0", "result": [{"GET_PARCEL_STATE": {"parcelTrackingId": "TX1234567890"}}], "input_token_count": 1235, "output_token_count": 36, "latency": 22.092582941055298}
{"id": "live_multiple_964-207-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_965-207-1", "result": [{"transfer_to_human_agent": {"statement": "\u6211\u5df2\u7d93\u63d0\u4ea4\u4e86\u6295\u8a34\uff0c\u4e26\u60f3\u8207\u4eba\u985e\u4ee3\u7406\u5546\u8a0e\u8ad6\u5176\u72c0\u6cc1\u3002"}}], "input_token_count": 793, "output_token_count": 47, "latency": 27.787970066070557}
{"id": "live_multiple_966-208-0", "result": "[answer_question(statement=\"\u6211\u5df2\u7d93\u63d0\u4ea4\u4e86\u6295\u8a34\uff0c\u6211\u60f3\u8207\u4eba\u985e\u4ee3\u7406\u4eba\u6aa2\u67e5\u5176\u7576\u524d\u72c0\u614b\u3002\", urgency_level=\"medium\", language=\"English\")]", "input_token_count": 1491, "output_token_count": 45, "latency": 26.654027223587036}
{"id": "live_multiple_967-209-0", "result": [{"transfer_to_human_agent": {"statement": "\u6211\u5e0c\u671b\u8207\u4eba\u985e\u4ee3\u7406\u5546\u8a0e\u8ad6\u6211\u7684\u6295\u8a34\u72c0\u6cc1\u3002", "urgency": "high", "language": "English"}}], "input_token_count": 1184, "output_token_count": 53, "latency": 31.707441091537476}
{"id": "live_multiple_968-210-0", "result": [{"uber.ride": {"loc": "2020 Addison Street, Berkeley, CA", "type": "plus", "time": 10}}], "input_token_count": 1115, "output_token_count": 42, "latency": 25.077231884002686}
{"id": "live_multiple_969-210-1", "result": [{"uber.eat.order": {"restaurant": "McDonald's, 123 Fastfood Lane, Chicago, IL", "items": ["Big Mac", "Fries", "Coke"]}}], "input_token_count": 1122, "output_token_count": 53, "latency": 31.245349645614624}
{"id": "live_multiple_970-211-0", "result": "[fmp.income_statement(symbol='AAPL', period='annual', limit=2)]", "input_token_count": 1321, "output_token_count": 23, "latency": 15.462267637252808}
{"id": "live_multiple_971-212-0", "result": "[get_service_providers(province_id=1, is_cleaning_home=True)]", "input_token_count": 2466, "output_token_count": 18, "latency": 12.564356803894043}
{"id": "live_multiple_972-212-1", "result": "[get_service_providers(avg_rating=5, province_id=1)]", "input_token_count": 2469, "output_token_count": 17, "latency": 11.995246410369873}
{"id": "live_multiple_973-213-0", "result": "[get_service_providers(province_id=1, service_ids=[2])]", "input_token_count": 2307, "output_token_count": 18, "latency": 13.148507595062256}
{"id": "live_multiple_974-214-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_975-214-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_976-215-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_977-215-1", "result": [{"get_service_providers": {"province_id": 1, "start_available_date": "2024-03-22 11:00:00", "end_available_date": "2024-03-22 13:00:00"}}], "input_token_count": 2627, "output_token_count": 74, "latency": 45.159632444381714}
{"id": "live_multiple_978-215-2", "result": "[get_service_providers(province_id=1, district_name='Bang Mueng District', start_available_date='2024-03-23 15:00:00', avg_rating=4.7, job_qty=100)]", "input_token_count": 2660, "output_token_count": 59, "latency": 36.17451047897339}
{"id": "live_multiple_979-215-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_980-215-4", "result": [{"get_service_providers": {"province_id": 1, "district_name": "Phaya Thai District", "service_id": 24}}], "input_token_count": 2624, "output_token_count": 40, "latency": 25.519670963287354}
{"id": "live_multiple_981-215-5", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_982-215-6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_983-215-7", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_984-215-8", "result": "[get_service_providers(province_id=1)]", "input_token_count": 2601, "output_token_count": 12, "latency": 8.470128536224365}
{"id": "live_multiple_985-216-0", "result": "[reminders_complete(token='1231289312')]", "input_token_count": 13015, "output_token_count": 19, "latency": 17.096936464309692}
{"id": "live_multiple_986-217-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1939, "output_token_count": 10, "latency": 7.8936450481414795}
{"id": "live_multiple_987-218-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 1999, "output_token_count": 10, "latency": 11.931450366973877}
{"id": "live_multiple_988-219-0", "result": "[EventSettingsApi.get_event_specification_infos_by_ids(event_ids=[\"EFJG9\"])]", "input_token_count": 1042, "output_token_count": 22, "latency": 18.200437545776367}
{"id": "live_multiple_989-220-0", "result": "[get_websites(status_filter=\"active\", include_metadata=True)]", "input_token_count": 1168, "output_token_count": 15, "latency": 15.34301209449768}
{"id": "live_multiple_990-221-0", "result": "[releases_api.ReleasesApi.delete_release(releaseId='RL50')]", "input_token_count": 1146, "output_token_count": 19, "latency": 17.596002340316772}
{"id": "live_multiple_991-222-0", "result": "[website_configuration_api.WebsiteConfigurationApi.rename_website(websiteId=\"1234\", name=\"\u9b91\u52c3\")]", "input_token_count": 988, "output_token_count": 30, "latency": 24.81543231010437}
{"id": "live_multiple_992-223-0", "result": "[delete_apdex_configuration(id=\"D0404\")]", "input_token_count": 1482, "output_token_count": 15, "latency": 15.91882061958313}
{"id": "live_multiple_993-224-0", "result": "[get_apdex_report(apdexId=\"NS9934\", _from=1617176400000, to=1617262800000)]", "input_token_count": 1607, "output_token_count": 50, "latency": 34.33068490028381}
{"id": "live_multiple_994-225-0", "result": [{"EventSettingsApi.restore_mobile_app_alert_config": {"id": "SL8", "created": "2023-03-05T16:45:00Z"}}], "input_token_count": 1196, "output_token_count": 54, "latency": 38.2287015914917}
{"id": "live_multiple_995-226-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_996-227-0", "result": "[add_service_config(service_name=\"FDSA\", configurations={\"timeout\": 30, \"retry_count\": 5, \"endpoint\": \"https://api.fdsa-service.com\", \"auth_required\": true})]", "input_token_count": 1646, "output_token_count": 47, "latency": 35.42534589767456}
{"id": "live_multiple_997-228-0", "result": "[usage_api.UsageApi.get_hosts_per_day(day=15, month=2, year=2022)]", "input_token_count": 1475, "output_token_count": 28, "latency": 24.820263385772705}
{"id": "live_multiple_998-229-0", "result": "[health_api.HealthApi.get_version()]", "input_token_count": 2024, "output_token_count": 10, "latency": 15.896145105361938}
{"id": "live_multiple_999-230-0", "result": "[health_api.HealthApi.get_version()]", "input_token_count": 2266, "output_token_count": 10, "latency": 15.360539197921753}
{"id": "live_multiple_1000-231-0", "result": "[get_maintenance_configs_v2(page=1, limit=10)]", "input_token_count": 1341, "output_token_count": 18, "latency": 20.318395137786865}
{"id": "live_multiple_1001-232-0", "result": "[api_token_api.APITokenApi.get_api_tokens(user_id='098-293')]", "input_token_count": 1355, "output_token_count": 25, "latency": 24.8001971244812}
{"id": "live_multiple_1002-232-1", "result": "[api_token_api.APITokenApi.get_api_tokens(user_id=\"\u7528\u6236123\")]", "input_token_count": 1374, "output_token_count": 24, "latency": 24.218610763549805}
{"id": "live_multiple_1003-232-2", "result": "[api_token_api.APITokenApi.get_api_tokens(user_id=12345), CustomDashboardsApi.get_shareable_api_tokens(user_id=12345)]", "input_token_count": 1364, "output_token_count": 41, "latency": 34.239888429641724}
{"id": "live_multiple_1004-233-0", "result": "[audit_log_api.AuditLogApi.get_access_logs(offset=434, pageSize=9, query='Llama')]", "input_token_count": 1674, "output_token_count": 31, "latency": 28.13099503517151}
{"id": "live_multiple_1005-234-0", "result": "[host_agent_api.HostAgentApi.get_agent_snapshot(id='Zzwzeem', to='2023-10-01T00:00:00Z', windowSize=60)]", "input_token_count": 1475, "output_token_count": 48, "latency": 38.16322875022888}
{"id": "live_multiple_1006-235-0", "result": "[get_monitoring_state(api_key=\"Gorilla-123\")]", "input_token_count": 1172, "output_token_count": 18, "latency": 20.267863273620605}
{"id": "live_multiple_1007-236-0", "result": "[software_versions(type=\"runtime\", version=\"5.5\")]", "input_token_count": 1424, "output_token_count": 16, "latency": 20.2619411945343}
{"id": "live_multiple_1008-237-0", "result": "[ApplicationAnalyzeApi.get_trace_download(id=\"GRGR\", retrievalSize=1024)]", "input_token_count": 1333, "output_token_count": 22, "latency": 24.167359828948975}
{"id": "live_multiple_1009-238-0", "result": "[get_website_geo_mapping_rules(websiteId='123E4567-E89B-12D3-A456-426614174000')]", "input_token_count": 1134, "output_token_count": 49, "latency": 39.817639112472534}
{"id": "live_multiple_1010-239-0", "result": "[CustomDashboardsApi.get_custom_dashboards(query=\"\u885d\u523a\")]", "input_token_count": 1371, "output_token_count": 19, "latency": 22.468279361724854}
{"id": "live_multiple_1011-240-0", "result": "[get_synthetic_credential_names(filter='active', sort_order='asc')]", "input_token_count": 1256, "output_token_count": 19, "latency": 22.457090616226196}
{"id": "live_multiple_1012-241-0", "result": "[get_synthetic_locations(sort='created_at', offset=0, limit=50)]", "input_token_count": 1522, "output_token_count": 22, "latency": 25.263999462127686}
{"id": "live_multiple_1013-242-0", "result": "[get_synthetic_locations(sort='asc', filter='name:Alpha, name:Beta, name:Gamma')]", "input_token_count": 1412, "output_token_count": 27, "latency": 28.589850187301636}
{"id": "live_multiple_1014-243-0", "result": "[get_identity_provider_patch(tenant_id=\"12345-Tenant-id\")]", "input_token_count": 1718, "output_token_count": 22, "latency": 25.227379322052002}
{"id": "live_multiple_1015-244-0", "result": "[audit_log_api.AuditLogApi.get_access_logs(offset=0, pageSize=50)]", "input_token_count": 1334, "output_token_count": 24, "latency": 25.786848783493042}
{"id": "live_multiple_1016-245-0", "result": "[create_global_application_alert_config(name=\"urgentalert77f7\", alert_type=\"error_rate\", threshold=5.0, recipients=[\"admin@example.com\", \"support@example.com\"])]", "input_token_count": 1551, "output_token_count": 42, "latency": 37.51621127128601}
{"id": "live_multiple_1017-246-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_1018-247-0", "result": "[website_configuration_api.get_websites(api_key=\"your_api_key\")]", "input_token_count": 1318, "output_token_count": 17, "latency": 23.487298488616943}
{"id": "live_multiple_1019-248-0", "result": "[releases_api.ReleasesApi.delete_release(releaseId='RL50')]", "input_token_count": 1397, "output_token_count": 19, "latency": 24.52286148071289}
{"id": "live_multiple_1020-249-0", "result": "[delete_apdex_configuration(id=\"D0404\")]", "input_token_count": 1270, "output_token_count": 15, "latency": 21.71043872833252}
{"id": "live_multiple_1021-250-0", "result": [{"restore_mobile_app_alert_config": {"id": "SL8", "created": "2023-04-01T10:00:00Z"}}], "input_token_count": 1482, "output_token_count": 51, "latency": 42.87332534790039}
{"id": "live_multiple_1022-251-0", "result": "[get_hosts_per_month(month=2, year=2022)]", "input_token_count": 1426, "output_token_count": 19, "latency": 24.397677421569824}
{"id": "live_multiple_1023-252-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 2508, "output_token_count": 10, "latency": 19.84817862510681}
{"id": "live_multiple_1024-253-0", "result": "[find_infra_alert_config_versions(id=\"Delta\")]", "input_token_count": 1995, "output_token_count": 15, "latency": 23.227678298950195}
{"id": "live_multiple_1025-254-0", "result": "[get_maintenance_configs()]", "input_token_count": 1133, "output_token_count": 8, "latency": 18.702178955078125}
{"id": "live_multiple_1026-255-0", "result": "[CustomDashboardsApi.get_shareable_api_tokens(user_id=123456789)]", "input_token_count": 1502, "output_token_count": 25, "latency": 28.766051054000854}
{"id": "live_multiple_1027-255-1", "result": "[api_token_api.APITokenApi.get_api_tokens(page=1, page_size=20)]", "input_token_count": 1489, "output_token_count": 23, "latency": 28.182816982269287}
{"id": "live_multiple_1028-256-0", "result": "[host_agent_api.get_agent_snapshot(id='Zzwzee', windowSize=60)]", "input_token_count": 1409, "output_token_count": 21, "latency": 26.523854732513428}
{"id": "live_multiple_1029-257-0", "result": "[InfrastructureResourcesApi.software_versions(time='2023-04-01 12:00:00', version='5.5')]", "input_token_count": 1597, "output_token_count": 39, "latency": 37.13726186752319}
{"id": "live_multiple_1030-258-0", "result": "[get_website_geo_mapping_rules(websiteId=\"larry_rotter\")]", "input_token_count": 1144, "output_token_count": 20, "latency": 25.96941614151001}
{"id": "live_multiple_1031-259-0", "result": "[get_custom_dashboard(customDashboardId=\"12345\")]", "input_token_count": 1293, "output_token_count": 18, "latency": 25.400502681732178}
{"id": "live_multiple_1032-260-0", "result": "[get_synthetic_locations(limit=5)]", "input_token_count": 1261, "output_token_count": 12, "latency": 22.043138027191162}
{"id": "live_multiple_1033-261-0", "result": "[SyntheticSettingsApi.get_synthetic_locations(limit=20, filter=\"alpha,beta,gamma\")]", "input_token_count": 1306, "output_token_count": 26, "latency": 29.26305890083313}
{"id": "live_multiple_1034-262-0", "result": "[audit_log_api.AuditLogApi.get_access_logs(offset=0, pageSize=50)]", "input_token_count": 1601, "output_token_count": 24, "latency": 28.687339782714844}
{"id": "live_multiple_1035-263-0", "result": "[api_token_api.APITokenApi.get_api_tokens(user_id=12345)]", "input_token_count": 1246, "output_token_count": 22, "latency": 28.12472414970398}
{"id": "live_multiple_1036-263-1", "result": "[api_token_api.APITokenApi.get_api_tokens(user_id=12345)]", "input_token_count": 1238, "output_token_count": 22, "latency": 27.58322262763977}
{"id": "live_multiple_1037-264-0", "result": "[calendar_event_create(start_date='2024-12-01', start_time='19:00', duration=120)]", "input_token_count": 2841, "output_token_count": 34, "latency": 34.83271503448486}
{"id": "live_multiple_1038-265-0", "result": "[detail_project(project_name=\"invoice-website\", include_status=True, start_date=\"2021-06-15\")]", "input_token_count": 3048, "output_token_count": 30, "latency": 32.57971811294556}
{"id": "live_multiple_1039-266-0", "result": "[detail_experience_and_education(experience_or_education_type=\"Education at Universitas Sebelas Maret (UNS)\")]", "input_token_count": 3018, "output_token_count": 27, "latency": 29.7543466091156}
{"id": "live_multiple_1040-267-0", "result": "[detail_experience_and_education(experience_or_education_type=\"Education at Universitas Sebelas Maret (UNS)\")]", "input_token_count": 3031, "output_token_count": 27, "latency": 29.74741005897522}
{"id": "live_multiple_1041-268-0", "result": "[get_sensor_readings_history(timespan=36000, t0='2023-01-01T10:00:00Z')]", "input_token_count": 3897, "output_token_count": 42, "latency": 39.262481451034546}
{"id": "live_multiple_1042-269-0", "result": [{"Weather_1_GetWeather": {"city": "Portland, OR", "date": "2023-04-05"}}], "input_token_count": 3612, "output_token_count": 40, "latency": 38.69038653373718}
{"id": "live_multiple_1043-270-0", "result": [{"Weather_1_GetWeather": {"city": "\u99ac\u6b47\u723e"}}], "input_token_count": 3611, "output_token_count": 25, "latency": 30.28112554550171}
{"id": "live_multiple_1044-271-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_1045-272-0", "result": [{"Services_4_FindProvider": {"city": "Lafayette, CA", "type": "Family Counselor", "insurance_accepted": true}}], "input_token_count": 1711, "output_token_count": 43, "latency": 40.32119345664978}
{"id": "live_multiple_1046-273-0", "result": "[Hotels_2_SearchHouse(where_to='Delhi, IN', number_of_adults=2, rating=4.6)]", "input_token_count": 1327, "output_token_count": 32, "latency": 33.625813722610474}
{"id": "live_multiple_1047-274-0", "result": "[Hotels_2_SearchHouse(where_to='Cape Town, South Africa', number_of_adults=2)]", "input_token_count": 1352, "output_token_count": 28, "latency": 31.370545864105225}
{"id": "live_multiple_1048-275-0", "result": "[Hotels_2_SearchHouse(where_to='Paris, France', number_of_adults=2)]", "input_token_count": 1318, "output_token_count": 25, "latency": 27.471105098724365}
{"id": "live_multiple_1049-276-0", "result": "[Trains_1_FindTrains(_from=\"New York, NY\", to=\"Berkeley, CA\", date_of_journey=\"04/10/2023\")]", "input_token_count": 4621, "output_token_count": 43, "latency": 38.54286980628967}
{"id": "live_multiple_1050-277-0", "result": [{"Weather_1_GetWeather": {"city": "Atlanta, GA", "date": "2023-03-07"}}], "input_token_count": 1804, "output_token_count": 39, "latency": 36.86749196052551}
{"id": "live_multiple_1051-278-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_multiple_1052-279-0", "result": "[set_volume(volume=50), play_song(query=\"AP Dillon \u4e0e\u60a8\", volume=50)]", "input_token_count": 936, "output_token_count": 26, "latency": 28.49022626876831}
