{"id": "java_0", "result": [{"GeometryPresentation.createPresentation": {"controller": "mapController", "parent": "maparea"}}], "input_token_count": 701, "output_token_count": 29, "latency": 15.910497426986694}
{"id": "java_1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_2", "result": [{"FireBirdUtils.getViewSourceWithHeader": {"monitor": "dbMonitor", "view": "status", "source": "select * from status where status = 'active'"}}], "input_token_count": 802, "output_token_count": 47, "latency": 25.13893747329712}
{"id": "java_3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_4", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_5", "result": [{"PlainTextPresentation.createPresentation": {"controller": "datacontroller", "parent": "CompoteParent"}}], "input_token_count": 741, "output_token_count": 33, "latency": 18.729915380477905}
{"id": "java_6", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_7", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_8", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_9", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_10", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_11", "result": [{"BasePolicyDataProvider.getRegistryPolicyValue": {"root": "HKEY_LOCAL_MACHINE", "property": "EnableExtensions"}}], "input_token_count": 710, "output_token_count": 37, "latency": 19.893006324768066}
{"id": "java_12", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_13", "result": [{"AltibaseGrantee.prepareObjectsStatement": {"session": "jdbc_session", "owner": "Johndoe"}}], "input_token_count": 724, "output_token_count": 34, "latency": 18.24715542793274}
{"id": "java_14", "result": [{"FunGameBase.onFinish": {"layout": "gamelayout object", "success": "true"}}], "input_token_count": 680, "output_token_count": 31, "latency": 17.721688270568848}
{"id": "java_15", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_16", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_17", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_18", "result": "[SysRoleController.queryPageRoleCount(pageNo=3, pageSize=20)]", "input_token_count": 708, "output_token_count": 20, "latency": 11.851304054260254}
{"id": "java_19", "result": [{"PersonController.personal": {"model": "webModel", "request": "john_doe"}}], "input_token_count": 713, "output_token_count": 31, "latency": 17.176735639572144}
{"id": "java_20", "result": [{"HbaseAdapter.updateConfig": {"fileName": "\u7528\u6236\u6620\u5c04", "config": "newMappingConfig"}}], "input_token_count": 711, "output_token_count": 35, "latency": 19.418158292770386}
{"id": "java_21", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_22", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_23", "result": "[SmsHomeNewProductServiceImpl.list(productName=\"LED\u96fb\u8996\", recommendStatus=\"1\", pageSize=\"20\", pageNum=\"3\")]", "input_token_count": 921, "output_token_count": 33, "latency": 18.347273111343384}
{"id": "java_24", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_25", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_26", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_27", "result": "[TwoSum.twoSum(nums=\"[2, 7, 11, 15]\", target=\"9\")]", "input_token_count": 686, "output_token_count": 28, "latency": 16.1134831905365}
{"id": "java_28", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_29", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_30", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_31", "result": "[RedissonRx.getQueue(name=\"Taskqueue\", codec=\"com.example.MyCustomCodec\")]", "input_token_count": 664, "output_token_count": 21, "latency": 12.916814804077148}
{"id": "java_32", "result": "[RedissonPermitExpirableSemaphore.tryAcquireAsync(waitTime=\"5000\", leaseTime=\"120000\", unit=\"SECONDS\")]", "input_token_count": 847, "output_token_count": 42, "latency": 23.55784249305725}
{"id": "java_33", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_34", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_35", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_36", "result": [{"ObjectMapEntryReplayDecoder.decode": {"parts": "['userId', 42, 'username', 'johndoe', 'iSActive', true]", "state": "null"}}], "input_token_count": 727, "output_token_count": 52, "latency": 29.233993530273438}
{"id": "java_37", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_38", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_39", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_40", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_41", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_42", "result": [{"TermQueryBuilderTests.termQuery": {"mapper": "usernamefield", "value": "Johndoe", "caseInsensitive": "true"}}], "input_token_count": 801, "output_token_count": 41, "latency": 23.28364109992981}
{"id": "java_43", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_44", "result": "[DesAPITest.init(crypt=\"DESede\", mode=\"CBC\", padding=\"PKCS5Padding\")]", "input_token_count": 812, "output_token_count": 27, "latency": 16.738301038742065}
{"id": "java_45", "result": [{"Basic.checkSizes": {"environ": "endvariables", "size": "5"}}], "input_token_count": 661, "output_token_count": 27, "latency": 17.28780221939087}
{"id": "java_46", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_47", "result": [{"LargeHandshakeTest.format": {"name": "\u8b49\u66f8", "value": "Miifdtccbf2gawibagissg"}}], "input_token_count": 735, "output_token_count": 41, "latency": 23.284526586532593}
{"id": "java_48", "result": [{"CookieHeaderTest.create": {"sa": "192.168.1.10:8080", "sslContext": "TestsslContext"}}], "input_token_count": 807, "output_token_count": 46, "latency": 26.59689164161682}
{"id": "java_49", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_50", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_51", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_52", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_53", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_54", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_55", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_56", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_57", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_58", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_59", "result": [{"TruncateTranslogAction.execute": {"terminal": "Terminal", "shardPath": "/var/var/var/var/data/lasticsearch/nodes/nodes/nodes/nodices/indices/indices/indices/indices/indices/indices/index/index/index/index/index", "indexDirectory": "/var/data/lasticsearch/0/indices/1shard"}}], "input_token_count": 985, "output_token_count": 86, "latency": 33.932852268218994}
{"id": "java_60", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_61", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_62", "result": [{"dvRangeQuery": {"field": "\u6eab\u5ea6", "queryType": "FLOAT", "from": "20.5", "to": "30.0", "includeFrom": "true", "includeTo": "false"}}], "input_token_count": 1139, "output_token_count": 62, "latency": 28.131726026535034}
{"id": "java_63", "result": "[withinQuery(field=\"\u5e74\u9f61\", from=\"30\", to=\"40\", includeFrom=\"true\", includeTo=\"false\")]", "input_token_count": 1024, "output_token_count": 31, "latency": 17.685124397277832}
{"id": "java_64", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_65", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_66", "result": "[CompositeRuntimeField.createChildRuntimeField(parserContext=\"MappingParserContext\", parent=\"CompositeField1\", parentScriptFactory=\"CompoSitesscriptFactory\", onScriptError=\"OnScripterRor.ignore\")]", "input_token_count": 955, "output_token_count": 49, "latency": 25.801403999328613}
{"id": "java_67", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_68", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_69", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_70", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_71", "result": [{"CoroutineManager.co_exit_to": {"arg_object": "ResultData", "thisCoroutine": "5", "toCoroutine": "10"}}], "input_token_count": 858, "output_token_count": 39, "latency": 22.333608388900757}
{"id": "java_72", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_73", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_74", "result": [{"BaseMarkupSerializer.surrogates": {"high": "55357", "low": "56832", "inContent": "false"}}], "input_token_count": 810, "output_token_count": 46, "latency": 24.27692198753357}
{"id": "java_75", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_76", "result": [{"Intro.step": {"w": "800", "h": "600"}}], "input_token_count": 636, "output_token_count": 29, "latency": 16.85216498374939}
{"id": "java_77", "result": [{"JndiLoginModule.verifyPassword": {"encryptedPassword": "e3b0c44298fc1c149afbf4c8996fb92427ae41E4649B934CA495991B7852B855", "password": "P@ssw0rd!"}}], "input_token_count": 722, "output_token_count": 94, "latency": 38.042232513427734}
{"id": "java_78", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_79", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_80", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_81", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_82", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_83", "result": [{"thrcputime002.runIt": {"argv": "-waitTime, 2, -iterations, 500", "out": "System.Out"}}], "input_token_count": 827, "output_token_count": 47, "latency": 21.50350069999695}
{"id": "java_84", "result": [{"checkInnerFields": {"redefCls": "myredefclass", "expValue": "100"}}], "input_token_count": 712, "output_token_count": 34, "latency": 18.535497426986694}
{"id": "java_85", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_86", "result": [{"argumenttypes001.runThis": {"argv": "['-v', '-no-strict']", "out": "debugOutput"}}], "input_token_count": 744, "output_token_count": 39, "latency": 20.813363790512085}
{"id": "java_87", "result": "[suspendpolicy017.settingVMDeathRequest(suspendPolicy=\"event_thread\", property=\"DeathEvent001\")]", "input_token_count": 708, "output_token_count": 28, "latency": 15.244394063949585}
{"id": "java_88", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_89", "result": [{"runThis": {"argv": "-waitTime, 2, -debuggeeName, testDebuggee", "out": "testLogstream"}}], "input_token_count": 802, "output_token_count": 42, "latency": 20.077893495559692}
{"id": "java_90", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_91", "result": [{"invokemethod007.runIt": {"args": "['susteend', 'log']", "out": "debuglog"}}], "input_token_count": 732, "output_token_count": 40, "latency": 18.997263431549072}
{"id": "java_92", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_93", "result": [{"AbstractJarAgent.runJarAgent": {"options": "track,log", "inst": "AppInstrumentation"}}], "input_token_count": 731, "output_token_count": 33, "latency": 16.921518087387085}
{"id": "java_94", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_95", "result": [{"ExportNodeTest.doGeneric": {"receiver": "exportInlinedObject1Instance", "argument": "helloworld", "node": "iNobablenodeInstance", "library": "nodeLibraryInstance"}}], "input_token_count": 956, "output_token_count": 55, "latency": 19.24889349937439}
{"id": "java_96", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_97", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_98", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "java_99", "result": [{"LibraryExport.createDelegate": {"factory": "MyFactory", "delegate": "fasterdelegate"}}], "input_token_count": 714, "output_token_count": 30, "latency": 16.41787075996399}
