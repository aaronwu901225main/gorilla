{"id": "live_parallel_multiple_0-0-0", "result": "[ChaFod(foodItem=\"\u51f1\u6492\u6c99\u62c9\", removeIngredients=\"\u9cf3\u5c3e\u9b5a\"), ChaDri.change_drink(drink_id=\"123\", new_preferences={\"size\": \"large\", \"temperature\": \"hot\", \"sweetness_level\": \"regular\", \"milk_type\": \"almond\"})]", "input_token_count": 1512, "output_token_count": 75, "latency": 49.25827956199646}
{"id": "live_parallel_multiple_1-1-0", "result": "[get_current_weather(location=\"\u5ee3\u5dde\u5e02, China\"), get_current_weather(location=\"\u5317\u4eac\u5e02, China\")]", "input_token_count": 1695, "output_token_count": 26, "latency": 26.83928346633911}
{"id": "live_parallel_multiple_2-2-0", "result": "[ControlAppliance.execute(command=\"\uac70\uc2e4, \uc5d0\uc5b4\ucee8, \uc2e4\ud589\"), ControlAppliance.execute(command=\"\uce68\uc2e4, \uacf5\uae30\uccad\uc815\uae30, \uc911\uc9c0\")]", "input_token_count": 3075, "output_token_count": 36, "latency": 33.50605869293213}
{"id": "live_parallel_multiple_3-2-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_parallel_multiple_4-3-0", "result": "[get_news_report(location=\"Paris, France\", language=\"en\"), get_news_report(location=\"Letterkenny, Ireland\", category=\"Technology\", language=\"en\")]", "input_token_count": 1200, "output_token_count": 38, "latency": 35.15831685066223}
{"id": "live_parallel_multiple_5-4-0", "result": "[get_news_report(location=\"Paris, France\"), get_current_weather(location=\"Letskenny, Ireland\", unit=\"celsius\")]", "input_token_count": 921, "output_token_count": 30, "latency": 30.19616961479187}
{"id": "live_parallel_multiple_6-5-0", "result": "[get_interviewer_list(skill=\"Python\"), get_interviewer_list(skill=\"Java\")]", "input_token_count": 953, "output_token_count": 23, "latency": 26.3011474609375}
{"id": "live_parallel_multiple_7-6-0", "result": "[get_aws_pricing(memory=4, cpu=2), get_gcp_pricing(memory_gb=4, cpu_count=2)]", "input_token_count": 1158, "output_token_count": 33, "latency": 30.74929714202881}
{"id": "live_parallel_multiple_8-7-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_parallel_multiple_9-8-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_parallel_multiple_10-9-0", "result": "[recall_memory_search(query=\"Shishir's birthday\", request_heartbeat=true)]", "input_token_count": 3985, "output_token_count": 20, "latency": 25.713754177093506}
{"id": "live_parallel_multiple_11-10-0", "result": "[get_relevant_classes(search_string=\"cellResult\"), get_class_info(class_name=\"AbstractCellHandler\")]", "input_token_count": 2033, "output_token_count": 23, "latency": 26.275137424468994}
{"id": "live_parallel_multiple_12-10-1", "result": [{"get_class_info": {"class_name": "\u5929\u6c23"}}], "input_token_count": 1924, "output_token_count": 22, "latency": 27.39519953727722}
{"id": "live_parallel_multiple_13-11-0", "result": [{"math_gcd": {"a": 36, "b": 48}}, {"estimate_derivative": {"function": "lambda x: x**2", "x": 5}}], "input_token_count": 1082, "output_token_count": 57, "latency": 41.94244170188904}
{"id": "live_parallel_multiple_14-12-0", "result": "[math_gcd(a=36, b=48), estimate_derivative(function=lambda x: x**2, x=5)]", "input_token_count": 1036, "output_token_count": 31, "latency": 32.938217878341675}
{"id": "live_parallel_multiple_15-13-0", "result": "[sum(a=1, b=2), getCurrentTime(timezone=\"Europe/Berlin\", include_date=True)]", "input_token_count": 1119, "output_token_count": 26, "latency": 30.148730278015137}
{"id": "live_parallel_multiple_16-14-0", "result": "[get_area_of_square(size=5), get_current_weather(location='Singapore, Singapore')]", "input_token_count": 860, "output_token_count": 24, "latency": 28.492282390594482}
{"id": "live_parallel_multiple_17-15-0", "result": "[rotateImageAction(degrees=20), flipImageAction(flip_direction='horizontal')]", "input_token_count": 2568, "output_token_count": 22, "latency": 28.481043338775635}
{"id": "live_parallel_multiple_18-16-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_parallel_multiple_19-16-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_parallel_multiple_20-17-0", "result": [{"Events_3_FindEvents": {"event_type": "Music", "city": "New York, NY", "date": "2023-05-21"}}, {"Buses_3_FindBus": {"from_city": "Boston, MA", "to_city": "New York, NY", "departure_date": "2023-05-21", "num_passengers": 2, "category": "direct"}}], "input_token_count": 5445, "output_token_count": 115, "latency": 62.18938136100769}
{"id": "live_parallel_multiple_21-18-0", "result": [{"Services_1_FindProvider": {"city": "San Jose, CA"}}, {"Services_1_BookAppointment": {"stylist_name": "\u512a\u96c5\u98a8\u683c", "appointment_time": "15:00", "appointment_date": "2023-05-10"}}], "input_token_count": 1435, "output_token_count": 80, "latency": 51.965818643569946}
{"id": "live_parallel_multiple_22-19-0", "result": "[get_current_weather(location=\"Boston, MA\"), get_current_weather(location=\"Falls, CA\")]", "input_token_count": 3071, "output_token_count": 24, "latency": 33.48630690574646}
{"id": "live_parallel_multiple_23-20-0", "result": "[partner.mandates(status=\"pending\"), partner.mandates(status=\"active\")]", "input_token_count": 911, "output_token_count": 19, "latency": 29.575570583343506}
