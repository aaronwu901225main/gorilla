{"id": "live_simple_0-0-0", "result": "[get_user_info(user_id=7890, special=\"black\")]", "input_token_count": 563, "output_token_count": 18, "latency": 28.26097822189331}
{"id": "live_simple_1-1-0", "result": [{"github_star": {"repos": "Shishirpatil/Gorilla,Gorilla-llm/Gorilla-Cli", "aligned": true}}], "input_token_count": 686, "output_token_count": 44, "latency": 38.66479158401489}
{"id": "live_simple_2-2-0", "result": [{"uber.ride": {"loc": "2020, California, Berkeley, USA", "type": "comfort", "time": 600}}], "input_token_count": 691, "output_token_count": 43, "latency": 37.53671908378601}
{"id": "live_simple_3-2-1", "result": [{"uber.ride": {"loc": "221B Baker Street, Berkeley, CA, USA", "type": "plus", "time": 600}}], "input_token_count": 684, "output_token_count": 45, "latency": 38.09417700767517}
{"id": "live_simple_4-3-0", "result": "[get_current_weather(location=\"Tel Aviv, Israel\", unit=\"fahrenheit\")]", "input_token_count": 652, "output_token_count": 19, "latency": 28.241451740264893}
{"id": "live_simple_5-3-1", "result": [{"get_current_weather": {"location": "Divin\u00f3polis, MG", "unit": "fahrenheit"}}], "input_token_count": 619, "output_token_count": 33, "latency": 32.37315487861633}
{"id": "live_simple_6-3-2", "result": [{"get_current_weather": {"location": "San Francisco, CA", "unit": "fahrenheit"}}], "input_token_count": 658, "output_token_count": 31, "latency": 31.1106538772583}
{"id": "live_simple_7-3-3", "result": "[get_current_weather(location=\"Riga, Latvia\")]", "input_token_count": 651, "output_token_count": 14, "latency": 25.37936520576477}
{"id": "live_simple_8-3-4", "result": [{"get_current_weather": {"location": "London, UK"}}], "input_token_count": 643, "output_token_count": 23, "latency": 28.152438163757324}
{"id": "live_simple_9-3-5", "result": "[get_current_weather(location=\"Hyderabad, India\")]", "input_token_count": 636, "output_token_count": 14, "latency": 24.286900281906128}
{"id": "live_simple_10-3-6", "result": [{"get_current_weather": {"location": "Mariposa, CA", "unit": "celsius"}}], "input_token_count": 680, "output_token_count": 32, "latency": 30.211097955703735}
{"id": "live_simple_11-3-7", "result": [{"get_current_weather": {"location": "\u4f5b\u7f85\u91cc\u9054\u90a3\u4e0d\u52d2\u65af", "unit": "fahrenheit"}}], "input_token_count": 667, "output_token_count": 35, "latency": 30.199074029922485}
{"id": "live_simple_12-3-8", "result": [{"get_current_weather": {"location": "New York, NY", "unit": "celsius"}}], "input_token_count": 672, "output_token_count": 31, "latency": 27.403551816940308}
{"id": "live_simple_13-3-9", "result": "[get_current_weather(location=\"\u4e0a\u6d77, \u4e2d\u56fd\", unit=\"celsius\")]", "input_token_count": 690, "output_token_count": 18, "latency": 22.74989891052246}
{"id": "live_simple_14-3-10", "result": "[get_current_weather(location=\"Bangkok, Thailand\", unit=\"fahrenheit\")]", "input_token_count": 667, "output_token_count": 19, "latency": 22.850631952285767}
{"id": "live_simple_15-3-11", "result": "[get_current_weather(location=\"Chennai, Tamil Nadu\", unit=\"fahrenheit\")]", "input_token_count": 650, "output_token_count": 20, "latency": 23.13474941253662}
{"id": "live_simple_16-3-12", "result": "[get_current_weather(location=\"San Francisco, CA\")]", "input_token_count": 642, "output_token_count": 14, "latency": 20.423954963684082}
{"id": "live_simple_17-3-13", "result": "[get_current_weather(location=\"\u6ce2\u58eb\u9813, MA\")]", "input_token_count": 637, "output_token_count": 15, "latency": 20.977450847625732}
{"id": "live_simple_18-3-14", "result": "[get_current_weather(location=\"Moscow, Russia\", unit=\"celsius\")]", "input_token_count": 652, "output_token_count": 20, "latency": 22.55061388015747}
{"id": "live_simple_19-3-15", "result": [{"get_current_weather": {"location": "\u91d1\u5854\u7d0d\u00b7\u7f85\u5967, Mexico", "unit": "celsius"}}], "input_token_count": 692, "output_token_count": 35, "latency": 27.10545015335083}
{"id": "live_simple_20-4-0", "result": [{"change_food": {"food_item": "\u6f22\u5821", "modification_request": "\u6c92\u6709\u6d0b\u8525, \u984d\u5916\u7684\u5976\u916a"}}], "input_token_count": 620, "output_token_count": 46, "latency": 32.48890018463135}
{"id": "live_simple_21-4-1", "result": [{"change_food": {"food_item": "\u96de\u8089\u83dc", "modification_request": "extra spicy"}}], "input_token_count": 622, "output_token_count": 34, "latency": 26.53295135498047}
{"id": "live_simple_22-5-0", "result": [{"ChaFod": {"TheFod": "BURGER"}}], "input_token_count": 577, "output_token_count": 24, "latency": 23.7971670627594}
{"id": "live_simple_23-5-1", "result": [{"ChaFod": {"TheFod": "PIZZA"}}], "input_token_count": 571, "output_token_count": 24, "latency": 23.176844120025635}
{"id": "live_simple_24-5-2", "result": [{"ChaFod": {"TheFod": "BURGER"}}], "input_token_count": 581, "output_token_count": 24, "latency": 23.162140607833862}
{"id": "live_simple_25-5-3", "result": [{"ChaFod": {"TheFod": "SALAD"}}], "input_token_count": 590, "output_token_count": 24, "latency": 22.70053505897522}
{"id": "live_simple_26-6-0", "result": [{"uber.ride": {"loc": "123 Main St, Springfield, IL", "type": "plus", "time": 10}}], "input_token_count": 700, "output_token_count": 41, "latency": 28.605348825454712}
{"id": "live_simple_27-7-0", "result": [{"uber.eat.order": {"restaurant": "Uber Pitada", "items": ["\u6f22\u5821", "\u96de\u7fc5"], "quantities": [5, 6]}}], "input_token_count": 655, "output_token_count": 50, "latency": 33.12647843360901}
{"id": "live_simple_28-7-1", "result": [{"uber.eat.order": {"restaurant": "\u9ea5\u7576\u52de", "items": ["\u96de\u817f\u5821", "\u53ef\u53e3\u53ef\u6a02", "\u6cb9\u70b8\u96de\u7fc5", "\u85af\u689d"], "quantities": [10, 50, 30, 90]}}], "input_token_count": 668, "output_token_count": 77, "latency": 39.393240213394165}
{"id": "live_simple_29-7-2", "result": [{"uber.eat.order": {"restaurant": "\u9ea5\u7576\u52de", "items": ["\u6bd4\u85a9\u9905"], "quantities": [1]}}], "input_token_count": 645, "output_token_count": 44, "latency": 29.689218044281006}
{"id": "live_simple_30-8-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_31-8-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_32-9-0", "result": [{"answer.string": {"answer": "\u908f\u8f2f\u56de\u6b78\u4e0d\u5b58\u5728\uff0c\u56e0\u6b64\u6211\u7121\u6cd5\u56de\u7b54\u9019\u500b\u554f\u984c\u3002"}}], "input_token_count": 553, "output_token_count": 37, "latency": 24.646434783935547}
{"id": "live_simple_33-10-0", "result": [{"answer.string": {"answer": "\u908f\u8f2f\u56de\u6b78\u4e0d\u5b58\u5728\uff0c\u56e0\u6b64\u6211\u7121\u6cd5\u56de\u7b54\u9019\u500b\u554f\u984c\u3002"}}], "input_token_count": 545, "output_token_count": 36, "latency": 23.52154564857483}
{"id": "live_simple_34-11-0", "result": [{"answer.string": {"answer": "\u908f\u8f2f\u56de\u6b78"}}], "input_token_count": 559, "output_token_count": 24, "latency": 19.522393465042114}
{"id": "live_simple_35-12-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_36-13-0", "result": [{"parseAnswer": {"answer": "\u6587\u672c\u6c92\u6709\u5b9a\u7fa9\u908f\u8f2f\u56de\u6b78\uff0c\u56e0\u6b64\u6211\u7121\u6cd5\u56de\u7b54\u9019\u500b\u554f\u984c\u3002"}}], "input_token_count": 562, "output_token_count": 41, "latency": 25.74118947982788}
{"id": "live_simple_37-14-0", "result": [{"parseAnswer": {"answer": "\u6587\u672c\u6c92\u6709\u5b9a\u7fa9\u908f\u8f2f\u56de\u6b78\uff0c\u56e0\u6b64\u6211\u7121\u6cd5\u56de\u7b54\u9019\u500b\u554f\u984c\u3002"}}], "input_token_count": 520, "output_token_count": 41, "latency": 26.297312021255493}
{"id": "live_simple_38-15-0", "result": "[get_current_weather(location=\"Mariposa, CA\", unit=\"fahrenheit\")]", "input_token_count": 790, "output_token_count": 20, "latency": 16.94501304626465}
{"id": "live_simple_39-16-0", "result": [{"fetch_weather_data": {"latitude": 37.8651, "longitude": 119.5383}}], "input_token_count": 834, "output_token_count": 40, "latency": 24.694329500198364}
{"id": "live_simple_40-17-0", "result": [{"ThinQ_Connect": {"body": {"airConJobMode": "AIR_CLEAN", "windStrength": "HIGH", "monitoringEnabled": true}}}], "input_token_count": 1097, "output_token_count": 46, "latency": 27.522143602371216}
{"id": "live_simple_41-17-1", "result": [{"ThinQ_Connect": {"body": {"airConJobMode": "AIR_DRY", "windStrength": "MID"}}}], "input_token_count": 1075, "output_token_count": 39, "latency": 23.52291512489319}
{"id": "live_simple_42-17-2", "result": [{"ThinQ_Connect": {"body": {"airConJobMode": "COOL", "targetTemperature": 22}}}], "input_token_count": 1097, "output_token_count": 37, "latency": 22.414003133773804}
{"id": "live_simple_43-17-3", "result": [{"ThinQ_Connect": {"body": {"airConJobMode": "COOL", "coolTargetTemperature": 24, "windStrength": "HIGH"}}}], "input_token_count": 1075, "output_token_count": 46, "latency": 26.957947969436646}
{"id": "live_simple_44-18-0", "result": [{"ThinQ_Connect": {"body": {"airConOperationMode": "POWER_ON", "currentJobMode": "COOL", "targetTemperature": 22}}}], "input_token_count": 1146, "output_token_count": 48, "latency": 27.244419813156128}
{"id": "live_simple_45-18-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_46-19-0", "result": [{"ThinQ_Connect": {"airConJobMode": "COOL", "windStrength": "MID", "monitoringEnabled": true, "airCleanOperationMode": "START", "airConOperationMode": "POWER_ON", "powerSaveEnabled": false, "targetTemperature": 24}}], "input_token_count": 1053, "output_token_count": 77, "latency": 33.40377902984619}
{"id": "live_simple_47-20-0", "result": "[multiply(a=3, b=2)]", "input_token_count": 485, "output_token_count": 12, "latency": 12.238503694534302}
{"id": "live_simple_48-21-0", "result": [{"find_beer": {"brewery": "\u5167\u83ef\u9054\u5c71\u8108\u5564\u9152\u5ee0", "taste": "bitter", "aroma": "hoppy", "color": "pale", "style": "IPA"}}], "input_token_count": 1279, "output_token_count": 62, "latency": 28.211171627044678}
{"id": "live_simple_49-21-1", "result": [{"find_beer": {"brewery": "\u6eaa\u5564\u9152\u5ee0", "taste": "\u82e6", "aroma": "\u5de7\u514b\u529b", "color": "\u6df1\u8272", "style": "IPA"}}], "input_token_count": 1305, "output_token_count": 59, "latency": 26.69322633743286}
{"id": "live_simple_50-22-0", "result": "[get_latest_carbon_intensity(zone=\"United Kingdom\")]", "input_token_count": 515, "output_token_count": 16, "latency": 13.03791356086731}
{"id": "live_simple_51-23-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_52-23-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_53-24-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_54-25-0", "result": [{"todo": {"type": "delete", "content": "\u96a8\u6a5f"}}], "input_token_count": 553, "output_token_count": 25, "latency": 13.958221673965454}
{"id": "live_simple_55-25-1", "result": [{"todo": {"type": "add", "content": "\u4e0b\u53489\u9ede\u53bb\u8cfc\u7269"}}], "input_token_count": 546, "output_token_count": 30, "latency": 16.283795595169067}
{"id": "live_simple_56-26-0", "result": [{"todo_manager.handle_action": {"type": "delete", "content": "\u53bb\u5065\u8eab\u623f"}}], "input_token_count": 658, "output_token_count": 30, "latency": 15.736583232879639}
{"id": "live_simple_57-26-1", "result": [{"todo_manager.handle_action": {"type": "add", "content": "\u5728\u665a\u4e0a9\u9ede\u5165\u7761"}}], "input_token_count": 661, "output_token_count": 33, "latency": 16.864160776138306}
{"id": "live_simple_58-27-0", "result": [{"get_movies": {"city": "Mumbai"}}], "input_token_count": 1127, "output_token_count": 21, "latency": 11.011106491088867}
{"id": "live_simple_59-28-0", "result": "[get_movies(city=\"Mumbai\")]", "input_token_count": 926, "output_token_count": 12, "latency": 8.04105281829834}
{"id": "live_simple_60-29-0", "result": [{"todo": {"type": "complete", "content": "\u63d0\u4ea4\u6bcf\u6708\u8ca1\u52d9\u5831\u544a"}}], "input_token_count": 628, "output_token_count": 32, "latency": 15.221633434295654}
{"id": "live_simple_61-29-1", "result": [{"todo": {"type": "add", "content": "\u660e\u5929\u53bb\u5065\u8eab\u623f"}}], "input_token_count": 605, "output_token_count": 29, "latency": 13.511589527130127}
{"id": "live_simple_62-29-2", "result": [{"todo": {"type": "delete", "content": "ravi"}}], "input_token_count": 618, "output_token_count": 25, "latency": 10.360594511032104}
{"id": "live_simple_63-29-3", "result": [{"todo": {"type": "add", "content": "\u5728\u665a\u4e0a9\u9ede\u5165\u7761"}}], "input_token_count": 609, "output_token_count": 30, "latency": 12.96105408668518}
{"id": "live_simple_64-29-4", "result": [{"todo": {"type": "add", "content": "\u53bb\u679c\u963f"}}], "input_token_count": 604, "output_token_count": 26, "latency": 10.18606162071228}
{"id": "live_simple_65-29-5", "result": [{"todo": {"type": "add", "content": "Hi Charlie"}}], "input_token_count": 612, "output_token_count": 25, "latency": 8.482236385345459}
{"id": "live_simple_66-30-0", "result": [{"inventory.restock_check": {"item_ids": [102, 103], "threshold": 20}}], "input_token_count": 712, "output_token_count": 36, "latency": 14.728368520736694}
{"id": "live_simple_67-31-0", "result": [{"obtener_cotizacion_de_creditos": {"monto_del_credito": 1000000, "plazo_del_credito_mensual": 12, "producto": "auto", "a\u00f1o_vehiculo": 2024, "enganche": 0.2}}], "input_token_count": 1289, "output_token_count": 82, "latency": 26.461028814315796}
{"id": "live_simple_68-32-0", "result": [{"sum": {"a": 5.0, "b": 3.0}}], "input_token_count": 515, "output_token_count": 28, "latency": 11.028358459472656}
{"id": "live_simple_69-33-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_70-34-0", "result": [{"get_sensor_alerts": {"perPage": 10, "sensorSerial": "Q3CC-CRT3-SZ2G", "t0": "2023-10-01", "t1": "2023-10-01"}}], "input_token_count": 1342, "output_token_count": 72, "latency": 24.443178176879883}
{"id": "live_simple_71-35-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_72-36-0", "result": [{"detect_beats_and_filter": {"capture_percentage": 50, "confidence_window_size": 0.5}}], "input_token_count": 717, "output_token_count": 38, "latency": 15.228681325912476}
{"id": "live_simple_73-36-1", "result": [{"detect_beats_and_filter": {"capture_percentage": 90, "confidence_window_size": 0.25}}], "input_token_count": 695, "output_token_count": 39, "latency": 15.311752080917358}
{"id": "live_simple_74-36-2", "result": [{"detect_beats_and_filter": {"capture_percentage": 70, "confidence_window_size": 0.8}}], "input_token_count": 704, "output_token_count": 38, "latency": 14.799760341644287}
{"id": "live_simple_75-36-3", "result": [{"detect_beats_and_filter": {"capture_percentage": 93, "confidence_window_size": 0.5}}], "input_token_count": 701, "output_token_count": 38, "latency": 14.328158378601074}
{"id": "live_simple_76-37-0", "result": [{"language_translator.translate": {"source_language": "en", "target_language": "fr", "text": "What is your name?"}}], "input_token_count": 707, "output_token_count": 39, "latency": 14.830971240997314}
{"id": "live_simple_77-38-0", "result": [{"weather.get": {"city": "London", "country": "GB"}}], "input_token_count": 743, "output_token_count": 25, "latency": 10.762534618377686}
{"id": "live_simple_78-39-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_79-40-0", "result": [{"search_hotels": {"location": "San Diego, CA"}}], "input_token_count": 589, "output_token_count": 24, "latency": 10.47396731376648}
{"id": "live_simple_80-41-0", "result": [{"sitefinity_create_contentitem": {"Title": "\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u7a81\u7834", "Content": "\u6a5f\u5668\u5b78\u7fd2\u7b97\u6cd5\u7684\u6700\u65b0\u7a81\u7834", "MetaTitle": "\u6a5f\u5668\u5b78\u7fd2\u4e2d\u7684AI\u6700\u65b0\u767c\u5c55", "MetaDescription": "\u6982\u8ff0\u4eba\u5de5\u667a\u80fd\u548c\u6a5f\u5668\u5b78\u7fd2\u6280\u8853\u7684\u8fd1\u671f\u53d6\u5f97\u7684\u91cd\u5927\u9032\u6b65", "UrlName": "\u6700\u7d42\u6700\u7d42\u767c\u5c55"}}], "input_token_count": 1022, "output_token_count": 102, "latency": 38.349085092544556}
{"id": "live_simple_81-42-0", "result": [{"sitefinity_create_contentitem": {"ContentItem": "NewsItem", "Title": "\u6731\u5229\u5b89\uff08Julian\uff09\u6b63\u5728Testing12"}}], "input_token_count": 947, "output_token_count": 41, "latency": 15.043071508407593}
{"id": "live_simple_82-43-0", "result": "[sitefinity_create_contentitem(ContentItem=\"News\", Title=\"Julian\u6e2c\u8a66\")]", "input_token_count": 920, "output_token_count": 22, "latency": 9.886091947555542}
{"id": "live_simple_83-44-0", "result": [{"sitefinity_create_contentitem": {"ContentItem": "news", "Title": "\u6731\u5229\u5b89\u6b63\u5728\u6e2c\u8a66", "Content": "\u8a73\u7d30\u5206\u6790\u4e86\u7761\u7720\u6a21\u5f0f\u5c0d\u751f\u7522\u529b\u7684\u5f71\u97ff", "MetaTitle": "\u751f\u7522\u529b\u548c\u7761\u7720\u6a21\u5f0f", "MetaDescription": "\u63a2\u7d22\u7761\u7720\u5982\u4f55\u5f71\u97ff\u5de5\u4f5c\u6548\u7387", "UrlName": "julian-is-testing"}}], "input_token_count": 1003, "output_token_count": 105, "latency": 41.057700872421265}
{"id": "live_simple_84-45-0", "result": "[get_coordinates_from_city(city_name=\"Seattle\")]", "input_token_count": 587, "output_token_count": 15, "latency": 5.466954469680786}
{"id": "live_simple_85-46-0", "result": [{"open_meteo_api.fetch_weather_data": {"coordinates": [37.8715, -122.273], "units": "Celsius"}}], "input_token_count": 661, "output_token_count": 49, "latency": 17.381787061691284}
{"id": "live_simple_86-47-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_87-48-0", "result": "[get_current_loc(coordinate_format='DMS', include_altitude=True)]", "input_token_count": 680, "output_token_count": 18, "latency": 7.146921634674072}
{"id": "live_simple_88-49-0", "result": [{"log_food": {"food_name": "\u67f4\u8336", "portion_amount": 16, "portion_unit": "ounces", "meal_name": "snack"}}], "input_token_count": 818, "output_token_count": 48, "latency": 16.828577995300293}
{"id": "live_simple_89-50-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_90-51-0", "result": "[temperature(location=\"Paris, France\")]", "input_token_count": 706, "output_token_count": 10, "latency": 3.0809335708618164}
{"id": "live_simple_91-52-0", "result": [{"fetchPerson": {"id": 4}}], "input_token_count": 460, "output_token_count": 19, "latency": 8.106243371963501}
{"id": "live_simple_92-53-0", "result": "[play_artist(artist_name=\"K\u00e4\u00e4rij\u00e4\")]", "input_token_count": 477, "output_token_count": 15, "latency": 5.863381862640381}
{"id": "live_simple_93-54-0", "result": [{"play_artist": {"artist_name": "K\u00e4\u00e4rij\u00e4"}}], "input_token_count": 459, "output_token_count": 24, "latency": 10.310146570205688}
{"id": "live_simple_94-55-0", "result": "[play_song(artist_name=\"K\u00e4\u00e4rij\u00e4\", song_name=\"Cha Cha Cha\")]", "input_token_count": 517, "output_token_count": 22, "latency": 10.029648780822754}
{"id": "live_simple_95-56-0", "result": [{"process_data": {"data": [2.5, 3.6, 4.1, 5.2], "normalize": true, "categories": ["\u7d05\u8272", "\u85cd\u8272", "green"], "encoding_type": "label", "missing_values": "mean"}}], "input_token_count": 1061, "output_token_count": 70, "latency": 22.216059923171997}
{"id": "live_simple_96-57-0", "result": "[get_current_weather(location=\"\u6ce2\u58eb\u9813, MA\")]", "input_token_count": 621, "output_token_count": 15, "latency": 7.513444423675537}
{"id": "live_simple_97-57-1", "result": [{"get_current_weather": {"location": "El Gastor, Andalusia"}}], "input_token_count": 630, "output_token_count": 26, "latency": 10.747006177902222}
{"id": "live_simple_98-58-0", "result": "[get_weather_by_coordinates(city=\"\u6b3d\u5948\", lat=13.0827, lon=80.2707)]", "input_token_count": 603, "output_token_count": 35, "latency": 12.152579069137573}
{"id": "live_simple_99-59-0", "result": [{"connectBluetooth": {"device_name": "UE Boom"}}], "input_token_count": 595, "output_token_count": 21, "latency": 9.837466955184937}
{"id": "live_simple_100-59-1", "result": [{"connectBluetooth": {"device_name": "JBL Flip 4"}}], "input_token_count": 596, "output_token_count": 24, "latency": 9.980942249298096}
{"id": "live_simple_101-60-0", "result": [{"askForSSID": {"prompt_message": "\u8acb\u8f38\u5165\u60a8\u8981\u9023\u63a5\u5230\u7684Wi-Fi\u7db2\u7d61\u540d\u7a31\uff1a"}}], "input_token_count": 754, "output_token_count": 40, "latency": 14.633588790893555}
{"id": "live_simple_102-61-0", "result": [{"calculate_tax": {"purchase_amount": 59.99, "state": "CA"}}], "input_token_count": 953, "output_token_count": 31, "latency": 10.67582106590271}
{"id": "live_simple_103-61-1", "result": [{"calculate_tax": {"purchase_amount": 999, "state": "CA"}}], "input_token_count": 966, "output_token_count": 29, "latency": 10.322502613067627}
{"id": "live_simple_104-61-2", "result": [{"calculate_tax": {"purchase_amount": 250, "state": "NY"}}], "input_token_count": 940, "output_token_count": 29, "latency": 10.316691637039185}
{"id": "live_simple_105-62-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_106-63-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_107-64-0", "result": [{"record": {"faq_describe_telephone_banking_start": ["\u6211\u53ef\u4ee5\u8a3b\u518a\u96fb\u8a71\u9280\u884c\u670d\u52d9\u55ce\uff1f", "\u6211\u5728\u54ea\u88e1\u53ef\u4ee5\u627e\u5230\u96fb\u8a71\u9280\u884c\u670d\u52d9\u7684\u7533\u8acb\uff1f"], "bank_hours_start": ["\u73fe\u5728\u6709\u4efb\u4f55\u9280\u884c\u5728\u65af\u91cc\u862d\u5361\u958b\u696d\u55ce\uff1f"], "faq_describe_accounts_start": ["\u6211\u6709\u8208\u8da3\u958b\u8a2d\u4e00\u500b\u9577\u671f\u5132\u84c4\u5e33\u6236\u3002\u4f60\u6709\u4ec0\u9ebc\u9078\u64c7\uff1f", "\u60a8\u70ba\u5152\u7ae5\u6216\u672a\u6210\u5e74\u4eba\u63d0\u4f9b\u4efb\u4f55\u7279\u6b8a\u5e33\u6236\u55ce\uff1f", "\u60a8\u662f\u5426\u70ba\u5e0c\u671b\u7bc0\u7701\u8cfc\u623f\u6216\u7ffb\u65b0\u7684\u500b\u4eba\u63d0\u4f9b\u4efb\u4f55\u7279\u6b8a\u5e33\u6236\uff1f"]}}], "input_token_count": 905, "output_token_count": 172, "latency": 92.2433249950409}
{"id": "live_simple_108-65-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_109-66-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_110-67-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_111-67-1", "result": [{"record": {"get_balance_start": ["\u6211\u7684\u5e73\u8861\u662f\u4ec0\u9ebc\uff1f", "\u544a\u8a34\u6211\u6211\u7684\u53ef\u7528\u9918\u984d\uff0c\u8acb", "\u6211\u76ee\u524d\u7684\u53ef\u7528\u9918\u984d\u662f\u4ec0\u9ebc\uff1f", "\u8acb\u63d0\u4f9b\u6211\u7684\u7d93\u5e38\u8cec\u6236\u9918\u984d", "\u5411\u6211\u5c55\u793a\u6211\u7684\u5e73\u8861\u4fe1\u606f\u3002", "\u76ee\u524d\u6211\u7684\u5e33\u6236\u4e2d\u7684\u9918\u984d\u662f\u4ec0\u9ebc\uff1f", "\u6211\u7684\u5e33\u6236\u4e2d\u6709\u591a\u5c11\u9322\uff1f", "\u544a\u8a34\u6211\u6211\u7684\u53ef\u7528\u9918\u984d"]}}], "input_token_count": 1140, "output_token_count": 130, "latency": 65.508553981781}
{"id": "live_simple_112-68-0", "result": [{"record": {"acc_routing_start": [], "atm_finder_start": [], "faq_link_accounts_start": [], "get_balance_start": [], "get_transactions_start": [], "outofscope": ["\u5929\u6c23\u5982\u4f55"]}}], "input_token_count": 1062, "output_token_count": 60, "latency": 19.637941360473633}
{"id": "live_simple_113-69-0", "result": [{"calculate_dynamic_pricing": {"geolocation": "34.0522, -118.2437", "base_price": 100, "minimum_price": 90}}], "input_token_count": 915, "output_token_count": 56, "latency": 18.68902587890625}
{"id": "live_simple_114-70-0", "result": [{"update_user_profile": {"user_id": 12345, "profile_data": {"email": "John.doe@example.com", "age": 30}}}], "input_token_count": 788, "output_token_count": 46, "latency": 15.183048725128174}
{"id": "live_simple_115-71-0", "result": [{"calculate_sum": {"number1": 133, "number2": 34}}], "input_token_count": 527, "output_token_count": 30, "latency": 10.80242133140564}
{"id": "live_simple_116-72-0", "result": [{"sum_numbers": {"numbers_list": [133, 34]}}], "input_token_count": 475, "output_token_count": 27, "latency": 9.284464597702026}
{"id": "live_simple_117-73-0", "result": [{"reverse_input": {"input_value": "\u4f60\u597d"}}], "input_token_count": 532, "output_token_count": 20, "latency": 7.743567228317261}
{"id": "live_simple_118-74-0", "result": "[get_temperature(units=\"Celsius\", location=\"Hyderabad, India\")]", "input_token_count": 700, "output_token_count": 19, "latency": 7.652012348175049}
{"id": "live_simple_119-75-0", "result": [{"GetPrimeMinisters": {"countries": ["Australia", "Canada", "India"]}}], "input_token_count": 562, "output_token_count": 29, "latency": 10.243977308273315}
{"id": "live_simple_120-76-0", "result": [{"weather.forecast": {"location": "Paris, France", "start_date": "2023-04-03", "end_date": "2023-04-05", "temperature_unit": "Celsius"}}], "input_token_count": 977, "output_token_count": 62, "latency": 19.65392565727234}
{"id": "live_simple_121-77-0", "result": [{"generate_chart": {"data_labels": ["\u8edf\u4ef6\u5de5\u7a0b\u5e2b", "\u5716\u5f62\u8a2d\u8a08\u5e2b", "\u6578\u64da\u5206\u6790\u5e2b", "\u92b7\u552e\u7d93\u7406", "\u8b77\u58eb"], "data_values": [90000, 50000, 70000, 60000, 80000]}}], "input_token_count": 740, "output_token_count": 92, "latency": 39.04634213447571}
{"id": "live_simple_122-78-0", "result": [{"process_data": {"image_path": "image.png", "question": "\u5728\u6280\u8853\u4e0a\u8907\u96dc\u7684\u95dc\u6ce8\u5c0d\u60a8\u6240\u770b\u5230\u7684\u63cf\u8ff0\u7684\u8a73\u7d30\u8aaa\u660e", "model": "vikhyatk/moondream2"}}], "input_token_count": 709, "output_token_count": 62, "latency": 19.678256511688232}
{"id": "live_simple_123-79-0", "result": "[pipeline(image_path=\"http://www.thewowstyle.com/wp-content/uploads/2015/01/Home-Interior-Design-Hd-Wallpaper-Hd-Background-With-Simple-Staircase-And-Plasma-TV-Also-Nice-Laminate-Flooring-Ideas-With-Modern-Furniture-Interior-Minimalist-Design.jpg\", question=\"\u5bb6\u5177\u7684\u4f48\u7f6e\u5982\u4f55\u4fc3\u9032\u5167\u90e8\u7684\u6975\u7c21\u4e3b\u7fa9\u8a2d\u8a08\uff1f\")]", "input_token_count": 673, "output_token_count": 108, "latency": 50.06232523918152}
{"id": "live_simple_124-80-0", "result": "[get_tickets(customer='\u7d05\u661f\u79d1\u6280', status='open', limit=10)]", "input_token_count": 627, "output_token_count": 21, "latency": 6.988726377487183}
{"id": "live_simple_125-81-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_126-82-0", "result": [{"telemetry.flowrules.interfaceInfo.get": {"fabricName": "Global-Fric", "nodeId": 1200, "podId": 3, "interfaceType": "ethernet", "infoType": "status"}}], "input_token_count": 879, "output_token_count": 61, "latency": 19.146157026290894}
{"id": "live_simple_127-82-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_128-83-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_129-83-1", "result": [{"requests.get": {"url": "https://3.321.3232.2/sedgeapi/v1/cisco-nir/api/api/telemetry/flowrules/nodes?fabricName=Fab-Ed"}}], "input_token_count": 755, "output_token_count": 60, "latency": 17.976011037826538}
{"id": "live_simple_130-84-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_131-84-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_132-85-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_133-86-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_134-87-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_135-88-0", "result": [{"requests.get": {"url": "https://api.example.com/v1/data", "params": {"limit": 50}}}], "input_token_count": 740, "output_token_count": 37, "latency": 11.62995982170105}
{"id": "live_simple_136-89-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_137-90-0", "result": [{"reschedule": {"identifier": "\u611b\u9e97\u7d72\u4e00\u5c0d\u4e00", "dateOrTime": "2023-11-01T22:00:00", "timezone": "Europe/London"}}], "input_token_count": 720, "output_token_count": 60, "latency": 18.65027356147766}
{"id": "live_simple_138-91-0", "result": [{"reschedule": {"identifier": "Bob-123", "dateOrTime": "2023-11-01T18:00:00Z", "timezone": "Europe/Paris"}}], "input_token_count": 738, "output_token_count": 59, "latency": 18.643242359161377}
{"id": "live_simple_139-92-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_140-93-0", "result": "[greet_partner(user_name=\"\u827e\u7c73\u9e97\", partner_name=\"\u5091\u592b\")]", "input_token_count": 619, "output_token_count": 21, "latency": 6.8851587772369385}
{"id": "live_simple_141-94-0", "result": [{"cmd_controller.execute": {"command": "docker --version"}}], "input_token_count": 590, "output_token_count": 22, "latency": 7.421569347381592}
{"id": "live_simple_142-94-1", "result": [{"cmd_controller.execute": {"command": "dir"}}], "input_token_count": 587, "output_token_count": 20, "latency": 5.773006916046143}
{"id": "live_simple_143-95-0", "result": [{"cmd_controller.execute": {"command": "docker ps"}}], "input_token_count": 624, "output_token_count": 21, "latency": 6.870962619781494}
{"id": "live_simple_144-95-1", "result": [{"cmd_controller.execute": {"command": "taskkill /IM firefox.exe"}}], "input_token_count": 617, "output_token_count": 26, "latency": 8.936570405960083}
{"id": "live_simple_145-95-2", "result": [{"cmd_controller.execute": {"command": "dir C:"}}], "input_token_count": 615, "output_token_count": 22, "latency": 7.396474361419678}
{"id": "live_simple_146-95-3", "result": [{"cmd_controller.execute": {"command": "start https://huggingface.co"}}], "input_token_count": 631, "output_token_count": 27, "latency": 8.571792364120483}
{"id": "live_simple_147-95-4", "result": [{"cmd_controller.execute": {"command": "taskkill /IM Timer.exe"}}], "input_token_count": 623, "output_token_count": 25, "latency": 8.298678159713745}
{"id": "live_simple_148-95-5", "result": [{"cmd_controller.execute": {"command": "dir"}}], "input_token_count": 617, "output_token_count": 20, "latency": 5.76456093788147}
{"id": "live_simple_149-95-6", "result": [{"cmd_controller.execute": {"command": "echo Hello, World!"}}], "input_token_count": 616, "output_token_count": 24, "latency": 6.9069366455078125}
{"id": "live_simple_150-95-7", "result": [{"cmd_controller.execute": {"command": "shutdown /s /t 0"}}], "input_token_count": 624, "output_token_count": 27, "latency": 7.440581560134888}
{"id": "live_simple_151-95-8", "result": [{"cmd_controller.execute": {"command": "netsh wlan disconnect"}}], "input_token_count": 626, "output_token_count": 24, "latency": 6.883837461471558}
{"id": "live_simple_152-95-9", "result": [{"cmd_controller.execute": {"command": "dir d:\\ && echo testing.txt"}}], "input_token_count": 645, "output_token_count": 26, "latency": 6.880263328552246}
{"id": "live_simple_153-95-10", "result": [{"cmd_controller.execute": {"command": "DEL \"%userProfile%\\Desktop\\putty.lnk\""}}], "input_token_count": 644, "output_token_count": 35, "latency": 8.949670553207397}
{"id": "live_simple_154-95-11", "result": [{"cmd_controller.execute": {"command": "start https://www.youtube.com/watch?v=dQw4w9WgXcQ"}}], "input_token_count": 622, "output_token_count": 38, "latency": 10.003443717956543}
{"id": "live_simple_155-95-12", "result": [{"cmd_controller.execute": {"command": "date"}}], "input_token_count": 622, "output_token_count": 20, "latency": 5.117140769958496}
{"id": "live_simple_156-95-13", "result": [{"cmd_controller.execute": {"command": "dir && echo done"}}], "input_token_count": 632, "output_token_count": 24, "latency": 6.238999605178833}
{"id": "live_simple_157-95-14", "result": [{"cmd_controller.execute": {"command": "echo %time%"}}], "input_token_count": 623, "output_token_count": 23, "latency": 6.140740394592285}
{"id": "live_simple_158-95-15", "result": [{"cmd_controller.execute": {"command": "taskkill /F /IM Code.exe"}}], "input_token_count": 620, "output_token_count": 27, "latency": 6.95130181312561}
{"id": "live_simple_159-95-16", "result": [{"cmd_controller.execute": {"command": "timeout /t 10"}}], "input_token_count": 631, "output_token_count": 25, "latency": 6.754756450653076}
{"id": "live_simple_160-95-17", "result": [{"cmd_controller.execute": {"command": "Start Microsoft.windows.camera"}}], "input_token_count": 622, "output_token_count": 24, "latency": 6.6542956829071045}
{"id": "live_simple_161-96-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_162-96-1", "result": [{"get_items": {"items": ["red and blue circle logo", "yellow circle logo"]}}], "input_token_count": 550, "output_token_count": 29, "latency": 7.551733493804932}
{"id": "live_simple_163-96-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_164-97-0", "result": [{"get_copyright_info": {"copyright_content": "\u53ef\u53e3\u53ef\u6a02\u5fbd\u6a19", "copyright_holder": "\u53ef\u53e3\u53ef\u6a02\u516c\u53f8", "confidence_score": 100.0}}], "input_token_count": 832, "output_token_count": 52, "latency": 15.359259128570557}
{"id": "live_simple_165-98-0", "result": [{"extractor.extract_information": {"data": [{"name": "\u674e\u96f7", "age": 18}, {"name": "\u674e\u9e97", "age": 21}], "schema": "personal_info"}}], "input_token_count": 783, "output_token_count": 56, "latency": 18.35236644744873}
{"id": "live_simple_166-99-0", "result": [{"cmd_controller.execute": {"command": "echo %time%"}}], "input_token_count": 571, "output_token_count": 23, "latency": 6.31587553024292}
{"id": "live_simple_167-99-1", "result": [{"cmd_controller.execute": {"command": "tasklist /fi \"Imagename eq code.exe\""}}], "input_token_count": 576, "output_token_count": 32, "latency": 8.989111185073853}
{"id": "live_simple_168-99-2", "result": [{"cmd_controller.execute": {"command": "docker start"}}], "input_token_count": 567, "output_token_count": 21, "latency": 5.950332880020142}
{"id": "live_simple_169-99-3", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_170-99-4", "result": [{"cmd_controller.execute": {"command": "dir C:\\"}}], "input_token_count": 561, "output_token_count": 22, "latency": 6.1299848556518555}
{"id": "live_simple_171-99-5", "result": [{"cmd_controller.execute": {"command": "echo %date%"}}], "input_token_count": 568, "output_token_count": 23, "latency": 6.428973197937012}
{"id": "live_simple_172-99-6", "result": [{"cmd_controller.execute": {"command": "docker ps"}}], "input_token_count": 569, "output_token_count": 21, "latency": 6.239947319030762}
{"id": "live_simple_173-99-7", "result": [{"cmd_controller.execute": {"command": "start calc"}}], "input_token_count": 573, "output_token_count": 21, "latency": 6.608217239379883}
{"id": "live_simple_174-100-0", "result": [{"get_service_id": {"service_id": 2}}], "input_token_count": 709, "output_token_count": 21, "latency": 6.607391834259033}
{"id": "live_simple_175-101-0", "result": "[get_service_id(service_id=1)]", "input_token_count": 634, "output_token_count": 10, "latency": 4.3457348346710205}
{"id": "live_simple_176-102-0", "result": "[get_service_id(service_id=1, unit=1)]", "input_token_count": 565, "output_token_count": 14, "latency": 5.172608852386475}
{"id": "live_simple_177-103-0", "result": "[get_service_id(service_id=1)]", "input_token_count": 601, "output_token_count": 10, "latency": 4.173070192337036}
{"id": "live_simple_178-103-1", "result": "[get_service_id(service_id=2)]", "input_token_count": 599, "output_token_count": 10, "latency": 4.165351629257202}
{"id": "live_simple_179-104-0", "result": "[get_service_id(service_id=2, province_id=2)]", "input_token_count": 674, "output_token_count": 15, "latency": 5.274755239486694}
{"id": "live_simple_180-105-0", "result": "[get_service_id(service_id=2, province_id=1, rating=4)]", "input_token_count": 734, "output_token_count": 19, "latency": 6.435958623886108}
{"id": "live_simple_181-106-0", "result": "[get_service_id(service_id=2, province_id=1, district_name=\"Chatuchak\", rating=4.5)]", "input_token_count": 865, "output_token_count": 28, "latency": 8.289657831192017}
{"id": "live_simple_182-107-0", "result": "[get_service_providers(service_id=2, province_id=1, district_name='Khlong Sam Wa', sub_district_name='Khlong Sam Wa', rating=4.5)]", "input_token_count": 884, "output_token_count": 42, "latency": 15.03429913520813}
{"id": "live_simple_183-108-0", "result": "[getDataForProfessional(province_id=1, avg_rating=2.0)]", "input_token_count": 873, "output_token_count": 20, "latency": 7.40174126625061}
{"id": "live_simple_184-109-0", "result": "[getDataForProfessional(service_id=1, province_id=1, rating=4)]", "input_token_count": 780, "output_token_count": 21, "latency": 7.177139043807983}
{"id": "live_simple_185-110-0", "result": "[get_service_providers(service_id=2, province_id=3, rating=4.5, start_available_date='2023-09-30')]", "input_token_count": 1065, "output_token_count": 38, "latency": 12.852138042449951}
{"id": "live_simple_186-111-0", "result": "[get_service_providers(service_id=2, province_id=3, rating=4.5, start_available_date='2024-12-03 16:00:00', end_available_date='2024-12-03 18:00:00')]", "input_token_count": 1149, "output_token_count": 71, "latency": 35.04995512962341}
{"id": "live_simple_187-112-0", "result": "[get_service_providers(service_id=2, province_id=3, rating=4.5, start_available_date='2024-12-03', end_available_date='2024-12-03', has_late_check_in=False)]", "input_token_count": 1285, "output_token_count": 59, "latency": 26.299479722976685}
{"id": "live_simple_188-113-0", "result": [{"getDataForProfessional": {"service_id": 2, "province_id": 2, "district_name": "Sankampang", "sub_district_name": "Tum Pao", "rating": 4.5}}], "input_token_count": 1177, "output_token_count": 60, "latency": 27.863176345825195}
{"id": "live_simple_189-114-0", "result": "[{\"name\": \"extractor.extract_information\", \"arguments\": {\"data\": [{\"age\": 42}, {\"age\": 42, \"name\": \"\u7c21\"}]}]}", "input_token_count": 743, "output_token_count": 41, "latency": 14.79128646850586}
{"id": "live_simple_190-115-0", "result": [{"raptor.mpn.specs": {"identifier": "MPN", "search_type": "MPN", "include_images": true}}], "input_token_count": 681, "output_token_count": 39, "latency": 13.524946212768555}
{"id": "live_simple_191-115-1", "result": [{"raptor.mpn.specs": {"identifier": "3PAK7"}}], "input_token_count": 683, "output_token_count": 27, "latency": 7.708589315414429}
{"id": "live_simple_192-116-0", "result": [{"Weather_1_GetWeather": {"city": "Pacifica", "date": "2023-04-11"}}], "input_token_count": 590, "output_token_count": 38, "latency": 13.010122060775757}
{"id": "live_simple_193-116-1", "result": [{"Weather_1_GetWeather": {"city": "New York", "date": "2023-03-08"}}], "input_token_count": 590, "output_token_count": 38, "latency": 12.997555017471313}
{"id": "live_simple_194-116-2", "result": [{"Weather_1_GetWeather": {"city": "\u99ac\u4e01\u5167\u65af", "date": "2023-04-25"}}], "input_token_count": 594, "output_token_count": 40, "latency": 13.717731475830078}
{"id": "live_simple_195-116-3", "result": [{"Weather_1_GetWeather": {"city": "Palm Alto"}}], "input_token_count": 591, "output_token_count": 24, "latency": 5.7617692947387695}
{"id": "live_simple_196-116-4", "result": [{"Weather_1_GetWeather": {"city": "\u963f\u62c9\u7c73\u9054", "date": "2023-04-26"}}], "input_token_count": 600, "output_token_count": 40, "latency": 13.748612880706787}
{"id": "live_simple_197-116-5", "result": [{"Weather_1_GetWeather": {"city": "Stinson Beach", "date": "2023-04-05"}}], "input_token_count": 591, "output_token_count": 39, "latency": 13.138547897338867}
{"id": "live_simple_198-116-6", "result": [{"Weather_1_GetWeather": {"city": "\u5e0c\u723e\u8332\u5821", "date": "2023-03-02"}}], "input_token_count": 592, "output_token_count": 41, "latency": 14.329423189163208}
{"id": "live_simple_199-116-7", "result": [{"Weather_1_GetWeather": {"city": "\u99ac\u6b47\u723e", "date": "2023-03-05"}}], "input_token_count": 597, "output_token_count": 40, "latency": 13.739610195159912}
{"id": "live_simple_200-116-8", "result": [{"Weather_1_GetWeather": {"city": "\u5f17\u91cc\u8499\u7279", "date": "2023-03-01"}}], "input_token_count": 589, "output_token_count": 40, "latency": 14.031391859054565}
{"id": "live_simple_201-116-9", "result": [{"Weather_1_GetWeather": {"city": "\u574e\u8c9d\u723e", "date": "2023-03-04"}}], "input_token_count": 607, "output_token_count": 41, "latency": 14.601759672164917}
{"id": "live_simple_202-116-10", "result": [{"Weather_1_GetWeather": {"city": "\u5bc4\u990a\u57ce", "date": "2023-04-25"}}], "input_token_count": 592, "output_token_count": 41, "latency": 14.60118556022644}
{"id": "live_simple_203-116-11", "result": [{"Weather_1_GetWeather": {"city": "\u83ef\u76db\u9813\u7279\u5340", "date": "2023-03-01"}}], "input_token_count": 597, "output_token_count": 41, "latency": 15.095601320266724}
{"id": "live_simple_204-116-12", "result": [{"Weather_1_GetWeather": {"city": "\u76e7\u745f\u798f", "date": "2023-04-22"}}], "input_token_count": 597, "output_token_count": 40, "latency": 14.49415898323059}
{"id": "live_simple_205-116-13", "result": [{"Weather_1_GetWeather": {"city": "Berkeley", "date": "2023-04-29"}}], "input_token_count": 601, "output_token_count": 38, "latency": 13.792089939117432}
{"id": "live_simple_206-116-14", "result": [{"Weather_1_GetWeather": {"city": "London", "date": "2023-03-05"}}], "input_token_count": 591, "output_token_count": 37, "latency": 13.222101211547852}
{"id": "live_simple_207-116-15", "result": [{"Weather_1_GetWeather": {"city": "\u85a9\u514b\u62c9\u66fc\u591a", "date": "2023-04-22"}}], "input_token_count": 594, "output_token_count": 42, "latency": 16.235718727111816}
{"id": "live_simple_208-117-0", "result": [{"Movies_3_FindMovies": {"directed_by": "Quentin Tarantino", "cast": "Duane Whitaker"}}], "input_token_count": 850, "output_token_count": 37, "latency": 13.191680431365967}
{"id": "live_simple_209-117-1", "result": [{"Movies_3_FindMovies": {"directed_by": "David Leitch", "cast": "Lori Pelenise Tuisano"}}], "input_token_count": 851, "output_token_count": 40, "latency": 14.939259767532349}
{"id": "live_simple_210-117-2", "result": [{"Movies_3_FindMovies": {"genre": "Drama"}}], "input_token_count": 835, "output_token_count": 24, "latency": 6.101636648178101}
{"id": "live_simple_211-117-3", "result": [{"Movies_3_FindMovies": {"directed_by": "dontcare", "genre": "Animation", "cast": "James Corden"}}], "input_token_count": 840, "output_token_count": 40, "latency": 14.938713788986206}
{"id": "live_simple_212-117-4", "result": [{"Movies_3_FindMovies": {"directed_by": "Edgar Wright", "genre": "Comedy"}}], "input_token_count": 832, "output_token_count": 34, "latency": 11.84865403175354}
{"id": "live_simple_213-117-5", "result": [{"Movies_3_FindMovies": {"directed_by": "Tim Burton", "genre": "Offbeat"}}], "input_token_count": 830, "output_token_count": 33, "latency": 11.234915971755981}
{"id": "live_simple_214-117-6", "result": [{"Movies_3_FindMovies": {"directed_by": "Nitesh Tiwari", "genre": "Anime"}}], "input_token_count": 865, "output_token_count": 37, "latency": 13.682263612747192}
{"id": "live_simple_215-117-7", "result": [{"Movies_3_FindMovies": {"genre": "Fantasy"}}], "input_token_count": 835, "output_token_count": 24, "latency": 6.283930063247681}
{"id": "live_simple_216-117-8", "result": [{"Movies_3_FindMovies": {"directed_by": "David Leitch", "cast": "Alex King"}}], "input_token_count": 845, "output_token_count": 34, "latency": 11.994763135910034}
{"id": "live_simple_217-117-9", "result": [{"Movies_3_FindMovies": {"directed_by": "Nitesh Tiwari", "genre": "dontcare", "cast": "dontcare"}}], "input_token_count": 829, "output_token_count": 44, "latency": 18.68269681930542}
{"id": "live_simple_218-117-10", "result": [{"Movies_3_FindMovies": {"directed_by": "Paul Downs Colaizzo", "cast": "Michaela Watkins"}}], "input_token_count": 859, "output_token_count": 38, "latency": 15.433304786682129}
{"id": "live_simple_219-117-11", "result": [{"Movies_3_FindMovies": {"directed_by": "Simon Curtis", "genre": "Drama"}}], "input_token_count": 848, "output_token_count": 33, "latency": 12.379340887069702}
{"id": "live_simple_220-117-12", "result": [{"Movies_3_FindMovies": {"directed_by": "Alexander Mackendrick", "genre": "Thriller"}}], "input_token_count": 837, "output_token_count": 35, "latency": 13.540111064910889}
{"id": "live_simple_221-117-13", "result": [{"Movies_3_FindMovies": {"directed_by": "James Gray"}}], "input_token_count": 859, "output_token_count": 26, "latency": 8.127893686294556}
{"id": "live_simple_222-117-14", "result": [{"Movies_3_FindMovies": {"cast": "Sterling K. Brown"}}], "input_token_count": 839, "output_token_count": 28, "latency": 9.78208065032959}
{"id": "live_simple_223-117-15", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_224-117-16", "result": [{"Movies_3_FindMovies": {"directed_by": "Tim Burton", "cast": "Johnny Depp", "genre": "Offbeat"}}], "input_token_count": 842, "output_token_count": 41, "latency": 17.832149028778076}
{"id": "live_simple_225-117-17", "result": [{"Movies_3_FindMovies": {"directed_by": "Kirill Mikhanovsky", "genre": "Comedy"}}], "input_token_count": 862, "output_token_count": 38, "latency": 16.291404485702515}
{"id": "live_simple_226-118-0", "result": [{"text_to_speech.convert": {"text": "\u6211\u662f\u4e00\u500b\u6f02\u4eae\u7684\u5973\u5b69", "language": "es-ES", "gender": "female"}}], "input_token_count": 875, "output_token_count": 46, "latency": 22.19916081428528}
{"id": "live_simple_227-118-1", "result": [{"text_to_speech.convert": {"text": "\u6211\u611b\u5b78\u7fd2", "gender": "male", "language": "zh-CN", "format": "wav"}}], "input_token_count": 894, "output_token_count": 48, "latency": 24.2525851726532}
{"id": "live_simple_228-119-0", "result": [{"text_to_speech.convert": {"text": "\u6211\u662f\u4e00\u500b\u6f02\u4eae\u7684\u5973\u5b69"}}], "input_token_count": 797, "output_token_count": 32, "latency": 13.54757285118103}
{"id": "live_simple_229-120-0", "result": [{"requests.get": {"anchor": "user"}}], "input_token_count": 508, "output_token_count": 20, "latency": 6.657150506973267}
{"id": "live_simple_230-121-0", "result": [{"play_song": {"song_id": "wjeiruhuq_roar", "quality": "high"}}], "input_token_count": 690, "output_token_count": 34, "latency": 15.15395188331604}
{"id": "live_simple_231-122-0", "result": [{"reschedule_event": {"event_identifier": "456123", "new_datetime": "2022-10-27T16:30:00Z"}}], "input_token_count": 637, "output_token_count": 53, "latency": 28.31892418861389}
{"id": "live_simple_232-122-1", "result": [{"reschedule_event": {"event_identifier": "Med123", "new_datetime": "2021-04-15T13:45:00Z"}}], "input_token_count": 652, "output_token_count": 51, "latency": 26.822271823883057}
{"id": "live_simple_233-123-0", "result": "[book_flight(departure_location=\"Paris, France\", departure_time=\"12/03/2023 15:00\")]", "input_token_count": 783, "output_token_count": 35, "latency": 16.38297128677368}
{"id": "live_simple_234-123-1", "result": "[book_flight(departure_location=\"New York, NY\", departure_time=\"20/06/2022 17:00\")]", "input_token_count": 764, "output_token_count": 36, "latency": 16.59670329093933}
{"id": "live_simple_235-124-0", "result": "[play_spotify_song(query=\"track:Friends artist:Marshmello\")]", "input_token_count": 698, "output_token_count": 20, "latency": 7.384472131729126}
{"id": "live_simple_236-124-1", "result": [{"play_spotify_song": {"query": "track:Dil Nu artist:Maninder Buttar"}}], "input_token_count": 691, "output_token_count": 33, "latency": 15.313367366790771}
{"id": "live_simple_237-125-0", "result": [{"play_spotify_song": {"query": "track:Wrecking Ball artist:Miley Cyrus"}}], "input_token_count": 673, "output_token_count": 33, "latency": 14.786022663116455}
{"id": "live_simple_238-125-1", "result": [{"play_spotify_song": {"query": "track:Dil Nu artist:Maninder Buttar"}}], "input_token_count": 678, "output_token_count": 33, "latency": 14.764557600021362}
{"id": "live_simple_239-125-2", "result": [{"play_spotify_song": {"query": "\u60a8\u7684\u5f62\u72c0"}}], "input_token_count": 669, "output_token_count": 27, "latency": 11.040951490402222}
{"id": "live_simple_240-125-3", "result": [{"play_spotify_song": {"query": "\u9bca\u9b5a"}}], "input_token_count": 669, "output_token_count": 27, "latency": 11.038683652877808}
{"id": "live_simple_241-125-4", "result": [{"play_spotify_song": {"query": "track:Johnny Johnny is a Dad artist:Johnny Johnny is a Dad"}}], "input_token_count": 665, "output_token_count": 36, "latency": 16.997950315475464}
{"id": "live_simple_242-126-0", "result": [{"set_volume": {"volume": 20}}], "input_token_count": 512, "output_token_count": 20, "latency": 7.558812856674194}
{"id": "live_simple_243-126-1", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_244-126-2", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_245-127-0", "result": [{"book_flight": {"departure_location": "JFK", "departure_date": "16/03/2024", "departure_time": "14:00"}}], "input_token_count": 764, "output_token_count": 55, "latency": 32.200204849243164}
{"id": "live_simple_246-128-0", "result": "[book_flight(departure_location=\"New York, NY\", departure_time=\"15/03/2024\")]", "input_token_count": 659, "output_token_count": 30, "latency": 16.75910520553589}
{"id": "live_simple_247-129-0", "result": "[version_api.VersionApi.get_version()]", "input_token_count": 415, "output_token_count": 10, "latency": 4.411194086074829}
{"id": "live_simple_248-130-0", "result": "Error during inference: 'arguments'", "traceback": "Traceback (most recent call last):\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/base_oss_handler.py\", line 279, in _multi_threaded_inference\n    model_responses, metadata = self.inference_single_turn_prompting(\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/base_handler.py\", line 631, in inference_single_turn_prompting\n    model_response_data = self._parse_query_response_prompting(api_response)\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 276, in _parse_query_response_prompting\n    model_responses = [\n  File \"/workspace/gorilla/berkeley-function-call-leaderboard/bfcl_eval/model_handler/local_inference/mistral_fc.py\", line 277, in <listcomp>\n    {item[\"name\"]: item[\"arguments\"]} for item in model_responses\nKeyError: 'arguments'\n"}
{"id": "live_simple_249-131-0", "result": [{"chat_with_friend": {"user_message": "\u4f60\u597d\u55ce"}}], "input_token_count": 508, "output_token_count": 24, "latency": 13.448184728622437}
{"id": "live_simple_250-132-0", "result": [{"uber.eat.order": {"restaurants": "\u9ea5\u7576\u52de", "items": ["\u5de8\u7121\u9738", "McFlurry"], "quantities": [2, 1]}}], "input_token_count": 696, "output_token_count": 52, "latency": 33.4989812374115}
{"id": "live_simple_251-133-0", "result": [{"flight.status.check": {"flight_id": "Indigo 6E123", "passenger_name": "\u5361\u862d", "ticket_number": "IND4567"}}], "input_token_count": 703, "output_token_count": 48, "latency": 31.248095750808716}
{"id": "live_simple_252-134-0", "result": [{"flight.status.check": {"airlines": "\u975b\u85cd", "person_name": "\u5361\u862d", "ticket_number": "IND4567"}}], "input_token_count": 707, "output_token_count": 43, "latency": 28.220399618148804}
{"id": "live_simple_253-135-0", "result": [{"uber.eat.order": {"restaurants": "\u9ea5\u7576\u52de", "items": ["\u6f22\u5821", "\u96de\u7fc5"], "quantities": [5, 6]}}], "input_token_count": 702, "output_token_count": 52, "latency": 34.07076334953308}
{"id": "live_simple_254-136-0", "result": [{"user.mandates": {"user_id": "U123"}}], "input_token_count": 663, "output_token_count": 25, "latency": 15.099878311157227}
{"id": "live_simple_255-136-1", "result": [{"user.mandates": {"user_id": "U123456"}}], "input_token_count": 669, "output_token_count": 28, "latency": 17.386099576950073}
{"id": "live_simple_256-137-0", "result": [{"answer_question": {"statement": "\u6211\u5df2\u7d93\u63d0\u4ea4\u4e86\u6295\u8a34\uff0c\u6211\u559c\u6b61\u6aa2\u67e5\u5176\u72c0\u614b"}}], "input_token_count": 706, "output_token_count": 39, "latency": 25.432724475860596}
{"id": "live_simple_257-137-1", "result": [{"answer_question": {"statement": "What is the minimum delivery time for a package?", "language": "en"}}], "input_token_count": 703, "output_token_count": 33, "latency": 21.441914796829224}
